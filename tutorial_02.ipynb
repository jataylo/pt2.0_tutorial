{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/test/rocm5.6/\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (2.1.0+rocm5.6)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.16.0+rocm5.6)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (2.1.0+rocm5.6)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: pytorch-triton-rocm==2.1.0 in /usr/local/lib/python3.8/dist-packages (from torch) (2.1.0+34f8189eae)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.24.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "# Install PT2.0,#\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/test/rocm5.6/\n",
    "\n",
    "# Install timm\n",
    "!pip3 install timm viztracer tabulate ipywidgets\n",
    "\n",
    "# Imports\n",
    "import torch \n",
    "import timm\n",
    "import tabulate\n",
    "import torch._dynamo\n",
    "import logging\n",
    "import transformers\n",
    "from typing import List\n",
    "from viztracer import VizTracer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'timm.models.resnet.ResNet'>\n",
      "<class 'torch._dynamo.eval_frame.OptimizedModule'>\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act1): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (drop_block): Identity()\n",
      "      (act1): ReLU(inplace=True)\n",
      "      (aa): Identity()\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act2): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "OptimizedModule(\n",
      "  (_orig_mod): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch._logging.set_logs()\n",
    "\n",
    "torch._dynamo.reset()\n",
    "\n",
    "model = timm.create_model('resnet18', pretrained=False, num_classes=2).to('cuda:0')\n",
    "\n",
    "# Wraps the original torch.nn.Module and later patches to optimised self.forward method\n",
    "opt_model = torch.compile(model, backend=\"inductor\")\n",
    "\n",
    "print(type(model))\n",
    "print(type(opt_model))\n",
    "\n",
    "print(model)\n",
    "print(opt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2383, -0.1939],\n",
       "        [ 0.6572,  0.1961],\n",
       "        [-0.1838,  0.0419],\n",
       "        [ 0.1979, -0.5030],\n",
       "        [ 0.0690, -0.4075],\n",
       "        [-0.1802,  0.5213],\n",
       "        [ 0.7444, -0.8149],\n",
       "        [ 0.6839, -0.0070],\n",
       "        [-0.0533, -0.0607],\n",
       "        [ 0.0489,  0.2604],\n",
       "        [ 0.4726, -0.5212],\n",
       "        [ 0.9182, -0.3004],\n",
       "        [ 0.1978,  0.1747],\n",
       "        [-0.1231, -0.0444],\n",
       "        [-0.2041, -0.1494],\n",
       "        [-0.2494, -0.3497],\n",
       "        [ 0.0855, -0.8035],\n",
       "        [ 0.2432,  0.1111],\n",
       "        [ 0.3039, -0.1925],\n",
       "        [-0.2229, -0.6068],\n",
       "        [ 0.1484,  0.1843],\n",
       "        [ 0.3748, -0.7154],\n",
       "        [ 0.1294,  0.0347],\n",
       "        [-0.1229, -0.1495],\n",
       "        [ 0.0286, -0.1407],\n",
       "        [-0.1305, -0.6298],\n",
       "        [ 0.4487, -0.0850],\n",
       "        [ 0.6505, -0.0454],\n",
       "        [ 0.3222, -0.1426],\n",
       "        [-0.0153, -0.3810],\n",
       "        [ 1.4025, -0.6599],\n",
       "        [-0.0867,  0.2649],\n",
       "        [-0.1993,  0.5970],\n",
       "        [ 0.6469, -0.3114],\n",
       "        [ 0.5813, -0.1107],\n",
       "        [ 0.5300, -0.4511],\n",
       "        [ 0.1829, -0.0629],\n",
       "        [-0.1024, -0.5492],\n",
       "        [ 0.3651, -0.0683],\n",
       "        [-0.2617,  0.1615],\n",
       "        [ 0.1111, -0.2702],\n",
       "        [ 1.1592, -0.1242],\n",
       "        [ 0.0943, -0.4330],\n",
       "        [ 0.2717, -0.2527],\n",
       "        [-0.4076,  0.1377],\n",
       "        [ 0.9321,  0.0626],\n",
       "        [ 0.7769, -0.0423],\n",
       "        [-0.0891, -0.4545],\n",
       "        [ 0.7990, -1.4038],\n",
       "        [ 0.1916,  0.2411],\n",
       "        [ 0.7431, -0.4617],\n",
       "        [ 0.7614, -0.7670],\n",
       "        [ 0.1401, -0.3751],\n",
       "        [ 0.1419, -0.0672],\n",
       "        [ 0.5425,  0.0543],\n",
       "        [ 0.3296, -0.5703],\n",
       "        [ 0.3864,  0.2163],\n",
       "        [-0.0906, -0.1873],\n",
       "        [-0.2481,  0.0273],\n",
       "        [ 0.1964, -0.6345],\n",
       "        [-0.8896,  0.3108],\n",
       "        [ 0.5824, -0.3065],\n",
       "        [-0.4679, -0.1886],\n",
       "        [ 0.9835, -0.0247]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "input_batch = torch.randn(64,3,7,7).to('cuda:0')\n",
    "\n",
    "model = timm.create_model('resnet18', pretrained=False, num_classes=2).to('cuda:0')\n",
    "opt_model = torch.compile(model, backend=\"inductor\")\n",
    "\n",
    "# Wraps the original torch.nn.Module and later patches to optimised self.forward method\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-06 23:01:34 19834:19834 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-09-06 23:01:40 19834:19834 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-09-06 23:01:40 19834:19834 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "torch._dynamo.reset()\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    with torch.profiler.record_function(\"torch.compile call\"):\n",
    "        input_batch = torch.randn(64,3,7,7).to('cuda:0')\n",
    "        opt_model = torch.compile(model, backend=\"inductor\")\n",
    "    with torch.profiler.record_function(\"opt_model(input_batch)\"):\n",
    "        opt_model(input_batch)\n",
    "\n",
    "prof.export_chrome_trace(\"trace.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamo output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-06 23:06:57,100] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:540\n",
      "[2023-09-06 23:06:57,100] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,104] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:541\n",
      "[2023-09-06 23:06:57,104] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.forward_features(x)\n",
      "[2023-09-06 23:06:57,105] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:519 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,105] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward_features(self, x):\n",
      "[2023-09-06 23:06:57,105] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:520 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,105] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,109] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,109] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,121] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:522 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,121] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,123] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:523 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,123] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.maxpool(x)\n",
      "[2023-09-06 23:06:57,125] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:525 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,125] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.grad_checkpointing and not torch.jit.is_scripting():\n",
      "[2023-09-06 23:06:57,126] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:528 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,126] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer1(x)\n",
      "[2023-09-06 23:06:57,129] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,129] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,130] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,130] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,131] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,131] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,133] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,133] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,133] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,133] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,134] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,134] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,134] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,134] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,135] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,135] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,135] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,135] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,136] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,136] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,136] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,136] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,136] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,136] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,137] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,137] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,138] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,138] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,138] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,138] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,142] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,142] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,154] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,154] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,156] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,156] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,158] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,158] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,159] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,159] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,162] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,162] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,174] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,174] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,175] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,175] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,176] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,176] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,176] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,176] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,178] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,178] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,180] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,180] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,183] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,183] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,184] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,184] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,185] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,185] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,187] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,187] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,187] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,187] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,188] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,188] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,188] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,188] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,189] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,189] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,190] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,190] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,190] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,190] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,190] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,190] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,191] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,191] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,191] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,191] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,192] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,192] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,192] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,192] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,196] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,196] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,209] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,209] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,211] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,211] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,213] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,213] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,214] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,214] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,217] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,217] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,230] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,230] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,231] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,231] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,232] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,232] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,233] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,233] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,234] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,234] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,236] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,236] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,237] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:529 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,237] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer2(x)\n",
      "[2023-09-06 23:06:57,240] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,240] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,241] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,241] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,242] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,242] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,244] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,244] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,244] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,244] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,245] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,245] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,245] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,245] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,246] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,246] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,246] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,246] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,246] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,246] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,247] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,247] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,247] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,247] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,248] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,248] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,248] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,248] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,249] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,249] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,253] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,253] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,266] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,266] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,268] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,268] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,270] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,270] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,271] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,271] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,275] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,275] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,288] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,288] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,289] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,289] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,290] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,290] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,291] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,291] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 shortcut = self.downsample(shortcut)\n",
      "[2023-09-06 23:06:57,306] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,306] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,307] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,307] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,308] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,308] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,311] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,311] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,312] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,312] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,313] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,313] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,314] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,314] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,315] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,315] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,315] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,315] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,316] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,316] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,316] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,316] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,316] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,316] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,317] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,317] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,317] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,317] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,317] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,317] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,319] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,319] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,319] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,319] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,319] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,319] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,324] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,324] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,336] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,336] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,337] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,337] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,339] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,339] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,341] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,341] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,344] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,344] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,355] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,355] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,356] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,356] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,357] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,357] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,358] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,358] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,359] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,359] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,361] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,361] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,362] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:530 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,362] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer3(x)\n",
      "[2023-09-06 23:06:57,365] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,365] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,366] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,366] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,368] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,368] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,370] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,370] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,370] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,370] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,371] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,371] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,371] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,371] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,372] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,372] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,372] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,372] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,373] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,373] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,373] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,373] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,373] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,373] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,374] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,374] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,375] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,375] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,375] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,375] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,380] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,380] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,394] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,394] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,395] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,395] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,397] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,397] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,399] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,399] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,402] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,402] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,416] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,416] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,417] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,417] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,418] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,418] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,419] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,419] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 shortcut = self.downsample(shortcut)\n",
      "[2023-09-06 23:06:57,436] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,436] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,437] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,437] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,439] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,439] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,442] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,442] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,443] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,443] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,444] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,444] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,447] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,447] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,447] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,447] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,448] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,448] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,448] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,448] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,449] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,449] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,449] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,449] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,450] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,450] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,450] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,450] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,450] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,450] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,452] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,452] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,452] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,452] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,452] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,452] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,456] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,456] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,470] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,470] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,471] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,471] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,474] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,474] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,476] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,476] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,479] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,479] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,492] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,492] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,493] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,493] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,493] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,493] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,494] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,494] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,496] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,496] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,498] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,498] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,499] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:531 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,499] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer4(x)\n",
      "[2023-09-06 23:06:57,502] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,502] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,503] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,503] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,504] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,504] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,507] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,507] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,507] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,507] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,508] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,508] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,508] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,508] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,508] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,508] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,509] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,509] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,509] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,509] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,509] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,509] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,510] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,510] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,511] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,511] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,511] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,511] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,512] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,512] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,516] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,516] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,530] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,530] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,532] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,532] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,534] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,534] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,536] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,536] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,539] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,539] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,553] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,553] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,554] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,554] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,555] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,555] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,556] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,556] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 shortcut = self.downsample(shortcut)\n",
      "[2023-09-06 23:06:57,573] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,573] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,575] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,575] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,577] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,577] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,581] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,581] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,581] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,581] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,582] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,582] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,585] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,585] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,585] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,585] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,586] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,586] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,586] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,586] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,587] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,587] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,587] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,587] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,587] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,587] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,588] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,588] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,588] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,588] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,589] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,589] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,590] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,590] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-06 23:06:57,590] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,590] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-06 23:06:57,595] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,595] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-06 23:06:57,609] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,609] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-06 23:06:57,611] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,611] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-06 23:06:57,613] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,613] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-06 23:06:57,615] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,615] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-06 23:06:57,619] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,619] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-06 23:06:57,632] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,632] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-06 23:06:57,633] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,633] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-06 23:06:57,634] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,634] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-06 23:06:57,635] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,635] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-06 23:06:57,637] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,637] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-06 23:06:57,639] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,639] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,640] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:532 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,640] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,641] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:542\n",
      "[2023-09-06 23:06:57,641] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.forward_head(x)\n",
      "[2023-09-06 23:06:57,642] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:534 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,642] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward_head(self, x, pre_logits: bool = False):\n",
      "[2023-09-06 23:06:57,642] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:535 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,642] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.global_pool(x)\n",
      "[2023-09-06 23:06:57,646] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,646] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-06 23:06:57,646] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,646] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-06 23:06:57,647] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,647] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,649] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,649] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,650] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,650] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,650] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,650] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-06 23:06:57,650] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,650] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,651] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,651] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,651] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,651] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,651] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,651] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-06 23:06:57,652] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,652] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-06 23:06:57,652] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-06 23:06:57,652] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-06 23:06:57,653] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:166 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,653] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-06 23:06:57,654] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:167 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,654] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.pool(x)\n",
      "[2023-09-06 23:06:57,657] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:168 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,657] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.flatten(x)\n",
      "[2023-09-06 23:06:57,659] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:169 (inline depth: 3)\n",
      "[2023-09-06 23:06:57,659] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-06 23:06:57,660] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:536 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,660] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_rate:\n",
      "[2023-09-06 23:06:57,661] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:538 (inline depth: 1)\n",
      "[2023-09-06 23:06:57,661] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x if pre_logits else self.fc(x)\n",
      "[2023-09-06 23:06:57,667] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:543\n",
      "[2023-09-06 23:06:57,667] [28/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6776, -0.7374],\n",
       "        [-0.8101, -0.0034],\n",
       "        [ 0.1255, -0.2349],\n",
       "        [-0.4029, -0.1299],\n",
       "        [ 0.1070, -0.3228],\n",
       "        [-0.5940, -0.0554],\n",
       "        [-0.4449, -0.9274],\n",
       "        [ 0.0860, -0.1852],\n",
       "        [ 0.1218, -0.5544],\n",
       "        [-1.3032,  0.0221],\n",
       "        [-0.3760, -0.4635],\n",
       "        [-0.2732, -0.5201],\n",
       "        [ 0.2781, -0.3265],\n",
       "        [-0.0740, -0.2682],\n",
       "        [-0.5682, -1.0316],\n",
       "        [-0.2384, -0.3366],\n",
       "        [-0.3340, -0.0929],\n",
       "        [-0.2389, -0.2243],\n",
       "        [-0.7796, -0.2437],\n",
       "        [-0.0260, -0.1377],\n",
       "        [ 0.0033, -0.0315],\n",
       "        [ 0.2189, -0.1909],\n",
       "        [-0.5649, -0.0356],\n",
       "        [-0.0759, -0.3170],\n",
       "        [ 0.0263, -0.8109],\n",
       "        [-0.0387, -0.9966],\n",
       "        [-0.8074, -1.0785],\n",
       "        [ 0.1519, -0.3504],\n",
       "        [-0.6180, -0.7323],\n",
       "        [-0.2960, -0.6540],\n",
       "        [ 0.3075, -0.7503],\n",
       "        [ 0.0692, -0.3588],\n",
       "        [-0.1934,  0.4809],\n",
       "        [-0.4050, -0.5018],\n",
       "        [ 0.3792, -0.0941],\n",
       "        [-0.0811, -0.6375],\n",
       "        [-0.1886, -0.1428],\n",
       "        [ 0.2529, -0.7100],\n",
       "        [-0.4634, -0.2559],\n",
       "        [-0.8162, -0.2680],\n",
       "        [-0.3019, -0.8472],\n",
       "        [-0.1891, -0.6373],\n",
       "        [-0.7102,  0.0336],\n",
       "        [-0.1311, -0.3468],\n",
       "        [-0.2014, -0.3977],\n",
       "        [-0.3249, -0.3949],\n",
       "        [-0.4759, -0.7508],\n",
       "        [-0.0650, -0.1991],\n",
       "        [-0.3171,  0.1728],\n",
       "        [-0.2010, -0.2755],\n",
       "        [-0.2637, -0.4647],\n",
       "        [-0.6658, -0.2353],\n",
       "        [-0.2518, -0.3385],\n",
       "        [-0.3607, -0.4237],\n",
       "        [ 0.3110, -0.8252],\n",
       "        [-0.3933, -0.2984],\n",
       "        [-0.2418,  0.0319],\n",
       "        [-0.3363, -0.2234],\n",
       "        [-0.2661,  0.0295],\n",
       "        [-0.5282, -0.3457],\n",
       "        [-0.7451,  0.1358],\n",
       "        [-0.7544, -0.1464],\n",
       "        [ 0.3849, -0.5511],\n",
       "        [-0.6905, -0.6349]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamo tracing\n",
    "torch._logging.set_logs(trace_source=True)\n",
    "torch._dynamo.reset()\n",
    "input_batch = torch.randn(64,3,7,7).to('cuda:0')\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] ORIGINAL BYTECODE forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py line 540 \n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] 541           0 LOAD_FAST                0 (self)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_METHOD              0 (forward_features)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 LOAD_FAST                1 (x)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 CALL_METHOD              1\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 STORE_FAST               1 (x)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] 542          10 LOAD_FAST                0 (self)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              12 LOAD_METHOD              1 (forward_head)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              14 LOAD_FAST                1 (x)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              16 CALL_METHOD              1\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              18 STORE_FAST               1 (x)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] 543          20 LOAD_FAST                1 (x)\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]              22 RETURN_VALUE\n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2023-09-07 14:55:01,137] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] MODIFIED BYTECODE forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py line 540 \n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] 540           0 LOAD_GLOBAL              3 (__compiled_fn_1)\n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               2 LOAD_FAST                1 (x)\n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               4 CALL_FUNCTION            1\n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               6 UNPACK_SEQUENCE          1\n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG]               8 RETURN_VALUE\n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n",
      "[2023-09-07 14:55:01,138] [1/0] torch._dynamo.convert_frame.__bytecode: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1540e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1752e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2432e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1029e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5336e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2622e-02],\n",
       "        [ 4.4532e-01,  7.0079e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0302e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bytecode transformation\n",
    "torch._logging.set_logs(bytecode=True)\n",
    "torch._dynamo.reset()\n",
    "input_batch = torch.randn(64,3,7,7).to('cuda:0')\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OptimizedModule(\n",
      "  (_orig_mod): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act1): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (drop_block): Identity()\n",
      "        (act1): ReLU(inplace=True)\n",
      "        (aa): Identity()\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
      "    (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_2 <eval_with_key>.175 opcode         name                                         target                                       args                                                                               kwargs\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -------------------------------------------  -------------------------------------------  ---------------------------------------------------------------------------------  --------\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_                                         L_x_                                         ()                                                                                 {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___conv1                              L__self___conv1                              (l_x_,)                                                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___bn1                                L__self___bn1                                (l__self___conv1,)                                                                 {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___act1                               L__self___act1                               (l__self___bn1,)                                                                   {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___maxpool                            L__self___maxpool                            (l__self___act1,)                                                                  {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___conv1         getattr_L__self___layer1___0___conv1         (l__self___maxpool,)                                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___bn1           getattr_L__self___layer1___0___bn1           (getattr_l__self___layer1___0___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___drop_block    getattr_L__self___layer1___0___drop_block    (getattr_l__self___layer1___0___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___act1          getattr_L__self___layer1___0___act1          (getattr_l__self___layer1___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___aa            getattr_L__self___layer1___0___aa            (getattr_l__self___layer1___0___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___conv2         getattr_L__self___layer1___0___conv2         (getattr_l__self___layer1___0___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___bn2           getattr_L__self___layer1___0___bn2           (getattr_l__self___layer1___0___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd                                         <built-in function iadd>                     (getattr_l__self___layer1___0___bn2, l__self___maxpool)                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___act2          getattr_L__self___layer1___0___act2          (iadd,)                                                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___conv1         getattr_L__self___layer1___1___conv1         (getattr_l__self___layer1___0___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___bn1           getattr_L__self___layer1___1___bn1           (getattr_l__self___layer1___1___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___drop_block    getattr_L__self___layer1___1___drop_block    (getattr_l__self___layer1___1___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___act1          getattr_L__self___layer1___1___act1          (getattr_l__self___layer1___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___aa            getattr_L__self___layer1___1___aa            (getattr_l__self___layer1___1___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___conv2         getattr_L__self___layer1___1___conv2         (getattr_l__self___layer1___1___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___bn2           getattr_L__self___layer1___1___bn2           (getattr_l__self___layer1___1___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_1                                       <built-in function iadd>                     (getattr_l__self___layer1___1___bn2, getattr_l__self___layer1___0___act2)          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___act2          getattr_L__self___layer1___1___act2          (iadd_1,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___conv1         getattr_L__self___layer2___0___conv1         (getattr_l__self___layer1___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___bn1           getattr_L__self___layer2___0___bn1           (getattr_l__self___layer2___0___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___drop_block    getattr_L__self___layer2___0___drop_block    (getattr_l__self___layer2___0___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___act1          getattr_L__self___layer2___0___act1          (getattr_l__self___layer2___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___aa            getattr_L__self___layer2___0___aa            (getattr_l__self___layer2___0___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___conv2         getattr_L__self___layer2___0___conv2         (getattr_l__self___layer2___0___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___bn2           getattr_L__self___layer2___0___bn2           (getattr_l__self___layer2___0___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___downsample_0  getattr_L__self___layer2___0___downsample_0  (getattr_l__self___layer1___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___downsample_1  getattr_L__self___layer2___0___downsample_1  (getattr_l__self___layer2___0___downsample_0,)                                     {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_2                                       <built-in function iadd>                     (getattr_l__self___layer2___0___bn2, getattr_l__self___layer2___0___downsample_1)  {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___act2          getattr_L__self___layer2___0___act2          (iadd_2,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___conv1         getattr_L__self___layer2___1___conv1         (getattr_l__self___layer2___0___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___bn1           getattr_L__self___layer2___1___bn1           (getattr_l__self___layer2___1___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___drop_block    getattr_L__self___layer2___1___drop_block    (getattr_l__self___layer2___1___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___act1          getattr_L__self___layer2___1___act1          (getattr_l__self___layer2___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___aa            getattr_L__self___layer2___1___aa            (getattr_l__self___layer2___1___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___conv2         getattr_L__self___layer2___1___conv2         (getattr_l__self___layer2___1___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___bn2           getattr_L__self___layer2___1___bn2           (getattr_l__self___layer2___1___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_3                                       <built-in function iadd>                     (getattr_l__self___layer2___1___bn2, getattr_l__self___layer2___0___act2)          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___act2          getattr_L__self___layer2___1___act2          (iadd_3,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___conv1         getattr_L__self___layer3___0___conv1         (getattr_l__self___layer2___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___bn1           getattr_L__self___layer3___0___bn1           (getattr_l__self___layer3___0___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___drop_block    getattr_L__self___layer3___0___drop_block    (getattr_l__self___layer3___0___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___act1          getattr_L__self___layer3___0___act1          (getattr_l__self___layer3___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___aa            getattr_L__self___layer3___0___aa            (getattr_l__self___layer3___0___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___conv2         getattr_L__self___layer3___0___conv2         (getattr_l__self___layer3___0___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___bn2           getattr_L__self___layer3___0___bn2           (getattr_l__self___layer3___0___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___downsample_0  getattr_L__self___layer3___0___downsample_0  (getattr_l__self___layer2___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___downsample_1  getattr_L__self___layer3___0___downsample_1  (getattr_l__self___layer3___0___downsample_0,)                                     {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_4                                       <built-in function iadd>                     (getattr_l__self___layer3___0___bn2, getattr_l__self___layer3___0___downsample_1)  {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___act2          getattr_L__self___layer3___0___act2          (iadd_4,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___conv1         getattr_L__self___layer3___1___conv1         (getattr_l__self___layer3___0___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___bn1           getattr_L__self___layer3___1___bn1           (getattr_l__self___layer3___1___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___drop_block    getattr_L__self___layer3___1___drop_block    (getattr_l__self___layer3___1___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___act1          getattr_L__self___layer3___1___act1          (getattr_l__self___layer3___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___aa            getattr_L__self___layer3___1___aa            (getattr_l__self___layer3___1___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___conv2         getattr_L__self___layer3___1___conv2         (getattr_l__self___layer3___1___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___bn2           getattr_L__self___layer3___1___bn2           (getattr_l__self___layer3___1___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_5                                       <built-in function iadd>                     (getattr_l__self___layer3___1___bn2, getattr_l__self___layer3___0___act2)          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___act2          getattr_L__self___layer3___1___act2          (iadd_5,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___conv1         getattr_L__self___layer4___0___conv1         (getattr_l__self___layer3___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___bn1           getattr_L__self___layer4___0___bn1           (getattr_l__self___layer4___0___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___drop_block    getattr_L__self___layer4___0___drop_block    (getattr_l__self___layer4___0___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___act1          getattr_L__self___layer4___0___act1          (getattr_l__self___layer4___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___aa            getattr_L__self___layer4___0___aa            (getattr_l__self___layer4___0___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___conv2         getattr_L__self___layer4___0___conv2         (getattr_l__self___layer4___0___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___bn2           getattr_L__self___layer4___0___bn2           (getattr_l__self___layer4___0___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___downsample_0  getattr_L__self___layer4___0___downsample_0  (getattr_l__self___layer3___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___downsample_1  getattr_L__self___layer4___0___downsample_1  (getattr_l__self___layer4___0___downsample_0,)                                     {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_6                                       <built-in function iadd>                     (getattr_l__self___layer4___0___bn2, getattr_l__self___layer4___0___downsample_1)  {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___act2          getattr_L__self___layer4___0___act2          (iadd_6,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___conv1         getattr_L__self___layer4___1___conv1         (getattr_l__self___layer4___0___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___bn1           getattr_L__self___layer4___1___bn1           (getattr_l__self___layer4___1___conv1,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___drop_block    getattr_L__self___layer4___1___drop_block    (getattr_l__self___layer4___1___bn1,)                                              {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___act1          getattr_L__self___layer4___1___act1          (getattr_l__self___layer4___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___aa            getattr_L__self___layer4___1___aa            (getattr_l__self___layer4___1___act1,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___conv2         getattr_L__self___layer4___1___conv2         (getattr_l__self___layer4___1___aa,)                                               {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___bn2           getattr_L__self___layer4___1___bn2           (getattr_l__self___layer4___1___conv2,)                                            {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_7                                       <built-in function iadd>                     (getattr_l__self___layer4___1___bn2, getattr_l__self___layer4___0___act2)          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___act2          getattr_L__self___layer4___1___act2          (iadd_7,)                                                                          {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___global_pool_pool                   L__self___global_pool_pool                   (getattr_l__self___layer4___1___act2,)                                             {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___global_pool_flatten                L__self___global_pool_flatten                (l__self___global_pool_pool,)                                                      {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___fc                                 L__self___fc                                 (l__self___global_pool_flatten,)                                                   {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                       output                                       ((l__self___fc,),)                                                                 {}\n",
      "[2023-09-07 14:55:37,264] [2/0] torch._dynamo.output_graph.__graph: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1540e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1753e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2431e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1031e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5335e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2623e-02],\n",
       "        [ 4.4532e-01,  7.0078e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0302e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bytecode transformation\n",
    "torch._logging.set_logs(graph=True)\n",
    "torch._dynamo.reset()\n",
    "\n",
    "print(opt_model)\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 14:56:40,182] [3/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2023-09-07 14:56:40,184] [3/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2023-09-07 14:56:40,184] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 139853266183168)                   # x = self.conv1(x)  # timm/models/resnet.py:520 in forward_features\n",
      "[2023-09-07 14:56:40,185] [3/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # x = self.conv1(x)  # timm/models/resnet.py:520 in forward_features\n",
      "[2023-09-07 14:56:40,185] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'].forward_head.__defaults__[0], 9474016)  # return x if pre_logits else self.fc(x)  # timm/models/resnet.py:538 in forward_head\n",
      "[2023-09-07 14:56:40,185] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2023-09-07 14:56:40,186] [3/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2023-09-07 14:56:40,186] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2023-09-07 14:56:40,187] [3/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2023-09-07 14:56:40,187] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,187] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,188] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,188] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,188] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,189] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,189] [3/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,189] [3/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:56:40,190] [3/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[64, 3, 7, 7], stride=[147, 49, 7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1541e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1752e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2432e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1031e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5335e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2623e-02],\n",
       "        [ 4.4532e-01,  7.0079e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0302e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guards\n",
    "torch._logging.set_logs(guards=True)\n",
    "torch._dynamo.reset()\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 14:57:21,920] [4/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo start tracing forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:540\n",
      "[2023-09-07 14:57:21,922] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:540\n",
      "[2023-09-07 14:57:21,922] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:21,925] [4/0] torch._dynamo.variables.builder: [DEBUG] wrap_to_fake L['x'] (64, 3, 7, 7) [<DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>, <DimDynamic.STATIC: 2>] [None, None, None, None]\n",
      "[2023-09-07 14:57:21,926] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:541\n",
      "[2023-09-07 14:57:21,926] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.forward_features(x)\n",
      "[2023-09-07 14:57:21,927] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,927] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward_features [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,928] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserMethodVariable(<function ResNet.forward_features at 0x7f300c587310>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:21,928] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserMethodVariable(<function ResNet.forward_features at 0x7f300c587310>, NNModuleVariable()), TensorVariable()]\n",
      "[2023-09-07 14:57:21,929] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward_features at 0x7f300c56c0e0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 519>\n",
      "[2023-09-07 14:57:21,929] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:519 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,929] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward_features(self, x):\n",
      "[2023-09-07 14:57:21,930] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:520 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,930] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:21,930] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,930] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,931] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,931] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:21,935] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:21,936] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,936] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:21,936] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,937] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,937] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,938] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:21,951] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:21,952] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:522 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,952] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:21,952] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,952] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,953] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,953] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:21,955] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:21,956] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:523 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,956] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.maxpool(x)\n",
      "[2023-09-07 14:57:21,956] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,956] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR maxpool [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,957] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,957] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:21,959] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:21,959] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:525 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,959] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.grad_checkpointing and not torch.jit.is_scripting():\n",
      "[2023-09-07 14:57:21,960] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,960] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR grad_checkpointing [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,961] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 88 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:21,961] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:528 (inline depth: 1)\n",
      "[2023-09-07 14:57:21,961] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer1(x)\n",
      "[2023-09-07 14:57:21,961] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,962] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,963] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,963] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:21,964] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:21,966] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,966] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:21,967] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,967] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:21,967] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:21,968] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:21,968] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:21,969] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:21,969] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:21,970] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,970] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,971] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:21,971] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,971] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:21,971] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,972] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,972] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,973] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,973] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,974] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,974] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,975] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,975] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,976] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,976] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,977] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,977] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,977] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:21,977] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:21,978] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,978] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:21,978] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,978] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,978] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:21,979] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:21,979] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,979] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:21,980] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,980] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,980] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:21,980] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:21,981] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,981] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:21,981] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,982] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,982] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:21,982] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:21,982] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,982] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:21,983] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,983] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:21,983] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:21,983] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:21,984] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:21,984] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:21,984] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:21,985] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:21,986] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:21,986] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:21,986] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:21,986] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:21,986] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:21,987] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:21,987] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:21,987] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:21,987] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,988] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,988] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,989] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:21,996] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:21,996] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:21,996] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:21,996] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:21,997] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,997] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:21,998] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,011] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,012] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,012] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,012] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,012] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,013] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,013] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,015] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,015] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,015] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,015] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,016] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,016] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,017] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,019] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,019] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,019] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,019] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,020] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,020] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,021] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,022] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,022] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,022] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,023] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,023] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,024] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,024] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,027] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,028] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,028] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,028] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,029] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,029] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,030] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,042] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,043] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,043] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,043] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,043] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,044] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,044] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,045] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,045] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,045] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,045] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,045] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,046] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,046] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,047] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,047] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,047] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,047] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,048] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,048] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,048] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,049] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,049] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,049] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,049] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,050] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,050] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,053] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,053] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,053] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,053] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,054] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,054] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,055] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,056] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,056] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,056] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,057] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,057] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,057] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,058] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,058] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,059] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,061] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,061] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,061] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,061] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,062] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,062] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,062] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,063] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,063] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,064] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,064] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,065] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,065] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,065] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,065] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,065] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,066] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,066] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,067] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,068] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,068] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,069] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,069] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,069] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,070] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,070] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,071] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,071] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,071] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,071] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,071] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,071] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,072] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,072] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,072] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,072] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,072] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,073] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,073] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,073] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,073] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,074] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,074] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,074] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,074] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,074] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,074] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,075] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,075] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,075] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,075] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,075] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,076] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,076] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,076] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,077] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,077] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,078] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,078] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,078] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,078] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,079] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,079] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,079] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,079] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,080] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,080] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,081] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,081] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,088] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,088] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,088] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,088] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,089] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,089] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,090] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,103] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,104] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,104] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,104] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,104] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,105] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,105] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,106] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,107] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,107] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,107] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,107] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,108] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,108] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,110] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,111] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,111] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,111] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,111] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,112] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,112] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,113] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,113] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,113] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,114] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,114] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,115] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,115] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,119] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,119] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,119] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,120] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,120] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,121] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,121] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,133] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,134] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,134] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,134] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,134] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,135] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,135] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,135] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,136] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,136] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,136] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,136] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,137] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,137] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,138] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,138] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,138] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,138] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,139] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,139] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,139] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,140] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,140] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,140] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,140] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,141] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,141] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,143] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,144] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,144] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,144] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,144] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,145] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,145] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,147] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,147] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,147] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,148] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,148] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,148] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,149] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,149] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,150] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,150] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:529 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,150] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer2(x)\n",
      "[2023-09-07 14:57:22,150] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,150] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,151] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,152] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,153] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,155] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,155] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,156] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,156] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,156] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,156] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,157] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,158] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,158] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,158] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,159] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,159] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,160] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,160] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,160] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,160] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,161] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,161] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,162] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,162] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,163] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,163] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,163] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,164] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,164] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,165] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,165] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,165] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,165] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,166] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,166] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,166] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,166] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,166] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,167] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,167] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,167] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,168] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,168] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,168] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,168] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,169] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,169] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,169] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,169] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,169] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,170] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,170] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,170] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,170] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,171] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,171] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,171] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,171] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,172] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,172] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,173] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,173] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,173] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,174] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,174] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,174] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,174] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,175] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,175] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,175] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,175] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,176] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,176] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,184] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,184] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,184] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,184] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,185] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,185] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,186] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,198] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,198] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,198] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,199] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,199] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,200] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,200] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,201] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,202] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,202] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,202] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,202] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,203] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,203] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,205] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,205] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,205] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,205] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,206] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,206] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,207] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,208] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,208] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,208] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,209] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,209] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,210] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,210] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,214] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,214] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,214] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,214] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,215] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,215] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,216] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,228] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,228] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,228] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,229] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,229] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,230] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,230] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,230] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,231] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,231] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,231] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,231] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,232] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,232] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,233] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,233] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,233] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,233] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,234] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,234] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,235] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,235] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,236] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,236] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:57:22,236] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,236] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,237] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,237] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,253] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,253] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,253] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,253] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,254] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,254] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,255] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,256] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,256] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,256] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,256] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,257] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,257] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,258] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,259] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,259] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,259] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,259] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,260] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,260] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,260] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,261] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,264] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,264] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,264] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,264] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,264] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,265] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,265] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,266] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,266] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,267] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,267] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,267] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,268] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,268] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,268] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,268] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,269] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,269] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,270] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,270] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,271] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,271] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,271] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,272] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,272] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,273] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,273] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,273] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,274] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,274] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,274] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,274] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,274] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,274] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,275] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,275] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,275] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,275] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,276] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,276] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,276] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,276] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,276] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,276] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,277] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,277] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,277] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,277] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,277] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,278] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,278] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,278] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,279] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,279] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,279] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,280] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,280] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,281] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,281] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,281] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,281] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,282] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,282] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,282] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,282] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,283] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,283] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,284] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,284] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,291] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,291] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,291] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,292] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,292] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,293] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,293] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,305] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,305] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,305] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,305] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,306] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,306] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,307] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,308] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,309] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,309] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,309] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,309] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,310] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,310] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,312] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,313] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,313] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,313] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,313] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,314] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,314] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,315] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,316] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,316] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,316] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,316] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,317] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,317] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,320] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,321] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,321] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,321] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,322] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,322] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,335] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,335] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,335] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,336] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,336] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,337] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,337] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,337] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,338] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,338] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,338] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,338] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,339] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,339] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,339] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,340] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,340] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,340] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,340] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,341] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,341] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,342] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,342] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,342] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,342] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,343] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,343] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,346] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,346] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,346] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,347] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,348] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,349] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,350] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,350] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,350] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,350] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,351] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,351] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,351] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,352] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,352] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:530 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,352] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer3(x)\n",
      "[2023-09-07 14:57:22,353] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,353] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer3 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,354] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,354] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,355] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,358] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,358] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,358] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,358] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,359] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,359] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,360] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,360] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,361] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,361] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,362] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,362] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,362] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,362] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,363] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,363] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,364] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,364] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,365] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,365] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,366] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,367] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,367] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,368] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,368] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,369] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,369] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,369] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,369] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,369] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,370] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,370] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,370] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,370] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,371] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,371] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,371] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,371] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,371] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,372] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,372] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,372] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,372] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,373] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,373] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,373] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,373] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,373] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,374] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,374] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,374] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,374] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,375] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,375] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,375] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,376] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,377] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,377] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,377] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,377] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,377] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,378] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,378] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,378] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,379] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,379] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,380] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,380] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,390] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,390] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,390] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,391] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,391] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,392] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,392] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,406] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,407] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,407] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,407] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,407] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,408] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,410] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,410] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,410] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,411] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,411] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,412] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,412] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,414] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,414] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,414] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,415] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,415] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,416] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,416] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,417] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,418] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,418] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,418] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,418] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,419] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,419] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,423] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,423] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,423] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,424] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,424] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,425] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,425] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,439] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,439] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,439] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,440] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,440] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,441] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,441] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,442] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,442] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,442] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,442] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,443] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,443] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,444] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,444] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,445] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,445] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,445] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,445] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,446] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,447] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,447] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,448] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,448] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:57:22,448] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,448] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,449] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,449] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,468] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,468] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,468] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,468] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,469] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,469] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,471] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,471] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,471] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,472] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,472] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,472] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,473] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,475] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,475] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,475] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,476] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,476] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,476] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,477] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,477] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,478] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,481] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,481] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,481] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,481] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,481] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,482] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,482] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,483] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,483] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,484] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,484] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,485] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,485] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,485] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,487] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,487] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,488] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,488] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,489] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,489] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,490] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,491] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,491] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,492] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,492] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,493] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,493] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,493] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,494] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,494] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,494] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,494] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,495] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,495] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,495] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,495] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,495] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,496] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,496] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,496] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,496] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,497] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,497] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,497] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,497] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,497] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,498] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,498] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,498] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,498] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,499] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,499] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,499] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,499] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,500] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,500] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,501] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,502] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,502] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,502] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,502] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,502] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,503] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,503] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,503] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,503] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,504] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,504] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,505] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,510] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,511] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,511] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,511] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,512] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,512] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,526] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,527] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,527] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,527] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,527] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,528] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,529] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,530] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,530] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,530] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,531] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,531] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,532] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,532] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,534] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,535] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,535] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,535] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,535] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,536] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,536] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,538] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,538] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,538] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,539] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,539] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,540] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,540] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,543] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,544] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,544] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,544] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,545] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,545] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,546] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,560] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,560] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,560] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,561] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,561] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,562] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,562] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,562] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,563] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,563] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,563] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,564] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,564] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,565] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,565] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,566] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,566] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,566] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,566] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,567] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,567] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,568] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,568] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,568] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,568] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,569] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,569] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,572] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,573] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,573] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,573] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,573] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,574] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,574] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,577] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,577] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,577] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,577] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,578] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,578] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,578] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,579] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,579] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,580] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:531 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,580] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 x = self.layer4(x)\n",
      "[2023-09-07 14:57:22,580] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,580] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR layer4 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,581] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,581] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,583] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,585] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,585] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,585] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,585] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,586] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,587] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,587] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,588] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,588] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,589] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,590] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,590] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,590] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,590] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,591] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,592] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,592] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,593] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,593] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,594] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,594] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,595] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,595] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,596] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,597] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,597] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,597] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,597] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,597] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,598] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,598] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,598] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,598] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,599] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,599] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,599] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,599] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,599] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,600] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,600] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,600] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,600] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,601] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,601] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,601] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,601] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,601] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,602] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,602] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,602] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,602] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,603] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,603] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,604] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,605] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,605] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,605] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,606] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,606] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,606] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,606] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,607] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,607] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,607] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,607] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,608] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,608] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,616] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,617] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,617] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,617] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,617] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,618] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,619] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,632] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,633] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,633] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,633] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,634] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,634] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,635] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,636] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,637] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,637] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,637] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,637] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,638] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,638] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,641] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,641] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,641] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,641] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,642] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,642] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,643] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,644] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,645] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,645] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,645] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,645] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,646] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,646] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,650] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,651] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,651] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,651] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,651] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,652] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,652] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,666] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,667] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,667] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,667] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,667] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,668] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,668] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,669] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,669] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,669] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,670] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,670] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,671] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,671] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,671] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,672] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,672] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,672] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,673] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,673] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,674] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [NNModuleVariable(), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,674] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,675] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,675] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:57:22,675] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,675] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,676] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,676] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,695] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,696] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,696] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,696] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,696] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,697] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,698] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,699] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,699] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,699] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,699] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,700] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,701] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,703] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,703] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,703] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,704] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,704] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,704] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,705] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,705] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,706] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,709] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,709] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,709] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,709] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,710] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,710] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,711] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,711] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,712] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,712] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,712] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,713] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,713] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,713] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,714] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,714] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,714] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,715] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,715] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,716] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,717] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,717] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,718] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,718] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,719] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,719] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,720] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,720] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,720] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,721] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,721] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,721] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,721] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,721] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,722] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,722] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,722] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,722] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,723] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,723] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,723] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,723] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,723] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,724] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,724] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,724] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,724] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,725] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,725] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,725] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,725] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,725] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,726] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,726] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,726] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,727] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function BasicBlock.forward at 0x7f300c57da60>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,728] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,728] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:95 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,728] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,729] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:96 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,729] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             shortcut = x\n",
      "[2023-09-07 14:57:22,729] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,729] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,730] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,730] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,730] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,730] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,731] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,731] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,739] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,739] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,739] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,739] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,740] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,740] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,741] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,755] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,755] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,755] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,756] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,756] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_block [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,757] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,757] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,759] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,759] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,759] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act1(x)\n",
      "[2023-09-07 14:57:22,760] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,760] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act1 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,761] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,761] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,763] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,764] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,764] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.aa(x)\n",
      "[2023-09-07 14:57:22,764] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,764] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR aa [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,765] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,765] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,767] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,767] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,767] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,768] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,768] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR conv2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,769] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,769] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,772] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,773] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,773] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,773] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,774] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR bn2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,774] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,775] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,789] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,790] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:107 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,790] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.se is not None:\n",
      "[2023-09-07 14:57:22,790] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,790] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR se [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,791] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,791] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,792] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 94 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,792] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:110 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,792] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_path is not None:\n",
      "[2023-09-07 14:57:22,793] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,793] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_path [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,793] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,794] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,794] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 114 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,795] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:113 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,795] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.downsample is not None:\n",
      "[2023-09-07 14:57:22,795] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,795] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR downsample [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,796] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_CONST None [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,796] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE COMPARE_OP is not [ConstantVariable(NoneType), ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,797] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 134 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,797] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,797] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x += shortcut\n",
      "[2023-09-07 14:57:22,798] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,798] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST shortcut [TensorVariable()]\n",
      "[2023-09-07 14:57:22,798] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE INPLACE_ADD None [TensorVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,801] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,802] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,802] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.act2(x)\n",
      "[2023-09-07 14:57:22,802] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,802] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR act2 [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,803] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,803] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,806] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,806] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:118 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,806] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,806] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,806] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,807] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f300c5673a0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 95>\n",
      "[2023-09-07 14:57:22,807] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,808] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,808] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,809] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_features /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:532 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,809] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,809] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,809] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,810] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward_features at 0x7f300c56c0e0, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 519>\n",
      "[2023-09-07 14:57:22,810] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,810] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:542\n",
      "[2023-09-07 14:57:22,810] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.forward_head(x)\n",
      "[2023-09-07 14:57:22,811] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,811] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward_head [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,812] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [UserMethodVariable(<function ResNet.forward_head at 0x7f300c5873a0>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,812] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [UserMethodVariable(<function ResNet.forward_head at 0x7f300c5873a0>, NNModuleVariable()), TensorVariable()]\n",
      "[2023-09-07 14:57:22,813] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward_head at 0x7f300c56c190, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 534>\n",
      "[2023-09-07 14:57:22,813] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:534 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,813] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward_head(self, x, pre_logits: bool = False):\n",
      "[2023-09-07 14:57:22,814] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:535 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,814] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.global_pool(x)\n",
      "[2023-09-07 14:57:22,814] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,814] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR global_pool [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,815] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,815] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,816] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,819] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1520 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,819] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def _call_impl(self, *args, **kwargs):\n",
      "[2023-09-07 14:57:22,819] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1521 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,819] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             forward_call = (self._slow_forward if torch._C._get_tracing_state() else self.forward)\n",
      "[2023-09-07 14:57:22,820] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL torch []\n",
      "[2023-09-07 14:57:22,820] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _C [TorchVariable(<module 'torch' from '/usr/local/lib/python3.8/dist-packages/torch/__init__.py'>)]\n",
      "[2023-09-07 14:57:22,821] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _get_tracing_state [TorchVariable(<module 'torch._C' from '/usr/local/lib/python3.8/dist-packages/torch/_C.cpython-38-x86_64-linux-gnu.so'>)]\n",
      "[2023-09-07 14:57:22,821] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 0 [TorchVariable(<built-in method _get_tracing_state of PyCapsule object at 0x7f301c813b40>)]\n",
      "[2023-09-07 14:57:22,822] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 16 [ConstantVariable(NoneType)]\n",
      "[2023-09-07 14:57:22,822] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,823] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR forward [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,823] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST forward_call [UserMethodVariable(<function SelectAdaptivePool2d.forward at 0x7f3019b3fee0>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,824] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,824] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,824] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,824] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,825] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,825] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,826] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _backward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,826] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,827] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,827] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,828] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,828] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,828] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR _forward_pre_hooks [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,829] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,829] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,829] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,830] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_pre_hooks []\n",
      "[2023-09-07 14:57:22,830] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,830] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,830] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,831] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1525 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,831] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_backward_pre_hooks or _global_backward_hooks\n",
      "[2023-09-07 14:57:22,831] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_backward_hooks []\n",
      "[2023-09-07 14:57:22,831] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,831] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,832] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,832] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,832] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,832] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_hooks []\n",
      "[2023-09-07 14:57:22,833] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,833] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,833] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,833] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1526 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,833] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                     or _global_forward_hooks or _global_forward_pre_hooks):\n",
      "[2023-09-07 14:57:22,834] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_GLOBAL _global_forward_pre_hooks []\n",
      "[2023-09-07 14:57:22,834] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1524 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,834] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks\n",
      "[2023-09-07 14:57:22,834] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_TRUE 72 [ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,835] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line _call_impl /usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1527 (inline depth: 2)\n",
      "[2023-09-07 14:57:22,835] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]                 return forward_call(*args, **kwargs)\n",
      "[2023-09-07 14:57:22,835] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST forward_call []\n",
      "[2023-09-07 14:57:22,835] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST args [UserMethodVariable(<function SelectAdaptivePool2d.forward at 0x7f3019b3fee0>, NNModuleVariable())]\n",
      "[2023-09-07 14:57:22,835] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST kwargs [UserMethodVariable(<function SelectAdaptivePool2d.forward at 0x7f3019b3fee0>, NNModuleVariable()), TupleVariable()]\n",
      "[2023-09-07 14:57:22,836] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION_EX 1 [UserMethodVariable(<function SelectAdaptivePool2d.forward at 0x7f3019b3fee0>, NNModuleVariable()), TupleVariable(), ConstDictVariable()]\n",
      "[2023-09-07 14:57:22,837] [4/0] torch._dynamo.symbolic_convert: [DEBUG] INLINING <code object forward at 0x7f3019b420e0, file \"/usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py\", line 166>\n",
      "[2023-09-07 14:57:22,837] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:166 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,837] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]         def forward(self, x):\n",
      "[2023-09-07 14:57:22,838] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:167 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,838] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.pool(x)\n",
      "[2023-09-07 14:57:22,838] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,838] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR pool [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,839] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,839] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,846] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,847] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:168 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,847] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             x = self.flatten(x)\n",
      "[2023-09-07 14:57:22,847] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,847] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR flatten [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,848] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,848] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,851] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,851] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:169 (inline depth: 3)\n",
      "[2023-09-07 14:57:22,851] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,851] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,851] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,852] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward at 0x7f3019b420e0, file \"/usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py\", line 166>\n",
      "[2023-09-07 14:57:22,852] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,853] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object _call_impl at 0x7f301c375be0, file \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1520>\n",
      "[2023-09-07 14:57:22,853] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,854] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:536 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,854] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             if self.drop_rate:\n",
      "[2023-09-07 14:57:22,854] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,854] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR drop_rate [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,855] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 40 [ConstantVariable(float)]\n",
      "[2023-09-07 14:57:22,855] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward_head /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:538 (inline depth: 1)\n",
      "[2023-09-07 14:57:22,855] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x if pre_logits else self.fc(x)\n",
      "[2023-09-07 14:57:22,856] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST pre_logits []\n",
      "[2023-09-07 14:57:22,856] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE POP_JUMP_IF_FALSE 48 [ConstantVariable(bool)]\n",
      "[2023-09-07 14:57:22,856] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST self []\n",
      "[2023-09-07 14:57:22,857] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_ATTR fc [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,857] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x [NNModuleVariable()]\n",
      "[2023-09-07 14:57:22,858] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE CALL_FUNCTION 1 [NNModuleVariable(), TensorVariable()]\n",
      "[2023-09-07 14:57:22,865] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,865] [4/0] torch._dynamo.symbolic_convert: [DEBUG] DONE INLINING <code object forward_head at 0x7f300c56c190, file \"/usr/local/lib/python3.8/dist-packages/timm/models/resnet.py\", line 534>\n",
      "[2023-09-07 14:57:22,866] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE STORE_FAST x [TensorVariable()]\n",
      "[2023-09-07 14:57:22,866] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG] TRACE starts_line forward /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:543\n",
      "[2023-09-07 14:57:22,866] [4/0] torch._dynamo.symbolic_convert.__trace_source: [DEBUG]             return x\n",
      "[2023-09-07 14:57:22,866] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE LOAD_FAST x []\n",
      "[2023-09-07 14:57:22,867] [4/0] torch._dynamo.symbolic_convert: [DEBUG] TRACE RETURN_VALUE None [TensorVariable()]\n",
      "[2023-09-07 14:57:22,867] [4/0] torch._dynamo.symbolic_convert: [INFO] Step 1: torchdynamo done tracing forward (RETURN_VALUE)\n",
      "[2023-09-07 14:57:22,867] [4/0] torch._dynamo.symbolic_convert: [DEBUG] RETURN_VALUE triggered compile\n",
      "[2023-09-07 14:57:22,868] [4/0] torch._dynamo.output_graph: [DEBUG] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py, line 543 in forward>], graph_break=False)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_4 =====\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.205 class GraphModule(torch.nn.Module):\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor):\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:520, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___conv1 = self.L__self___conv1(l_x_);  l_x_ = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___bn1 = self.L__self___bn1(l__self___conv1);  l__self___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:522, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___act1 = self.L__self___act1(l__self___bn1);  l__self___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:523, code: x = self.maxpool(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___maxpool = self.L__self___maxpool(l__self___act1);  l__self___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv1 = self.getattr_L__self___layer1___0___conv1(l__self___maxpool)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn1 = self.getattr_L__self___layer1___0___bn1(getattr_l__self___layer1___0___conv1);  getattr_l__self___layer1___0___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___drop_block = self.getattr_L__self___layer1___0___drop_block(getattr_l__self___layer1___0___bn1);  getattr_l__self___layer1___0___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___act1 = self.getattr_L__self___layer1___0___act1(getattr_l__self___layer1___0___drop_block);  getattr_l__self___layer1___0___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___aa = self.getattr_L__self___layer1___0___aa(getattr_l__self___layer1___0___act1);  getattr_l__self___layer1___0___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv2 = self.getattr_L__self___layer1___0___conv2(getattr_l__self___layer1___0___aa);  getattr_l__self___layer1___0___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn2 = self.getattr_L__self___layer1___0___bn2(getattr_l__self___layer1___0___conv2);  getattr_l__self___layer1___0___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn2 += l__self___maxpool;  iadd = getattr_l__self___layer1___0___bn2;  getattr_l__self___layer1___0___bn2 = l__self___maxpool = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___act2 = self.getattr_L__self___layer1___0___act2(iadd);  iadd = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv1 = self.getattr_L__self___layer1___1___conv1(getattr_l__self___layer1___0___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn1 = self.getattr_L__self___layer1___1___bn1(getattr_l__self___layer1___1___conv1);  getattr_l__self___layer1___1___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___drop_block = self.getattr_L__self___layer1___1___drop_block(getattr_l__self___layer1___1___bn1);  getattr_l__self___layer1___1___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___act1 = self.getattr_L__self___layer1___1___act1(getattr_l__self___layer1___1___drop_block);  getattr_l__self___layer1___1___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___aa = self.getattr_L__self___layer1___1___aa(getattr_l__self___layer1___1___act1);  getattr_l__self___layer1___1___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv2 = self.getattr_L__self___layer1___1___conv2(getattr_l__self___layer1___1___aa);  getattr_l__self___layer1___1___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn2 = self.getattr_L__self___layer1___1___bn2(getattr_l__self___layer1___1___conv2);  getattr_l__self___layer1___1___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn2 += getattr_l__self___layer1___0___act2;  iadd_1 = getattr_l__self___layer1___1___bn2;  getattr_l__self___layer1___1___bn2 = getattr_l__self___layer1___0___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___act2 = self.getattr_L__self___layer1___1___act2(iadd_1);  iadd_1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv1 = self.getattr_L__self___layer2___0___conv1(getattr_l__self___layer1___1___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn1 = self.getattr_L__self___layer2___0___bn1(getattr_l__self___layer2___0___conv1);  getattr_l__self___layer2___0___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___drop_block = self.getattr_L__self___layer2___0___drop_block(getattr_l__self___layer2___0___bn1);  getattr_l__self___layer2___0___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___act1 = self.getattr_L__self___layer2___0___act1(getattr_l__self___layer2___0___drop_block);  getattr_l__self___layer2___0___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___aa = self.getattr_L__self___layer2___0___aa(getattr_l__self___layer2___0___act1);  getattr_l__self___layer2___0___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv2 = self.getattr_L__self___layer2___0___conv2(getattr_l__self___layer2___0___aa);  getattr_l__self___layer2___0___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn2 = self.getattr_L__self___layer2___0___bn2(getattr_l__self___layer2___0___conv2);  getattr_l__self___layer2___0___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___downsample_0 = self.getattr_L__self___layer2___0___downsample_0(getattr_l__self___layer1___1___act2);  getattr_l__self___layer1___1___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___downsample_1 = self.getattr_L__self___layer2___0___downsample_1(getattr_l__self___layer2___0___downsample_0);  getattr_l__self___layer2___0___downsample_0 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn2 += getattr_l__self___layer2___0___downsample_1;  iadd_2 = getattr_l__self___layer2___0___bn2;  getattr_l__self___layer2___0___bn2 = getattr_l__self___layer2___0___downsample_1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___act2 = self.getattr_L__self___layer2___0___act2(iadd_2);  iadd_2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv1 = self.getattr_L__self___layer2___1___conv1(getattr_l__self___layer2___0___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn1 = self.getattr_L__self___layer2___1___bn1(getattr_l__self___layer2___1___conv1);  getattr_l__self___layer2___1___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___drop_block = self.getattr_L__self___layer2___1___drop_block(getattr_l__self___layer2___1___bn1);  getattr_l__self___layer2___1___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___act1 = self.getattr_L__self___layer2___1___act1(getattr_l__self___layer2___1___drop_block);  getattr_l__self___layer2___1___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___aa = self.getattr_L__self___layer2___1___aa(getattr_l__self___layer2___1___act1);  getattr_l__self___layer2___1___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv2 = self.getattr_L__self___layer2___1___conv2(getattr_l__self___layer2___1___aa);  getattr_l__self___layer2___1___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn2 = self.getattr_L__self___layer2___1___bn2(getattr_l__self___layer2___1___conv2);  getattr_l__self___layer2___1___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn2 += getattr_l__self___layer2___0___act2;  iadd_3 = getattr_l__self___layer2___1___bn2;  getattr_l__self___layer2___1___bn2 = getattr_l__self___layer2___0___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___act2 = self.getattr_L__self___layer2___1___act2(iadd_3);  iadd_3 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv1 = self.getattr_L__self___layer3___0___conv1(getattr_l__self___layer2___1___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn1 = self.getattr_L__self___layer3___0___bn1(getattr_l__self___layer3___0___conv1);  getattr_l__self___layer3___0___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___drop_block = self.getattr_L__self___layer3___0___drop_block(getattr_l__self___layer3___0___bn1);  getattr_l__self___layer3___0___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___act1 = self.getattr_L__self___layer3___0___act1(getattr_l__self___layer3___0___drop_block);  getattr_l__self___layer3___0___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___aa = self.getattr_L__self___layer3___0___aa(getattr_l__self___layer3___0___act1);  getattr_l__self___layer3___0___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv2 = self.getattr_L__self___layer3___0___conv2(getattr_l__self___layer3___0___aa);  getattr_l__self___layer3___0___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn2 = self.getattr_L__self___layer3___0___bn2(getattr_l__self___layer3___0___conv2);  getattr_l__self___layer3___0___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___downsample_0 = self.getattr_L__self___layer3___0___downsample_0(getattr_l__self___layer2___1___act2);  getattr_l__self___layer2___1___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___downsample_1 = self.getattr_L__self___layer3___0___downsample_1(getattr_l__self___layer3___0___downsample_0);  getattr_l__self___layer3___0___downsample_0 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn2 += getattr_l__self___layer3___0___downsample_1;  iadd_4 = getattr_l__self___layer3___0___bn2;  getattr_l__self___layer3___0___bn2 = getattr_l__self___layer3___0___downsample_1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___act2 = self.getattr_L__self___layer3___0___act2(iadd_4);  iadd_4 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv1 = self.getattr_L__self___layer3___1___conv1(getattr_l__self___layer3___0___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn1 = self.getattr_L__self___layer3___1___bn1(getattr_l__self___layer3___1___conv1);  getattr_l__self___layer3___1___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___drop_block = self.getattr_L__self___layer3___1___drop_block(getattr_l__self___layer3___1___bn1);  getattr_l__self___layer3___1___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___act1 = self.getattr_L__self___layer3___1___act1(getattr_l__self___layer3___1___drop_block);  getattr_l__self___layer3___1___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___aa = self.getattr_L__self___layer3___1___aa(getattr_l__self___layer3___1___act1);  getattr_l__self___layer3___1___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv2 = self.getattr_L__self___layer3___1___conv2(getattr_l__self___layer3___1___aa);  getattr_l__self___layer3___1___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn2 = self.getattr_L__self___layer3___1___bn2(getattr_l__self___layer3___1___conv2);  getattr_l__self___layer3___1___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn2 += getattr_l__self___layer3___0___act2;  iadd_5 = getattr_l__self___layer3___1___bn2;  getattr_l__self___layer3___1___bn2 = getattr_l__self___layer3___0___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___act2 = self.getattr_L__self___layer3___1___act2(iadd_5);  iadd_5 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv1 = self.getattr_L__self___layer4___0___conv1(getattr_l__self___layer3___1___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn1 = self.getattr_L__self___layer4___0___bn1(getattr_l__self___layer4___0___conv1);  getattr_l__self___layer4___0___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___drop_block = self.getattr_L__self___layer4___0___drop_block(getattr_l__self___layer4___0___bn1);  getattr_l__self___layer4___0___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___act1 = self.getattr_L__self___layer4___0___act1(getattr_l__self___layer4___0___drop_block);  getattr_l__self___layer4___0___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___aa = self.getattr_L__self___layer4___0___aa(getattr_l__self___layer4___0___act1);  getattr_l__self___layer4___0___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv2 = self.getattr_L__self___layer4___0___conv2(getattr_l__self___layer4___0___aa);  getattr_l__self___layer4___0___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn2 = self.getattr_L__self___layer4___0___bn2(getattr_l__self___layer4___0___conv2);  getattr_l__self___layer4___0___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___downsample_0 = self.getattr_L__self___layer4___0___downsample_0(getattr_l__self___layer3___1___act2);  getattr_l__self___layer3___1___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___downsample_1 = self.getattr_L__self___layer4___0___downsample_1(getattr_l__self___layer4___0___downsample_0);  getattr_l__self___layer4___0___downsample_0 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn2 += getattr_l__self___layer4___0___downsample_1;  iadd_6 = getattr_l__self___layer4___0___bn2;  getattr_l__self___layer4___0___bn2 = getattr_l__self___layer4___0___downsample_1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___act2 = self.getattr_L__self___layer4___0___act2(iadd_6);  iadd_6 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv1 = self.getattr_L__self___layer4___1___conv1(getattr_l__self___layer4___0___act2)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn1 = self.getattr_L__self___layer4___1___bn1(getattr_l__self___layer4___1___conv1);  getattr_l__self___layer4___1___conv1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___drop_block = self.getattr_L__self___layer4___1___drop_block(getattr_l__self___layer4___1___bn1);  getattr_l__self___layer4___1___bn1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___act1 = self.getattr_L__self___layer4___1___act1(getattr_l__self___layer4___1___drop_block);  getattr_l__self___layer4___1___drop_block = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___aa = self.getattr_L__self___layer4___1___aa(getattr_l__self___layer4___1___act1);  getattr_l__self___layer4___1___act1 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv2 = self.getattr_L__self___layer4___1___conv2(getattr_l__self___layer4___1___aa);  getattr_l__self___layer4___1___aa = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn2 = self.getattr_L__self___layer4___1___bn2(getattr_l__self___layer4___1___conv2);  getattr_l__self___layer4___1___conv2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn2 += getattr_l__self___layer4___0___act2;  iadd_7 = getattr_l__self___layer4___1___bn2;  getattr_l__self___layer4___1___bn2 = getattr_l__self___layer4___0___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___act2 = self.getattr_L__self___layer4___1___act2(iadd_7);  iadd_7 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:167, code: x = self.pool(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___global_pool_pool = self.L__self___global_pool_pool(getattr_l__self___layer4___1___act2);  getattr_l__self___layer4___1___act2 = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:168, code: x = self.flatten(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___global_pool_flatten = self.L__self___global_pool_flatten(l__self___global_pool_pool);  l__self___global_pool_pool = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:538, code: return x if pre_logits else self.fc(x)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___fc = self.L__self___fc(l__self___global_pool_flatten);  l__self___global_pool_flatten = None\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___fc,)\n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:57:22,873] [4/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] TRACED GRAPH\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG]  __compiled_fn_4 <eval_with_key>.205 opcode         name                                         target                                       args                                                                               kwargs\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] -------------  -------------------------------------------  -------------------------------------------  ---------------------------------------------------------------------------------  --------\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] placeholder    l_x_                                         L_x_                                         ()                                                                                 {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___conv1                              L__self___conv1                              (l_x_,)                                                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___bn1                                L__self___bn1                                (l__self___conv1,)                                                                 {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___act1                               L__self___act1                               (l__self___bn1,)                                                                   {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___maxpool                            L__self___maxpool                            (l__self___act1,)                                                                  {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___conv1         getattr_L__self___layer1___0___conv1         (l__self___maxpool,)                                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___bn1           getattr_L__self___layer1___0___bn1           (getattr_l__self___layer1___0___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___drop_block    getattr_L__self___layer1___0___drop_block    (getattr_l__self___layer1___0___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___act1          getattr_L__self___layer1___0___act1          (getattr_l__self___layer1___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___aa            getattr_L__self___layer1___0___aa            (getattr_l__self___layer1___0___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___conv2         getattr_L__self___layer1___0___conv2         (getattr_l__self___layer1___0___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___bn2           getattr_L__self___layer1___0___bn2           (getattr_l__self___layer1___0___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd                                         <built-in function iadd>                     (getattr_l__self___layer1___0___bn2, l__self___maxpool)                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___0___act2          getattr_L__self___layer1___0___act2          (iadd,)                                                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___conv1         getattr_L__self___layer1___1___conv1         (getattr_l__self___layer1___0___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___bn1           getattr_L__self___layer1___1___bn1           (getattr_l__self___layer1___1___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___drop_block    getattr_L__self___layer1___1___drop_block    (getattr_l__self___layer1___1___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___act1          getattr_L__self___layer1___1___act1          (getattr_l__self___layer1___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___aa            getattr_L__self___layer1___1___aa            (getattr_l__self___layer1___1___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___conv2         getattr_L__self___layer1___1___conv2         (getattr_l__self___layer1___1___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___bn2           getattr_L__self___layer1___1___bn2           (getattr_l__self___layer1___1___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_1                                       <built-in function iadd>                     (getattr_l__self___layer1___1___bn2, getattr_l__self___layer1___0___act2)          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer1___1___act2          getattr_L__self___layer1___1___act2          (iadd_1,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___conv1         getattr_L__self___layer2___0___conv1         (getattr_l__self___layer1___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___bn1           getattr_L__self___layer2___0___bn1           (getattr_l__self___layer2___0___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___drop_block    getattr_L__self___layer2___0___drop_block    (getattr_l__self___layer2___0___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___act1          getattr_L__self___layer2___0___act1          (getattr_l__self___layer2___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___aa            getattr_L__self___layer2___0___aa            (getattr_l__self___layer2___0___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___conv2         getattr_L__self___layer2___0___conv2         (getattr_l__self___layer2___0___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___bn2           getattr_L__self___layer2___0___bn2           (getattr_l__self___layer2___0___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___downsample_0  getattr_L__self___layer2___0___downsample_0  (getattr_l__self___layer1___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___downsample_1  getattr_L__self___layer2___0___downsample_1  (getattr_l__self___layer2___0___downsample_0,)                                     {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_2                                       <built-in function iadd>                     (getattr_l__self___layer2___0___bn2, getattr_l__self___layer2___0___downsample_1)  {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___0___act2          getattr_L__self___layer2___0___act2          (iadd_2,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___conv1         getattr_L__self___layer2___1___conv1         (getattr_l__self___layer2___0___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___bn1           getattr_L__self___layer2___1___bn1           (getattr_l__self___layer2___1___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___drop_block    getattr_L__self___layer2___1___drop_block    (getattr_l__self___layer2___1___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___act1          getattr_L__self___layer2___1___act1          (getattr_l__self___layer2___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___aa            getattr_L__self___layer2___1___aa            (getattr_l__self___layer2___1___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___conv2         getattr_L__self___layer2___1___conv2         (getattr_l__self___layer2___1___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___bn2           getattr_L__self___layer2___1___bn2           (getattr_l__self___layer2___1___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_3                                       <built-in function iadd>                     (getattr_l__self___layer2___1___bn2, getattr_l__self___layer2___0___act2)          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer2___1___act2          getattr_L__self___layer2___1___act2          (iadd_3,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___conv1         getattr_L__self___layer3___0___conv1         (getattr_l__self___layer2___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___bn1           getattr_L__self___layer3___0___bn1           (getattr_l__self___layer3___0___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___drop_block    getattr_L__self___layer3___0___drop_block    (getattr_l__self___layer3___0___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___act1          getattr_L__self___layer3___0___act1          (getattr_l__self___layer3___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___aa            getattr_L__self___layer3___0___aa            (getattr_l__self___layer3___0___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___conv2         getattr_L__self___layer3___0___conv2         (getattr_l__self___layer3___0___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___bn2           getattr_L__self___layer3___0___bn2           (getattr_l__self___layer3___0___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___downsample_0  getattr_L__self___layer3___0___downsample_0  (getattr_l__self___layer2___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___downsample_1  getattr_L__self___layer3___0___downsample_1  (getattr_l__self___layer3___0___downsample_0,)                                     {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_4                                       <built-in function iadd>                     (getattr_l__self___layer3___0___bn2, getattr_l__self___layer3___0___downsample_1)  {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___0___act2          getattr_L__self___layer3___0___act2          (iadd_4,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___conv1         getattr_L__self___layer3___1___conv1         (getattr_l__self___layer3___0___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___bn1           getattr_L__self___layer3___1___bn1           (getattr_l__self___layer3___1___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___drop_block    getattr_L__self___layer3___1___drop_block    (getattr_l__self___layer3___1___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___act1          getattr_L__self___layer3___1___act1          (getattr_l__self___layer3___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___aa            getattr_L__self___layer3___1___aa            (getattr_l__self___layer3___1___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___conv2         getattr_L__self___layer3___1___conv2         (getattr_l__self___layer3___1___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___bn2           getattr_L__self___layer3___1___bn2           (getattr_l__self___layer3___1___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_5                                       <built-in function iadd>                     (getattr_l__self___layer3___1___bn2, getattr_l__self___layer3___0___act2)          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer3___1___act2          getattr_L__self___layer3___1___act2          (iadd_5,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___conv1         getattr_L__self___layer4___0___conv1         (getattr_l__self___layer3___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___bn1           getattr_L__self___layer4___0___bn1           (getattr_l__self___layer4___0___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___drop_block    getattr_L__self___layer4___0___drop_block    (getattr_l__self___layer4___0___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___act1          getattr_L__self___layer4___0___act1          (getattr_l__self___layer4___0___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___aa            getattr_L__self___layer4___0___aa            (getattr_l__self___layer4___0___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___conv2         getattr_L__self___layer4___0___conv2         (getattr_l__self___layer4___0___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___bn2           getattr_L__self___layer4___0___bn2           (getattr_l__self___layer4___0___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___downsample_0  getattr_L__self___layer4___0___downsample_0  (getattr_l__self___layer3___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___downsample_1  getattr_L__self___layer4___0___downsample_1  (getattr_l__self___layer4___0___downsample_0,)                                     {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_6                                       <built-in function iadd>                     (getattr_l__self___layer4___0___bn2, getattr_l__self___layer4___0___downsample_1)  {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___0___act2          getattr_L__self___layer4___0___act2          (iadd_6,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___conv1         getattr_L__self___layer4___1___conv1         (getattr_l__self___layer4___0___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___bn1           getattr_L__self___layer4___1___bn1           (getattr_l__self___layer4___1___conv1,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___drop_block    getattr_L__self___layer4___1___drop_block    (getattr_l__self___layer4___1___bn1,)                                              {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___act1          getattr_L__self___layer4___1___act1          (getattr_l__self___layer4___1___drop_block,)                                       {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___aa            getattr_L__self___layer4___1___aa            (getattr_l__self___layer4___1___act1,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___conv2         getattr_L__self___layer4___1___conv2         (getattr_l__self___layer4___1___aa,)                                               {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___bn2           getattr_L__self___layer4___1___bn2           (getattr_l__self___layer4___1___conv2,)                                            {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_function  iadd_7                                       <built-in function iadd>                     (getattr_l__self___layer4___1___bn2, getattr_l__self___layer4___0___act2)          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    getattr_l__self___layer4___1___act2          getattr_L__self___layer4___1___act2          (iadd_7,)                                                                          {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___global_pool_pool                   L__self___global_pool_pool                   (getattr_l__self___layer4___1___act2,)                                             {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___global_pool_flatten                L__self___global_pool_flatten                (l__self___global_pool_pool,)                                                      {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] call_module    l__self___fc                                 L__self___fc                                 (l__self___global_pool_flatten,)                                                   {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] output         output                                       output                                       ((l__self___fc,),)                                                                 {}\n",
      "[2023-09-07 14:57:22,876] [4/0] torch._dynamo.output_graph.__graph: [DEBUG] \n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] TRACED GRAPH TENSOR SIZES\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] ===== __compiled_fn_4 =====\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l_x_: (64, 3, 7, 7)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___conv1: (64, 64, 4, 4)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___bn1: (64, 64, 4, 4)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___act1: (64, 64, 4, 4)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___maxpool: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___conv1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___bn1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___drop_block: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___act1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___aa: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___conv2: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___bn2: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___0___act2: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___conv1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___bn1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___drop_block: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___act1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___aa: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___conv2: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___bn2: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_1: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer1___1___act2: (64, 64, 2, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___conv1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___bn1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___drop_block: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___act1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___aa: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___conv2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___bn2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___downsample_0: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___downsample_1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___0___act2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___conv1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___bn1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___drop_block: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___act1: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___aa: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___conv2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___bn2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_3: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer2___1___act2: (64, 128, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___conv1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___bn1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___drop_block: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___act1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___aa: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___conv2: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___bn2: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___downsample_0: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___downsample_1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_4: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___0___act2: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___conv1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___bn1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___drop_block: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___act1: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___aa: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___conv2: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___bn2: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_5: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer3___1___act2: (64, 256, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___conv1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___bn1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___drop_block: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___act1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___aa: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___conv2: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___bn2: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___downsample_0: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___downsample_1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_6: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___0___act2: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___conv1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___bn1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___drop_block: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___act1: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___aa: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___conv2: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___bn2: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] iadd_7: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] getattr_l__self___layer4___1___act2: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___global_pool_pool: (64, 512, 1, 1)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___global_pool_flatten: (64, 512)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] l__self___fc: (64, 2)\n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph.__graph_sizes: [DEBUG] \n",
      "[2023-09-07 14:57:22,883] [4/0] torch._dynamo.output_graph: [INFO] Step 2: calling compiler function inductor\n",
      "[2023-09-07 14:57:27,706] [4/0] torch._dynamo.output_graph: [INFO] Step 2: done compiler function inductor\n",
      "[2023-09-07 14:57:27,710] [4/0] torch._dynamo.guards.__guards: [DEBUG] GUARDS:\n",
      "[2023-09-07 14:57:27,711] [4/0] torch._dynamo.guards.__guards: [DEBUG] hasattr(L['x'], '_dynamo_dynamic_indices') == False           # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n",
      "[2023-09-07 14:57:27,712] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'], 139853266183168)                   # x = self.conv1(x)  # timm/models/resnet.py:520 in forward_features\n",
      "[2023-09-07 14:57:27,713] [4/0] torch._dynamo.guards.__guards: [DEBUG] L['self'].training == True                                    # x = self.conv1(x)  # timm/models/resnet.py:520 in forward_features\n",
      "[2023-09-07 14:57:27,713] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_obj_id(L['self'].forward_head.__defaults__[0], 9474016)  # return x if pre_logits else self.fc(x)  # timm/models/resnet.py:538 in forward_head\n",
      "[2023-09-07 14:57:27,714] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_grad_enabled()                                          # _dynamo/output_graph.py:345 in init_ambient_guards\n",
      "[2023-09-07 14:57:27,715] [4/0] torch._dynamo.guards.__guards: [DEBUG] not ___are_deterministic_algorithms_enabled()                 # _dynamo/output_graph.py:341 in init_ambient_guards\n",
      "[2023-09-07 14:57:27,715] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___is_torch_function_enabled()                                # _dynamo/output_graph.py:349 in init_ambient_guards\n",
      "[2023-09-07 14:57:27,716] [4/0] torch._dynamo.guards.__guards: [DEBUG] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:347 in init_ambient_guards\n",
      "[2023-09-07 14:57:27,716] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,717] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,718] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,718] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,719] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,719] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_forward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,720] [4/0] torch._dynamo.guards.__guards: [DEBUG] ___check_type_id(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks, 9468608)  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,721] [4/0] torch._dynamo.guards.__guards: [DEBUG] set(G['__import_torch_dot_nn_dot_modules_dot_module']._global_backward_pre_hooks.keys()) == set()  # if not (self._backward_hooks or self._backward_pre_hooks or self._forward_hooks or self._forward_pre_hooks  # nn/modules/module.py:1524 in _call_impl\n",
      "[2023-09-07 14:57:27,721] [4/0] torch._dynamo.guards.__guards: [DEBUG] check_tensor(L['x'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float32, device=0, requires_grad=False, size=[64, 3, 7, 7], stride=[147, 49, 7, 1])  # _dynamo/variables/builder.py:1244 in wrap_fx_proxy_cls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1540e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1752e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2430e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1028e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5335e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2623e-02],\n",
       "        [ 4.4532e-01,  7.0079e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0301e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dynamo log\n",
    "torch._logging.set_logs(dynamo=logging.DEBUG)\n",
    "torch._dynamo.reset()\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOTAutograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] TRACED GRAPH\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  ===== __compiled_fn_5 =====\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]  <eval_with_key>.220 class GraphModule(torch.nn.Module):\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]     def forward(self, L_x_ : torch.Tensor):\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l_x_ = L_x_\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:520, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___conv1 = self.L__self___conv1(l_x_);  l_x_ = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___bn1 = self.L__self___bn1(l__self___conv1);  l__self___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:522, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___act1 = self.L__self___act1(l__self___bn1);  l__self___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:523, code: x = self.maxpool(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___maxpool = self.L__self___maxpool(l__self___act1);  l__self___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv1 = self.getattr_L__self___layer1___0___conv1(l__self___maxpool)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn1 = self.getattr_L__self___layer1___0___bn1(getattr_l__self___layer1___0___conv1);  getattr_l__self___layer1___0___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___drop_block = self.getattr_L__self___layer1___0___drop_block(getattr_l__self___layer1___0___bn1);  getattr_l__self___layer1___0___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___act1 = self.getattr_L__self___layer1___0___act1(getattr_l__self___layer1___0___drop_block);  getattr_l__self___layer1___0___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___aa = self.getattr_L__self___layer1___0___aa(getattr_l__self___layer1___0___act1);  getattr_l__self___layer1___0___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___conv2 = self.getattr_L__self___layer1___0___conv2(getattr_l__self___layer1___0___aa);  getattr_l__self___layer1___0___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn2 = self.getattr_L__self___layer1___0___bn2(getattr_l__self___layer1___0___conv2);  getattr_l__self___layer1___0___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___bn2 += l__self___maxpool;  iadd = getattr_l__self___layer1___0___bn2;  getattr_l__self___layer1___0___bn2 = l__self___maxpool = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___0___act2 = self.getattr_L__self___layer1___0___act2(iadd);  iadd = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv1 = self.getattr_L__self___layer1___1___conv1(getattr_l__self___layer1___0___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn1 = self.getattr_L__self___layer1___1___bn1(getattr_l__self___layer1___1___conv1);  getattr_l__self___layer1___1___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___drop_block = self.getattr_L__self___layer1___1___drop_block(getattr_l__self___layer1___1___bn1);  getattr_l__self___layer1___1___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___act1 = self.getattr_L__self___layer1___1___act1(getattr_l__self___layer1___1___drop_block);  getattr_l__self___layer1___1___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___aa = self.getattr_L__self___layer1___1___aa(getattr_l__self___layer1___1___act1);  getattr_l__self___layer1___1___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___conv2 = self.getattr_L__self___layer1___1___conv2(getattr_l__self___layer1___1___aa);  getattr_l__self___layer1___1___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn2 = self.getattr_L__self___layer1___1___bn2(getattr_l__self___layer1___1___conv2);  getattr_l__self___layer1___1___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___bn2 += getattr_l__self___layer1___0___act2;  iadd_1 = getattr_l__self___layer1___1___bn2;  getattr_l__self___layer1___1___bn2 = getattr_l__self___layer1___0___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer1___1___act2 = self.getattr_L__self___layer1___1___act2(iadd_1);  iadd_1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv1 = self.getattr_L__self___layer2___0___conv1(getattr_l__self___layer1___1___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn1 = self.getattr_L__self___layer2___0___bn1(getattr_l__self___layer2___0___conv1);  getattr_l__self___layer2___0___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___drop_block = self.getattr_L__self___layer2___0___drop_block(getattr_l__self___layer2___0___bn1);  getattr_l__self___layer2___0___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___act1 = self.getattr_L__self___layer2___0___act1(getattr_l__self___layer2___0___drop_block);  getattr_l__self___layer2___0___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___aa = self.getattr_L__self___layer2___0___aa(getattr_l__self___layer2___0___act1);  getattr_l__self___layer2___0___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___conv2 = self.getattr_L__self___layer2___0___conv2(getattr_l__self___layer2___0___aa);  getattr_l__self___layer2___0___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn2 = self.getattr_L__self___layer2___0___bn2(getattr_l__self___layer2___0___conv2);  getattr_l__self___layer2___0___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___downsample_0 = self.getattr_L__self___layer2___0___downsample_0(getattr_l__self___layer1___1___act2);  getattr_l__self___layer1___1___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___downsample_1 = self.getattr_L__self___layer2___0___downsample_1(getattr_l__self___layer2___0___downsample_0);  getattr_l__self___layer2___0___downsample_0 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___bn2 += getattr_l__self___layer2___0___downsample_1;  iadd_2 = getattr_l__self___layer2___0___bn2;  getattr_l__self___layer2___0___bn2 = getattr_l__self___layer2___0___downsample_1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___0___act2 = self.getattr_L__self___layer2___0___act2(iadd_2);  iadd_2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv1 = self.getattr_L__self___layer2___1___conv1(getattr_l__self___layer2___0___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn1 = self.getattr_L__self___layer2___1___bn1(getattr_l__self___layer2___1___conv1);  getattr_l__self___layer2___1___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___drop_block = self.getattr_L__self___layer2___1___drop_block(getattr_l__self___layer2___1___bn1);  getattr_l__self___layer2___1___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___act1 = self.getattr_L__self___layer2___1___act1(getattr_l__self___layer2___1___drop_block);  getattr_l__self___layer2___1___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___aa = self.getattr_L__self___layer2___1___aa(getattr_l__self___layer2___1___act1);  getattr_l__self___layer2___1___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___conv2 = self.getattr_L__self___layer2___1___conv2(getattr_l__self___layer2___1___aa);  getattr_l__self___layer2___1___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn2 = self.getattr_L__self___layer2___1___bn2(getattr_l__self___layer2___1___conv2);  getattr_l__self___layer2___1___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___bn2 += getattr_l__self___layer2___0___act2;  iadd_3 = getattr_l__self___layer2___1___bn2;  getattr_l__self___layer2___1___bn2 = getattr_l__self___layer2___0___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer2___1___act2 = self.getattr_L__self___layer2___1___act2(iadd_3);  iadd_3 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv1 = self.getattr_L__self___layer3___0___conv1(getattr_l__self___layer2___1___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn1 = self.getattr_L__self___layer3___0___bn1(getattr_l__self___layer3___0___conv1);  getattr_l__self___layer3___0___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___drop_block = self.getattr_L__self___layer3___0___drop_block(getattr_l__self___layer3___0___bn1);  getattr_l__self___layer3___0___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___act1 = self.getattr_L__self___layer3___0___act1(getattr_l__self___layer3___0___drop_block);  getattr_l__self___layer3___0___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___aa = self.getattr_L__self___layer3___0___aa(getattr_l__self___layer3___0___act1);  getattr_l__self___layer3___0___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___conv2 = self.getattr_L__self___layer3___0___conv2(getattr_l__self___layer3___0___aa);  getattr_l__self___layer3___0___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn2 = self.getattr_L__self___layer3___0___bn2(getattr_l__self___layer3___0___conv2);  getattr_l__self___layer3___0___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___downsample_0 = self.getattr_L__self___layer3___0___downsample_0(getattr_l__self___layer2___1___act2);  getattr_l__self___layer2___1___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___downsample_1 = self.getattr_L__self___layer3___0___downsample_1(getattr_l__self___layer3___0___downsample_0);  getattr_l__self___layer3___0___downsample_0 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___bn2 += getattr_l__self___layer3___0___downsample_1;  iadd_4 = getattr_l__self___layer3___0___bn2;  getattr_l__self___layer3___0___bn2 = getattr_l__self___layer3___0___downsample_1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___0___act2 = self.getattr_L__self___layer3___0___act2(iadd_4);  iadd_4 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv1 = self.getattr_L__self___layer3___1___conv1(getattr_l__self___layer3___0___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn1 = self.getattr_L__self___layer3___1___bn1(getattr_l__self___layer3___1___conv1);  getattr_l__self___layer3___1___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___drop_block = self.getattr_L__self___layer3___1___drop_block(getattr_l__self___layer3___1___bn1);  getattr_l__self___layer3___1___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___act1 = self.getattr_L__self___layer3___1___act1(getattr_l__self___layer3___1___drop_block);  getattr_l__self___layer3___1___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___aa = self.getattr_L__self___layer3___1___aa(getattr_l__self___layer3___1___act1);  getattr_l__self___layer3___1___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___conv2 = self.getattr_L__self___layer3___1___conv2(getattr_l__self___layer3___1___aa);  getattr_l__self___layer3___1___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn2 = self.getattr_L__self___layer3___1___bn2(getattr_l__self___layer3___1___conv2);  getattr_l__self___layer3___1___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___bn2 += getattr_l__self___layer3___0___act2;  iadd_5 = getattr_l__self___layer3___1___bn2;  getattr_l__self___layer3___1___bn2 = getattr_l__self___layer3___0___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer3___1___act2 = self.getattr_L__self___layer3___1___act2(iadd_5);  iadd_5 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv1 = self.getattr_L__self___layer4___0___conv1(getattr_l__self___layer3___1___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn1 = self.getattr_L__self___layer4___0___bn1(getattr_l__self___layer4___0___conv1);  getattr_l__self___layer4___0___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___drop_block = self.getattr_L__self___layer4___0___drop_block(getattr_l__self___layer4___0___bn1);  getattr_l__self___layer4___0___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___act1 = self.getattr_L__self___layer4___0___act1(getattr_l__self___layer4___0___drop_block);  getattr_l__self___layer4___0___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___aa = self.getattr_L__self___layer4___0___aa(getattr_l__self___layer4___0___act1);  getattr_l__self___layer4___0___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___conv2 = self.getattr_L__self___layer4___0___conv2(getattr_l__self___layer4___0___aa);  getattr_l__self___layer4___0___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn2 = self.getattr_L__self___layer4___0___bn2(getattr_l__self___layer4___0___conv2);  getattr_l__self___layer4___0___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___downsample_0 = self.getattr_L__self___layer4___0___downsample_0(getattr_l__self___layer3___1___act2);  getattr_l__self___layer3___1___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___downsample_1 = self.getattr_L__self___layer4___0___downsample_1(getattr_l__self___layer4___0___downsample_0);  getattr_l__self___layer4___0___downsample_0 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___bn2 += getattr_l__self___layer4___0___downsample_1;  iadd_6 = getattr_l__self___layer4___0___bn2;  getattr_l__self___layer4___0___bn2 = getattr_l__self___layer4___0___downsample_1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___0___act2 = self.getattr_L__self___layer4___0___act2(iadd_6);  iadd_6 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv1 = self.getattr_L__self___layer4___1___conv1(getattr_l__self___layer4___0___act2)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn1 = self.getattr_L__self___layer4___1___bn1(getattr_l__self___layer4___1___conv1);  getattr_l__self___layer4___1___conv1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:100, code: x = self.drop_block(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___drop_block = self.getattr_L__self___layer4___1___drop_block(getattr_l__self___layer4___1___bn1);  getattr_l__self___layer4___1___bn1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___act1 = self.getattr_L__self___layer4___1___act1(getattr_l__self___layer4___1___drop_block);  getattr_l__self___layer4___1___drop_block = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:102, code: x = self.aa(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___aa = self.getattr_L__self___layer4___1___aa(getattr_l__self___layer4___1___act1);  getattr_l__self___layer4___1___act1 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___conv2 = self.getattr_L__self___layer4___1___conv2(getattr_l__self___layer4___1___aa);  getattr_l__self___layer4___1___aa = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn2 = self.getattr_L__self___layer4___1___bn2(getattr_l__self___layer4___1___conv2);  getattr_l__self___layer4___1___conv2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___bn2 += getattr_l__self___layer4___0___act2;  iadd_7 = getattr_l__self___layer4___1___bn2;  getattr_l__self___layer4___1___bn2 = getattr_l__self___layer4___0___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         getattr_l__self___layer4___1___act2 = self.getattr_L__self___layer4___1___act2(iadd_7);  iadd_7 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:167, code: x = self.pool(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___global_pool_pool = self.L__self___global_pool_pool(getattr_l__self___layer4___1___act2);  getattr_l__self___layer4___1___act2 = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:168, code: x = self.flatten(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___global_pool_flatten = self.L__self___global_pool_flatten(l__self___global_pool_pool);  l__self___global_pool_pool = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:538, code: return x if pre_logits else self.fc(x)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         l__self___fc = self.L__self___fc(l__self___global_pool_flatten);  l__self___global_pool_flatten = None\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         return (l__self___fc,)\n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG]         \n",
      "[2023-09-07 14:58:47,082] [5/0] torch._dynamo.output_graph.__graph_code: [DEBUG] \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] TRACED GRAPH\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  ===== Forward graph 23 =====\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  <eval_with_key>.232 class GraphModule(torch.nn.Module):\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]     def forward(self, primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_3: f32[64], primals_4: f32[64, 64, 3, 3], primals_5: f32[64], primals_6: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_9: f32[64], primals_10: f32[64, 64, 3, 3], primals_11: f32[64], primals_12: f32[64], primals_13: f32[64, 64, 3, 3], primals_14: f32[64], primals_15: f32[64], primals_16: f32[128, 64, 3, 3], primals_17: f32[128], primals_18: f32[128], primals_19: f32[128, 128, 3, 3], primals_20: f32[128], primals_21: f32[128], primals_22: f32[128, 64, 1, 1], primals_23: f32[128], primals_24: f32[128], primals_25: f32[128, 128, 3, 3], primals_26: f32[128], primals_27: f32[128], primals_28: f32[128, 128, 3, 3], primals_29: f32[128], primals_30: f32[128], primals_31: f32[256, 128, 3, 3], primals_32: f32[256], primals_33: f32[256], primals_34: f32[256, 256, 3, 3], primals_35: f32[256], primals_36: f32[256], primals_37: f32[256, 128, 1, 1], primals_38: f32[256], primals_39: f32[256], primals_40: f32[256, 256, 3, 3], primals_41: f32[256], primals_42: f32[256], primals_43: f32[256, 256, 3, 3], primals_44: f32[256], primals_45: f32[256], primals_46: f32[512, 256, 3, 3], primals_47: f32[512], primals_48: f32[512], primals_49: f32[512, 512, 3, 3], primals_50: f32[512], primals_51: f32[512], primals_52: f32[512, 256, 1, 1], primals_53: f32[512], primals_54: f32[512], primals_55: f32[512, 512, 3, 3], primals_56: f32[512], primals_57: f32[512], primals_58: f32[512, 512, 3, 3], primals_59: f32[512], primals_60: f32[512], primals_61: f32[2, 512], primals_62: f32[2], primals_63: f32[64], primals_64: f32[64], primals_65: i64[], primals_66: f32[64], primals_67: f32[64], primals_68: i64[], primals_69: f32[64], primals_70: f32[64], primals_71: i64[], primals_72: f32[64], primals_73: f32[64], primals_74: i64[], primals_75: f32[64], primals_76: f32[64], primals_77: i64[], primals_78: f32[128], primals_79: f32[128], primals_80: i64[], primals_81: f32[128], primals_82: f32[128], primals_83: i64[], primals_84: f32[128], primals_85: f32[128], primals_86: i64[], primals_87: f32[128], primals_88: f32[128], primals_89: i64[], primals_90: f32[128], primals_91: f32[128], primals_92: i64[], primals_93: f32[256], primals_94: f32[256], primals_95: i64[], primals_96: f32[256], primals_97: f32[256], primals_98: i64[], primals_99: f32[256], primals_100: f32[256], primals_101: i64[], primals_102: f32[256], primals_103: f32[256], primals_104: i64[], primals_105: f32[256], primals_106: f32[256], primals_107: i64[], primals_108: f32[512], primals_109: f32[512], primals_110: i64[], primals_111: f32[512], primals_112: f32[512], primals_113: i64[], primals_114: f32[512], primals_115: f32[512], primals_116: i64[], primals_117: f32[512], primals_118: f32[512], primals_119: i64[], primals_120: f32[512], primals_121: f32[512], primals_122: i64[], primals_123: f32[64, 3, 7, 7]):\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:520, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution: f32[64, 64, 4, 4] = torch.ops.aten.convolution.default(primals_123, primals_1, None, [2, 2], [3, 3], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add: i64[] = torch.ops.aten.add.Tensor(primals_65, 1);  primals_65 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean = torch.ops.aten.var_mean.correction(convolution, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem: f32[1, 64, 1, 1] = var_mean[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_1: f32[1, 64, 1, 1] = var_mean[1];  var_mean = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_1: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_1);  add_1 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub: f32[64, 64, 4, 4] = torch.ops.aten.sub.Tensor(convolution, getitem_1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul: f32[64, 64, 4, 4] = torch.ops.aten.mul.Tensor(sub, rsqrt);  sub = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze: f32[64] = torch.ops.aten.squeeze.dims(getitem_1, [0, 2, 3]);  getitem_1 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_1: f32[64] = torch.ops.aten.squeeze.dims(rsqrt, [0, 2, 3]);  rsqrt = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_1: f32[64] = torch.ops.aten.mul.Tensor(squeeze, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_2: f32[64] = torch.ops.aten.mul.Tensor(primals_63, 0.9);  primals_63 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_2: f32[64] = torch.ops.aten.add.Tensor(mul_1, mul_2);  mul_1 = mul_2 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_2: f32[64] = torch.ops.aten.squeeze.dims(getitem, [0, 2, 3]);  getitem = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_3: f32[64] = torch.ops.aten.mul.Tensor(squeeze_2, 1.0009775171065494);  squeeze_2 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_4: f32[64] = torch.ops.aten.mul.Tensor(mul_3, 0.1);  mul_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_5: f32[64] = torch.ops.aten.mul.Tensor(primals_64, 0.9);  primals_64 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_3: f32[64] = torch.ops.aten.add.Tensor(mul_4, mul_5);  mul_4 = mul_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_2, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_1: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze, -1);  unsqueeze = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_6: f32[64, 64, 4, 4] = torch.ops.aten.mul.Tensor(mul, unsqueeze_1);  mul = unsqueeze_1 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_2: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_3, -1);  primals_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_3: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_2, -1);  unsqueeze_2 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_4: f32[64, 64, 4, 4] = torch.ops.aten.add.Tensor(mul_6, unsqueeze_3);  mul_6 = unsqueeze_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:522, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu: f32[64, 64, 4, 4] = torch.ops.aten.relu.default(add_4);  add_4 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:523, code: x = self.maxpool(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         max_pool2d_with_indices = torch.ops.aten.max_pool2d_with_indices.default(relu, [3, 3], [2, 2], [1, 1])\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_2: f32[64, 64, 2, 2] = max_pool2d_with_indices[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_3: i64[64, 64, 2, 2] = max_pool2d_with_indices[1];  max_pool2d_with_indices = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_1: f32[64, 64, 2, 2] = torch.ops.aten.convolution.default(getitem_2, primals_4, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_5: i64[] = torch.ops.aten.add.Tensor(primals_68, 1);  primals_68 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_1 = torch.ops.aten.var_mean.correction(convolution_1, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_4: f32[1, 64, 1, 1] = var_mean_1[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_5: f32[1, 64, 1, 1] = var_mean_1[1];  var_mean_1 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_6: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_4, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_1: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_6);  add_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_1: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_1, getitem_5)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_7: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_1, rsqrt_1);  sub_1 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_3: f32[64] = torch.ops.aten.squeeze.dims(getitem_5, [0, 2, 3]);  getitem_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_4: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_1, [0, 2, 3]);  rsqrt_1 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_8: f32[64] = torch.ops.aten.mul.Tensor(squeeze_3, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_9: f32[64] = torch.ops.aten.mul.Tensor(primals_66, 0.9);  primals_66 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_7: f32[64] = torch.ops.aten.add.Tensor(mul_8, mul_9);  mul_8 = mul_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_5: f32[64] = torch.ops.aten.squeeze.dims(getitem_4, [0, 2, 3]);  getitem_4 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_10: f32[64] = torch.ops.aten.mul.Tensor(squeeze_5, 1.003921568627451);  squeeze_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_11: f32[64] = torch.ops.aten.mul.Tensor(mul_10, 0.1);  mul_10 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_12: f32[64] = torch.ops.aten.mul.Tensor(primals_67, 0.9);  primals_67 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_8: f32[64] = torch.ops.aten.add.Tensor(mul_11, mul_12);  mul_11 = mul_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_4: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_5, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_5: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_4, -1);  unsqueeze_4 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_13: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(mul_7, unsqueeze_5);  mul_7 = unsqueeze_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_6: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_6, -1);  primals_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_7: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_6, -1);  unsqueeze_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_9: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(mul_13, unsqueeze_7);  mul_13 = unsqueeze_7 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_1: f32[64, 64, 2, 2] = torch.ops.aten.relu.default(add_9);  add_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_2: f32[64, 64, 2, 2] = torch.ops.aten.convolution.default(relu_1, primals_7, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_10: i64[] = torch.ops.aten.add.Tensor(primals_71, 1);  primals_71 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_2 = torch.ops.aten.var_mean.correction(convolution_2, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_6: f32[1, 64, 1, 1] = var_mean_2[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_7: f32[1, 64, 1, 1] = var_mean_2[1];  var_mean_2 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_11: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_6, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_2: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_11);  add_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_2: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_2, getitem_7)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_14: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_2, rsqrt_2);  sub_2 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_6: f32[64] = torch.ops.aten.squeeze.dims(getitem_7, [0, 2, 3]);  getitem_7 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_7: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_2, [0, 2, 3]);  rsqrt_2 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_15: f32[64] = torch.ops.aten.mul.Tensor(squeeze_6, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_16: f32[64] = torch.ops.aten.mul.Tensor(primals_69, 0.9);  primals_69 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_12: f32[64] = torch.ops.aten.add.Tensor(mul_15, mul_16);  mul_15 = mul_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_8: f32[64] = torch.ops.aten.squeeze.dims(getitem_6, [0, 2, 3]);  getitem_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_17: f32[64] = torch.ops.aten.mul.Tensor(squeeze_8, 1.003921568627451);  squeeze_8 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_18: f32[64] = torch.ops.aten.mul.Tensor(mul_17, 0.1);  mul_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_19: f32[64] = torch.ops.aten.mul.Tensor(primals_70, 0.9);  primals_70 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_13: f32[64] = torch.ops.aten.add.Tensor(mul_18, mul_19);  mul_18 = mul_19 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_8: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_8, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_9: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_8, -1);  unsqueeze_8 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_20: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(mul_14, unsqueeze_9);  mul_14 = unsqueeze_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_10: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_9, -1);  primals_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_11: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_10, -1);  unsqueeze_10 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_14: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(mul_20, unsqueeze_11);  mul_20 = unsqueeze_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_15: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(add_14, getitem_2);  add_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_2: f32[64, 64, 2, 2] = torch.ops.aten.relu.default(add_15);  add_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_3: f32[64, 64, 2, 2] = torch.ops.aten.convolution.default(relu_2, primals_10, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_16: i64[] = torch.ops.aten.add.Tensor(primals_74, 1);  primals_74 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_3 = torch.ops.aten.var_mean.correction(convolution_3, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_8: f32[1, 64, 1, 1] = var_mean_3[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_9: f32[1, 64, 1, 1] = var_mean_3[1];  var_mean_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_17: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_8, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_3: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_17);  add_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_3: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_3, getitem_9)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_21: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_3, rsqrt_3);  sub_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_9: f32[64] = torch.ops.aten.squeeze.dims(getitem_9, [0, 2, 3]);  getitem_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_10: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_3, [0, 2, 3]);  rsqrt_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_22: f32[64] = torch.ops.aten.mul.Tensor(squeeze_9, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_23: f32[64] = torch.ops.aten.mul.Tensor(primals_72, 0.9);  primals_72 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_18: f32[64] = torch.ops.aten.add.Tensor(mul_22, mul_23);  mul_22 = mul_23 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_11: f32[64] = torch.ops.aten.squeeze.dims(getitem_8, [0, 2, 3]);  getitem_8 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_24: f32[64] = torch.ops.aten.mul.Tensor(squeeze_11, 1.003921568627451);  squeeze_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_25: f32[64] = torch.ops.aten.mul.Tensor(mul_24, 0.1);  mul_24 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_26: f32[64] = torch.ops.aten.mul.Tensor(primals_73, 0.9);  primals_73 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_19: f32[64] = torch.ops.aten.add.Tensor(mul_25, mul_26);  mul_25 = mul_26 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_12: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_11, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_13: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_12, -1);  unsqueeze_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_27: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(mul_21, unsqueeze_13);  mul_21 = unsqueeze_13 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_14: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_12, -1);  primals_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_15: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_14, -1);  unsqueeze_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_20: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(mul_27, unsqueeze_15);  mul_27 = unsqueeze_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_3: f32[64, 64, 2, 2] = torch.ops.aten.relu.default(add_20);  add_20 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_4: f32[64, 64, 2, 2] = torch.ops.aten.convolution.default(relu_3, primals_13, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_21: i64[] = torch.ops.aten.add.Tensor(primals_77, 1);  primals_77 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_4 = torch.ops.aten.var_mean.correction(convolution_4, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_10: f32[1, 64, 1, 1] = var_mean_4[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_11: f32[1, 64, 1, 1] = var_mean_4[1];  var_mean_4 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_22: f32[1, 64, 1, 1] = torch.ops.aten.add.Tensor(getitem_10, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_4: f32[1, 64, 1, 1] = torch.ops.aten.rsqrt.default(add_22);  add_22 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_4: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_4, getitem_11)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_28: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_4, rsqrt_4);  sub_4 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_12: f32[64] = torch.ops.aten.squeeze.dims(getitem_11, [0, 2, 3]);  getitem_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_13: f32[64] = torch.ops.aten.squeeze.dims(rsqrt_4, [0, 2, 3]);  rsqrt_4 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_29: f32[64] = torch.ops.aten.mul.Tensor(squeeze_12, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_30: f32[64] = torch.ops.aten.mul.Tensor(primals_75, 0.9);  primals_75 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_23: f32[64] = torch.ops.aten.add.Tensor(mul_29, mul_30);  mul_29 = mul_30 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_14: f32[64] = torch.ops.aten.squeeze.dims(getitem_10, [0, 2, 3]);  getitem_10 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_31: f32[64] = torch.ops.aten.mul.Tensor(squeeze_14, 1.003921568627451);  squeeze_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_32: f32[64] = torch.ops.aten.mul.Tensor(mul_31, 0.1);  mul_31 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_33: f32[64] = torch.ops.aten.mul.Tensor(primals_76, 0.9);  primals_76 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_24: f32[64] = torch.ops.aten.add.Tensor(mul_32, mul_33);  mul_32 = mul_33 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_16: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_14, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_17: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_16, -1);  unsqueeze_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_34: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(mul_28, unsqueeze_17);  mul_28 = unsqueeze_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_18: f32[64, 1] = torch.ops.aten.unsqueeze.default(primals_15, -1);  primals_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_19: f32[64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_18, -1);  unsqueeze_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_25: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(mul_34, unsqueeze_19);  mul_34 = unsqueeze_19 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_26: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(add_25, relu_2);  add_25 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_4: f32[64, 64, 2, 2] = torch.ops.aten.relu.default(add_26);  add_26 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_5: f32[64, 128, 1, 1] = torch.ops.aten.convolution.default(relu_4, primals_16, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_27: i64[] = torch.ops.aten.add.Tensor(primals_80, 1);  primals_80 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_5 = torch.ops.aten.var_mean.correction(convolution_5, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_12: f32[1, 128, 1, 1] = var_mean_5[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_13: f32[1, 128, 1, 1] = var_mean_5[1];  var_mean_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_28: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_12, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_5: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_28);  add_28 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_5: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_5, getitem_13)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_35: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_5, rsqrt_5);  sub_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_15: f32[128] = torch.ops.aten.squeeze.dims(getitem_13, [0, 2, 3]);  getitem_13 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_16: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_5, [0, 2, 3]);  rsqrt_5 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_36: f32[128] = torch.ops.aten.mul.Tensor(squeeze_15, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_37: f32[128] = torch.ops.aten.mul.Tensor(primals_78, 0.9);  primals_78 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_29: f32[128] = torch.ops.aten.add.Tensor(mul_36, mul_37);  mul_36 = mul_37 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_17: f32[128] = torch.ops.aten.squeeze.dims(getitem_12, [0, 2, 3]);  getitem_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_38: f32[128] = torch.ops.aten.mul.Tensor(squeeze_17, 1.0158730158730158);  squeeze_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_39: f32[128] = torch.ops.aten.mul.Tensor(mul_38, 0.1);  mul_38 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_40: f32[128] = torch.ops.aten.mul.Tensor(primals_79, 0.9);  primals_79 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_30: f32[128] = torch.ops.aten.add.Tensor(mul_39, mul_40);  mul_39 = mul_40 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_20: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_17, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_21: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_20, -1);  unsqueeze_20 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_41: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(mul_35, unsqueeze_21);  mul_35 = unsqueeze_21 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_22: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_18, -1);  primals_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_23: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_22, -1);  unsqueeze_22 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_31: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(mul_41, unsqueeze_23);  mul_41 = unsqueeze_23 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_5: f32[64, 128, 1, 1] = torch.ops.aten.relu.default(add_31);  add_31 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_6: f32[64, 128, 1, 1] = torch.ops.aten.convolution.default(relu_5, primals_19, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_32: i64[] = torch.ops.aten.add.Tensor(primals_83, 1);  primals_83 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_6 = torch.ops.aten.var_mean.correction(convolution_6, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_14: f32[1, 128, 1, 1] = var_mean_6[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_15: f32[1, 128, 1, 1] = var_mean_6[1];  var_mean_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_33: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_14, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_6: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_33);  add_33 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_6: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_6, getitem_15)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_42: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_6, rsqrt_6);  sub_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_18: f32[128] = torch.ops.aten.squeeze.dims(getitem_15, [0, 2, 3]);  getitem_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_19: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_6, [0, 2, 3]);  rsqrt_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_43: f32[128] = torch.ops.aten.mul.Tensor(squeeze_18, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_44: f32[128] = torch.ops.aten.mul.Tensor(primals_81, 0.9);  primals_81 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_34: f32[128] = torch.ops.aten.add.Tensor(mul_43, mul_44);  mul_43 = mul_44 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_20: f32[128] = torch.ops.aten.squeeze.dims(getitem_14, [0, 2, 3]);  getitem_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_45: f32[128] = torch.ops.aten.mul.Tensor(squeeze_20, 1.0158730158730158);  squeeze_20 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_46: f32[128] = torch.ops.aten.mul.Tensor(mul_45, 0.1);  mul_45 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_47: f32[128] = torch.ops.aten.mul.Tensor(primals_82, 0.9);  primals_82 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_35: f32[128] = torch.ops.aten.add.Tensor(mul_46, mul_47);  mul_46 = mul_47 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_24: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_20, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_25: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_24, -1);  unsqueeze_24 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_48: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(mul_42, unsqueeze_25);  mul_42 = unsqueeze_25 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_26: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_21, -1);  primals_21 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_27: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_26, -1);  unsqueeze_26 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_36: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(mul_48, unsqueeze_27);  mul_48 = unsqueeze_27 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_7: f32[64, 128, 1, 1] = torch.ops.aten.convolution.default(relu_4, primals_22, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_37: i64[] = torch.ops.aten.add.Tensor(primals_86, 1);  primals_86 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_7 = torch.ops.aten.var_mean.correction(convolution_7, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_16: f32[1, 128, 1, 1] = var_mean_7[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_17: f32[1, 128, 1, 1] = var_mean_7[1];  var_mean_7 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_38: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_16, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_7: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_38);  add_38 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_7: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_7, getitem_17)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_49: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_7, rsqrt_7);  sub_7 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_21: f32[128] = torch.ops.aten.squeeze.dims(getitem_17, [0, 2, 3]);  getitem_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_22: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_7, [0, 2, 3]);  rsqrt_7 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_50: f32[128] = torch.ops.aten.mul.Tensor(squeeze_21, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_51: f32[128] = torch.ops.aten.mul.Tensor(primals_84, 0.9);  primals_84 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_39: f32[128] = torch.ops.aten.add.Tensor(mul_50, mul_51);  mul_50 = mul_51 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_23: f32[128] = torch.ops.aten.squeeze.dims(getitem_16, [0, 2, 3]);  getitem_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_52: f32[128] = torch.ops.aten.mul.Tensor(squeeze_23, 1.0158730158730158);  squeeze_23 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_53: f32[128] = torch.ops.aten.mul.Tensor(mul_52, 0.1);  mul_52 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_54: f32[128] = torch.ops.aten.mul.Tensor(primals_85, 0.9);  primals_85 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_40: f32[128] = torch.ops.aten.add.Tensor(mul_53, mul_54);  mul_53 = mul_54 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_28: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_23, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_29: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_28, -1);  unsqueeze_28 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_55: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(mul_49, unsqueeze_29);  mul_49 = unsqueeze_29 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_30: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_24, -1);  primals_24 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_31: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_30, -1);  unsqueeze_30 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_41: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(mul_55, unsqueeze_31);  mul_55 = unsqueeze_31 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_42: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(add_36, add_41);  add_36 = add_41 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_6: f32[64, 128, 1, 1] = torch.ops.aten.relu.default(add_42);  add_42 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_8: f32[64, 128, 1, 1] = torch.ops.aten.convolution.default(relu_6, primals_25, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_43: i64[] = torch.ops.aten.add.Tensor(primals_89, 1);  primals_89 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_8 = torch.ops.aten.var_mean.correction(convolution_8, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_18: f32[1, 128, 1, 1] = var_mean_8[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_19: f32[1, 128, 1, 1] = var_mean_8[1];  var_mean_8 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_44: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_18, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_8: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_44);  add_44 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_8: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_8, getitem_19)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_56: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_8, rsqrt_8);  sub_8 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_24: f32[128] = torch.ops.aten.squeeze.dims(getitem_19, [0, 2, 3]);  getitem_19 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_25: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_8, [0, 2, 3]);  rsqrt_8 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_57: f32[128] = torch.ops.aten.mul.Tensor(squeeze_24, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_58: f32[128] = torch.ops.aten.mul.Tensor(primals_87, 0.9);  primals_87 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_45: f32[128] = torch.ops.aten.add.Tensor(mul_57, mul_58);  mul_57 = mul_58 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_26: f32[128] = torch.ops.aten.squeeze.dims(getitem_18, [0, 2, 3]);  getitem_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_59: f32[128] = torch.ops.aten.mul.Tensor(squeeze_26, 1.0158730158730158);  squeeze_26 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_60: f32[128] = torch.ops.aten.mul.Tensor(mul_59, 0.1);  mul_59 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_61: f32[128] = torch.ops.aten.mul.Tensor(primals_88, 0.9);  primals_88 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_46: f32[128] = torch.ops.aten.add.Tensor(mul_60, mul_61);  mul_60 = mul_61 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_32: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_26, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_33: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_32, -1);  unsqueeze_32 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_62: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(mul_56, unsqueeze_33);  mul_56 = unsqueeze_33 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_34: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_27, -1);  primals_27 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_35: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_34, -1);  unsqueeze_34 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_47: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(mul_62, unsqueeze_35);  mul_62 = unsqueeze_35 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_7: f32[64, 128, 1, 1] = torch.ops.aten.relu.default(add_47);  add_47 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_9: f32[64, 128, 1, 1] = torch.ops.aten.convolution.default(relu_7, primals_28, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_48: i64[] = torch.ops.aten.add.Tensor(primals_92, 1);  primals_92 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_9 = torch.ops.aten.var_mean.correction(convolution_9, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_20: f32[1, 128, 1, 1] = var_mean_9[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_21: f32[1, 128, 1, 1] = var_mean_9[1];  var_mean_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_49: f32[1, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_20, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_9: f32[1, 128, 1, 1] = torch.ops.aten.rsqrt.default(add_49);  add_49 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_9: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_9, getitem_21)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_63: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_9, rsqrt_9);  sub_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_27: f32[128] = torch.ops.aten.squeeze.dims(getitem_21, [0, 2, 3]);  getitem_21 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_28: f32[128] = torch.ops.aten.squeeze.dims(rsqrt_9, [0, 2, 3]);  rsqrt_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_64: f32[128] = torch.ops.aten.mul.Tensor(squeeze_27, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_65: f32[128] = torch.ops.aten.mul.Tensor(primals_90, 0.9);  primals_90 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_50: f32[128] = torch.ops.aten.add.Tensor(mul_64, mul_65);  mul_64 = mul_65 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_29: f32[128] = torch.ops.aten.squeeze.dims(getitem_20, [0, 2, 3]);  getitem_20 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_66: f32[128] = torch.ops.aten.mul.Tensor(squeeze_29, 1.0158730158730158);  squeeze_29 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_67: f32[128] = torch.ops.aten.mul.Tensor(mul_66, 0.1);  mul_66 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_68: f32[128] = torch.ops.aten.mul.Tensor(primals_91, 0.9);  primals_91 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_51: f32[128] = torch.ops.aten.add.Tensor(mul_67, mul_68);  mul_67 = mul_68 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_36: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_29, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_37: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_36, -1);  unsqueeze_36 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_69: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(mul_63, unsqueeze_37);  mul_63 = unsqueeze_37 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_38: f32[128, 1] = torch.ops.aten.unsqueeze.default(primals_30, -1);  primals_30 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_39: f32[128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_38, -1);  unsqueeze_38 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_52: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(mul_69, unsqueeze_39);  mul_69 = unsqueeze_39 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_53: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(add_52, relu_6);  add_52 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_8: f32[64, 128, 1, 1] = torch.ops.aten.relu.default(add_53);  add_53 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_10: f32[64, 256, 1, 1] = torch.ops.aten.convolution.default(relu_8, primals_31, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_54: i64[] = torch.ops.aten.add.Tensor(primals_95, 1);  primals_95 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_10 = torch.ops.aten.var_mean.correction(convolution_10, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_22: f32[1, 256, 1, 1] = var_mean_10[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_23: f32[1, 256, 1, 1] = var_mean_10[1];  var_mean_10 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_55: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_22, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_10: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_55);  add_55 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_10: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_10, getitem_23)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_70: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_10, rsqrt_10);  sub_10 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_30: f32[256] = torch.ops.aten.squeeze.dims(getitem_23, [0, 2, 3]);  getitem_23 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_31: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_10, [0, 2, 3]);  rsqrt_10 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_71: f32[256] = torch.ops.aten.mul.Tensor(squeeze_30, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_72: f32[256] = torch.ops.aten.mul.Tensor(primals_93, 0.9);  primals_93 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_56: f32[256] = torch.ops.aten.add.Tensor(mul_71, mul_72);  mul_71 = mul_72 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_32: f32[256] = torch.ops.aten.squeeze.dims(getitem_22, [0, 2, 3]);  getitem_22 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_73: f32[256] = torch.ops.aten.mul.Tensor(squeeze_32, 1.0158730158730158);  squeeze_32 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_74: f32[256] = torch.ops.aten.mul.Tensor(mul_73, 0.1);  mul_73 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_75: f32[256] = torch.ops.aten.mul.Tensor(primals_94, 0.9);  primals_94 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_57: f32[256] = torch.ops.aten.add.Tensor(mul_74, mul_75);  mul_74 = mul_75 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_40: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_32, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_41: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_40, -1);  unsqueeze_40 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_76: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(mul_70, unsqueeze_41);  mul_70 = unsqueeze_41 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_42: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_33, -1);  primals_33 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_43: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_42, -1);  unsqueeze_42 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_58: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(mul_76, unsqueeze_43);  mul_76 = unsqueeze_43 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_9: f32[64, 256, 1, 1] = torch.ops.aten.relu.default(add_58);  add_58 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_11: f32[64, 256, 1, 1] = torch.ops.aten.convolution.default(relu_9, primals_34, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_59: i64[] = torch.ops.aten.add.Tensor(primals_98, 1);  primals_98 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_11 = torch.ops.aten.var_mean.correction(convolution_11, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_24: f32[1, 256, 1, 1] = var_mean_11[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_25: f32[1, 256, 1, 1] = var_mean_11[1];  var_mean_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_60: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_24, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_11: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_60);  add_60 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_11: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_11, getitem_25)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_77: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_11, rsqrt_11);  sub_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_33: f32[256] = torch.ops.aten.squeeze.dims(getitem_25, [0, 2, 3]);  getitem_25 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_34: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_11, [0, 2, 3]);  rsqrt_11 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_78: f32[256] = torch.ops.aten.mul.Tensor(squeeze_33, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_79: f32[256] = torch.ops.aten.mul.Tensor(primals_96, 0.9);  primals_96 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_61: f32[256] = torch.ops.aten.add.Tensor(mul_78, mul_79);  mul_78 = mul_79 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_35: f32[256] = torch.ops.aten.squeeze.dims(getitem_24, [0, 2, 3]);  getitem_24 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_80: f32[256] = torch.ops.aten.mul.Tensor(squeeze_35, 1.0158730158730158);  squeeze_35 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_81: f32[256] = torch.ops.aten.mul.Tensor(mul_80, 0.1);  mul_80 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_82: f32[256] = torch.ops.aten.mul.Tensor(primals_97, 0.9);  primals_97 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_62: f32[256] = torch.ops.aten.add.Tensor(mul_81, mul_82);  mul_81 = mul_82 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_44: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_35, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_45: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_44, -1);  unsqueeze_44 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_83: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(mul_77, unsqueeze_45);  mul_77 = unsqueeze_45 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_46: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_36, -1);  primals_36 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_47: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_46, -1);  unsqueeze_46 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_63: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(mul_83, unsqueeze_47);  mul_83 = unsqueeze_47 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_12: f32[64, 256, 1, 1] = torch.ops.aten.convolution.default(relu_8, primals_37, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_64: i64[] = torch.ops.aten.add.Tensor(primals_101, 1);  primals_101 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_12 = torch.ops.aten.var_mean.correction(convolution_12, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_26: f32[1, 256, 1, 1] = var_mean_12[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_27: f32[1, 256, 1, 1] = var_mean_12[1];  var_mean_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_65: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_26, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_12: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_65);  add_65 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_12: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_12, getitem_27)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_84: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_12, rsqrt_12);  sub_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_36: f32[256] = torch.ops.aten.squeeze.dims(getitem_27, [0, 2, 3]);  getitem_27 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_37: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_12, [0, 2, 3]);  rsqrt_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_85: f32[256] = torch.ops.aten.mul.Tensor(squeeze_36, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_86: f32[256] = torch.ops.aten.mul.Tensor(primals_99, 0.9);  primals_99 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_66: f32[256] = torch.ops.aten.add.Tensor(mul_85, mul_86);  mul_85 = mul_86 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_38: f32[256] = torch.ops.aten.squeeze.dims(getitem_26, [0, 2, 3]);  getitem_26 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_87: f32[256] = torch.ops.aten.mul.Tensor(squeeze_38, 1.0158730158730158);  squeeze_38 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_88: f32[256] = torch.ops.aten.mul.Tensor(mul_87, 0.1);  mul_87 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_89: f32[256] = torch.ops.aten.mul.Tensor(primals_100, 0.9);  primals_100 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_67: f32[256] = torch.ops.aten.add.Tensor(mul_88, mul_89);  mul_88 = mul_89 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_48: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_38, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_49: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_48, -1);  unsqueeze_48 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_90: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(mul_84, unsqueeze_49);  mul_84 = unsqueeze_49 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_50: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_39, -1);  primals_39 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_51: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_50, -1);  unsqueeze_50 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_68: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(mul_90, unsqueeze_51);  mul_90 = unsqueeze_51 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_69: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(add_63, add_68);  add_63 = add_68 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_10: f32[64, 256, 1, 1] = torch.ops.aten.relu.default(add_69);  add_69 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_13: f32[64, 256, 1, 1] = torch.ops.aten.convolution.default(relu_10, primals_40, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_70: i64[] = torch.ops.aten.add.Tensor(primals_104, 1);  primals_104 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_13 = torch.ops.aten.var_mean.correction(convolution_13, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_28: f32[1, 256, 1, 1] = var_mean_13[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_29: f32[1, 256, 1, 1] = var_mean_13[1];  var_mean_13 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_71: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_28, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_13: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_71);  add_71 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_13: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_13, getitem_29)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_91: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_13, rsqrt_13);  sub_13 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_39: f32[256] = torch.ops.aten.squeeze.dims(getitem_29, [0, 2, 3]);  getitem_29 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_40: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_13, [0, 2, 3]);  rsqrt_13 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_92: f32[256] = torch.ops.aten.mul.Tensor(squeeze_39, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_93: f32[256] = torch.ops.aten.mul.Tensor(primals_102, 0.9);  primals_102 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_72: f32[256] = torch.ops.aten.add.Tensor(mul_92, mul_93);  mul_92 = mul_93 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_41: f32[256] = torch.ops.aten.squeeze.dims(getitem_28, [0, 2, 3]);  getitem_28 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_94: f32[256] = torch.ops.aten.mul.Tensor(squeeze_41, 1.0158730158730158);  squeeze_41 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_95: f32[256] = torch.ops.aten.mul.Tensor(mul_94, 0.1);  mul_94 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_96: f32[256] = torch.ops.aten.mul.Tensor(primals_103, 0.9);  primals_103 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_73: f32[256] = torch.ops.aten.add.Tensor(mul_95, mul_96);  mul_95 = mul_96 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_52: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_41, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_53: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_52, -1);  unsqueeze_52 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_97: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(mul_91, unsqueeze_53);  mul_91 = unsqueeze_53 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_54: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_42, -1);  primals_42 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_55: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_54, -1);  unsqueeze_54 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_74: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(mul_97, unsqueeze_55);  mul_97 = unsqueeze_55 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_11: f32[64, 256, 1, 1] = torch.ops.aten.relu.default(add_74);  add_74 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_14: f32[64, 256, 1, 1] = torch.ops.aten.convolution.default(relu_11, primals_43, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_75: i64[] = torch.ops.aten.add.Tensor(primals_107, 1);  primals_107 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_14 = torch.ops.aten.var_mean.correction(convolution_14, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_30: f32[1, 256, 1, 1] = var_mean_14[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_31: f32[1, 256, 1, 1] = var_mean_14[1];  var_mean_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_76: f32[1, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_30, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_14: f32[1, 256, 1, 1] = torch.ops.aten.rsqrt.default(add_76);  add_76 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_14: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_14, getitem_31)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_98: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_14, rsqrt_14);  sub_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_42: f32[256] = torch.ops.aten.squeeze.dims(getitem_31, [0, 2, 3]);  getitem_31 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_43: f32[256] = torch.ops.aten.squeeze.dims(rsqrt_14, [0, 2, 3]);  rsqrt_14 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_99: f32[256] = torch.ops.aten.mul.Tensor(squeeze_42, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_100: f32[256] = torch.ops.aten.mul.Tensor(primals_105, 0.9);  primals_105 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_77: f32[256] = torch.ops.aten.add.Tensor(mul_99, mul_100);  mul_99 = mul_100 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_44: f32[256] = torch.ops.aten.squeeze.dims(getitem_30, [0, 2, 3]);  getitem_30 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_101: f32[256] = torch.ops.aten.mul.Tensor(squeeze_44, 1.0158730158730158);  squeeze_44 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_102: f32[256] = torch.ops.aten.mul.Tensor(mul_101, 0.1);  mul_101 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_103: f32[256] = torch.ops.aten.mul.Tensor(primals_106, 0.9);  primals_106 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_78: f32[256] = torch.ops.aten.add.Tensor(mul_102, mul_103);  mul_102 = mul_103 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_56: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_44, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_57: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_56, -1);  unsqueeze_56 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_104: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(mul_98, unsqueeze_57);  mul_98 = unsqueeze_57 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_58: f32[256, 1] = torch.ops.aten.unsqueeze.default(primals_45, -1);  primals_45 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_59: f32[256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_58, -1);  unsqueeze_58 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_79: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(mul_104, unsqueeze_59);  mul_104 = unsqueeze_59 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_80: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(add_79, relu_10);  add_79 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_12: f32[64, 256, 1, 1] = torch.ops.aten.relu.default(add_80);  add_80 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_15: f32[64, 512, 1, 1] = torch.ops.aten.convolution.default(relu_12, primals_46, None, [2, 2], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_81: i64[] = torch.ops.aten.add.Tensor(primals_110, 1);  primals_110 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_15 = torch.ops.aten.var_mean.correction(convolution_15, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_32: f32[1, 512, 1, 1] = var_mean_15[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_33: f32[1, 512, 1, 1] = var_mean_15[1];  var_mean_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_82: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_32, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_15: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_82);  add_82 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_15: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_15, getitem_33)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_105: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_15, rsqrt_15);  sub_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_45: f32[512] = torch.ops.aten.squeeze.dims(getitem_33, [0, 2, 3]);  getitem_33 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_46: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_15, [0, 2, 3]);  rsqrt_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_106: f32[512] = torch.ops.aten.mul.Tensor(squeeze_45, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_107: f32[512] = torch.ops.aten.mul.Tensor(primals_108, 0.9);  primals_108 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_83: f32[512] = torch.ops.aten.add.Tensor(mul_106, mul_107);  mul_106 = mul_107 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_47: f32[512] = torch.ops.aten.squeeze.dims(getitem_32, [0, 2, 3]);  getitem_32 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_108: f32[512] = torch.ops.aten.mul.Tensor(squeeze_47, 1.0158730158730158);  squeeze_47 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_109: f32[512] = torch.ops.aten.mul.Tensor(mul_108, 0.1);  mul_108 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_110: f32[512] = torch.ops.aten.mul.Tensor(primals_109, 0.9);  primals_109 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_84: f32[512] = torch.ops.aten.add.Tensor(mul_109, mul_110);  mul_109 = mul_110 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_60: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_47, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_61: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_60, -1);  unsqueeze_60 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_111: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(mul_105, unsqueeze_61);  mul_105 = unsqueeze_61 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_62: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_48, -1);  primals_48 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_63: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_62, -1);  unsqueeze_62 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_85: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(mul_111, unsqueeze_63);  mul_111 = unsqueeze_63 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_13: f32[64, 512, 1, 1] = torch.ops.aten.relu.default(add_85);  add_85 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_16: f32[64, 512, 1, 1] = torch.ops.aten.convolution.default(relu_13, primals_49, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_86: i64[] = torch.ops.aten.add.Tensor(primals_113, 1);  primals_113 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_16 = torch.ops.aten.var_mean.correction(convolution_16, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_34: f32[1, 512, 1, 1] = var_mean_16[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_35: f32[1, 512, 1, 1] = var_mean_16[1];  var_mean_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_87: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_34, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_16: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_87);  add_87 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_16: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_16, getitem_35)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_112: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_16, rsqrt_16);  sub_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_48: f32[512] = torch.ops.aten.squeeze.dims(getitem_35, [0, 2, 3]);  getitem_35 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_49: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_16, [0, 2, 3]);  rsqrt_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_113: f32[512] = torch.ops.aten.mul.Tensor(squeeze_48, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_114: f32[512] = torch.ops.aten.mul.Tensor(primals_111, 0.9);  primals_111 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_88: f32[512] = torch.ops.aten.add.Tensor(mul_113, mul_114);  mul_113 = mul_114 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_50: f32[512] = torch.ops.aten.squeeze.dims(getitem_34, [0, 2, 3]);  getitem_34 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_115: f32[512] = torch.ops.aten.mul.Tensor(squeeze_50, 1.0158730158730158);  squeeze_50 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_116: f32[512] = torch.ops.aten.mul.Tensor(mul_115, 0.1);  mul_115 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_117: f32[512] = torch.ops.aten.mul.Tensor(primals_112, 0.9);  primals_112 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_89: f32[512] = torch.ops.aten.add.Tensor(mul_116, mul_117);  mul_116 = mul_117 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_64: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_50, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_65: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_64, -1);  unsqueeze_64 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_118: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(mul_112, unsqueeze_65);  mul_112 = unsqueeze_65 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_66: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_51, -1);  primals_51 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_67: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_66, -1);  unsqueeze_66 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_90: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(mul_118, unsqueeze_67);  mul_118 = unsqueeze_67 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_17: f32[64, 512, 1, 1] = torch.ops.aten.convolution.default(relu_12, primals_52, None, [2, 2], [0, 0], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_91: i64[] = torch.ops.aten.add.Tensor(primals_116, 1);  primals_116 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_17 = torch.ops.aten.var_mean.correction(convolution_17, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_36: f32[1, 512, 1, 1] = var_mean_17[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_37: f32[1, 512, 1, 1] = var_mean_17[1];  var_mean_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_92: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_36, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_17: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_92);  add_92 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_17: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_17, getitem_37)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_119: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_17, rsqrt_17);  sub_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_51: f32[512] = torch.ops.aten.squeeze.dims(getitem_37, [0, 2, 3]);  getitem_37 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_52: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_17, [0, 2, 3]);  rsqrt_17 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_120: f32[512] = torch.ops.aten.mul.Tensor(squeeze_51, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_121: f32[512] = torch.ops.aten.mul.Tensor(primals_114, 0.9);  primals_114 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_93: f32[512] = torch.ops.aten.add.Tensor(mul_120, mul_121);  mul_120 = mul_121 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_53: f32[512] = torch.ops.aten.squeeze.dims(getitem_36, [0, 2, 3]);  getitem_36 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_122: f32[512] = torch.ops.aten.mul.Tensor(squeeze_53, 1.0158730158730158);  squeeze_53 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_123: f32[512] = torch.ops.aten.mul.Tensor(mul_122, 0.1);  mul_122 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_124: f32[512] = torch.ops.aten.mul.Tensor(primals_115, 0.9);  primals_115 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_94: f32[512] = torch.ops.aten.add.Tensor(mul_123, mul_124);  mul_123 = mul_124 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_68: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_53, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_69: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_68, -1);  unsqueeze_68 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_125: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(mul_119, unsqueeze_69);  mul_119 = unsqueeze_69 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_70: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_54, -1);  primals_54 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_71: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_70, -1);  unsqueeze_70 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_95: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(mul_125, unsqueeze_71);  mul_125 = unsqueeze_71 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_96: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(add_90, add_95);  add_90 = add_95 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_14: f32[64, 512, 1, 1] = torch.ops.aten.relu.default(add_96);  add_96 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_18: f32[64, 512, 1, 1] = torch.ops.aten.convolution.default(relu_14, primals_55, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_97: i64[] = torch.ops.aten.add.Tensor(primals_119, 1);  primals_119 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_18 = torch.ops.aten.var_mean.correction(convolution_18, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_38: f32[1, 512, 1, 1] = var_mean_18[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_39: f32[1, 512, 1, 1] = var_mean_18[1];  var_mean_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_98: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_38, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_18: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_98);  add_98 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_18: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_18, getitem_39)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_126: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_18, rsqrt_18);  sub_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_54: f32[512] = torch.ops.aten.squeeze.dims(getitem_39, [0, 2, 3]);  getitem_39 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_55: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_18, [0, 2, 3]);  rsqrt_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_127: f32[512] = torch.ops.aten.mul.Tensor(squeeze_54, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_128: f32[512] = torch.ops.aten.mul.Tensor(primals_117, 0.9);  primals_117 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_99: f32[512] = torch.ops.aten.add.Tensor(mul_127, mul_128);  mul_127 = mul_128 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_56: f32[512] = torch.ops.aten.squeeze.dims(getitem_38, [0, 2, 3]);  getitem_38 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_129: f32[512] = torch.ops.aten.mul.Tensor(squeeze_56, 1.0158730158730158);  squeeze_56 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_130: f32[512] = torch.ops.aten.mul.Tensor(mul_129, 0.1);  mul_129 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_131: f32[512] = torch.ops.aten.mul.Tensor(primals_118, 0.9);  primals_118 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_100: f32[512] = torch.ops.aten.add.Tensor(mul_130, mul_131);  mul_130 = mul_131 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_72: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_56, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_73: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_72, -1);  unsqueeze_72 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_132: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(mul_126, unsqueeze_73);  mul_126 = unsqueeze_73 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_74: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_57, -1);  primals_57 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_75: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_74, -1);  unsqueeze_74 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_101: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(mul_132, unsqueeze_75);  mul_132 = unsqueeze_75 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_15: f32[64, 512, 1, 1] = torch.ops.aten.relu.default(add_101);  add_101 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_19: f32[64, 512, 1, 1] = torch.ops.aten.convolution.default(relu_15, primals_58, None, [1, 1], [1, 1], [1, 1], False, [0, 0], 1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_102: i64[] = torch.ops.aten.add.Tensor(primals_122, 1);  primals_122 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         var_mean_19 = torch.ops.aten.var_mean.correction(convolution_19, [0, 2, 3], correction = 0, keepdim = True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_40: f32[1, 512, 1, 1] = var_mean_19[0]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_41: f32[1, 512, 1, 1] = var_mean_19[1];  var_mean_19 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_103: f32[1, 512, 1, 1] = torch.ops.aten.add.Tensor(getitem_40, 1e-05)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         rsqrt_19: f32[1, 512, 1, 1] = torch.ops.aten.rsqrt.default(add_103);  add_103 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_19: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_19, getitem_41)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_133: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_19, rsqrt_19);  sub_19 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_57: f32[512] = torch.ops.aten.squeeze.dims(getitem_41, [0, 2, 3]);  getitem_41 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_58: f32[512] = torch.ops.aten.squeeze.dims(rsqrt_19, [0, 2, 3]);  rsqrt_19 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_134: f32[512] = torch.ops.aten.mul.Tensor(squeeze_57, 0.1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_135: f32[512] = torch.ops.aten.mul.Tensor(primals_120, 0.9);  primals_120 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_104: f32[512] = torch.ops.aten.add.Tensor(mul_134, mul_135);  mul_134 = mul_135 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         squeeze_59: f32[512] = torch.ops.aten.squeeze.dims(getitem_40, [0, 2, 3]);  getitem_40 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_136: f32[512] = torch.ops.aten.mul.Tensor(squeeze_59, 1.0158730158730158);  squeeze_59 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_137: f32[512] = torch.ops.aten.mul.Tensor(mul_136, 0.1);  mul_136 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_138: f32[512] = torch.ops.aten.mul.Tensor(primals_121, 0.9);  primals_121 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_105: f32[512] = torch.ops.aten.add.Tensor(mul_137, mul_138);  mul_137 = mul_138 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_76: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_59, -1)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_77: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_76, -1);  unsqueeze_76 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_139: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(mul_133, unsqueeze_77);  mul_133 = unsqueeze_77 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_78: f32[512, 1] = torch.ops.aten.unsqueeze.default(primals_60, -1);  primals_60 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_79: f32[512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_78, -1);  unsqueeze_78 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_106: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(mul_139, unsqueeze_79);  mul_139 = unsqueeze_79 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115, code: x += shortcut\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_107: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(add_106, relu_14);  add_106 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         relu_16: f32[64, 512, 1, 1] = torch.ops.aten.relu.default(add_107);  add_107 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:167, code: x = self.pool(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mean: f32[64, 512, 1, 1] = torch.ops.aten.mean.dim(relu_16, [-1, -2], True)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:168, code: x = self.flatten(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         view: f32[64, 512] = torch.ops.aten.view.default(mean, [64, 512]);  mean = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:538, code: return x if pre_logits else self.fc(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute: f32[512, 2] = torch.ops.aten.permute.default(primals_61, [1, 0]);  primals_61 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         addmm: f32[64, 2] = torch.ops.aten.addmm.default(primals_62, view, permute);  primals_62 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_1: f32[2, 512] = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le: b8[64, 512, 1, 1] = torch.ops.aten.le.Scalar(relu_16, 0);  relu_16 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_80: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_57, 0);  squeeze_57 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_81: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_80, 2);  unsqueeze_80 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_82: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_81, 3);  unsqueeze_81 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_92: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_54, 0);  squeeze_54 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_93: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_92, 2);  unsqueeze_92 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_94: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_93, 3);  unsqueeze_93 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_104: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_51, 0);  squeeze_51 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_105: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_104, 2);  unsqueeze_104 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_106: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_105, 3);  unsqueeze_105 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_116: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_48, 0);  squeeze_48 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_117: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_116, 2);  unsqueeze_116 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_118: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_117, 3);  unsqueeze_117 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_128: f32[1, 512] = torch.ops.aten.unsqueeze.default(squeeze_45, 0);  squeeze_45 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_129: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_128, 2);  unsqueeze_128 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_130: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_129, 3);  unsqueeze_129 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_140: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_42, 0);  squeeze_42 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_141: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_140, 2);  unsqueeze_140 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_142: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_141, 3);  unsqueeze_141 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_152: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_39, 0);  squeeze_39 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_153: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_152, 2);  unsqueeze_152 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_154: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_153, 3);  unsqueeze_153 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_164: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_36, 0);  squeeze_36 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_165: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_164, 2);  unsqueeze_164 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_166: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_165, 3);  unsqueeze_165 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_176: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_33, 0);  squeeze_33 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_177: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_176, 2);  unsqueeze_176 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_178: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_177, 3);  unsqueeze_177 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_188: f32[1, 256] = torch.ops.aten.unsqueeze.default(squeeze_30, 0);  squeeze_30 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_189: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_188, 2);  unsqueeze_188 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_190: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_189, 3);  unsqueeze_189 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_200: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_27, 0);  squeeze_27 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_201: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_200, 2);  unsqueeze_200 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_202: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_201, 3);  unsqueeze_201 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_212: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_24, 0);  squeeze_24 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_213: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_212, 2);  unsqueeze_212 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_214: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_213, 3);  unsqueeze_213 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_224: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_21, 0);  squeeze_21 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_225: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_224, 2);  unsqueeze_224 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_226: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_225, 3);  unsqueeze_225 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_236: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_18, 0);  squeeze_18 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_237: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_236, 2);  unsqueeze_236 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_238: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_237, 3);  unsqueeze_237 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_248: f32[1, 128] = torch.ops.aten.unsqueeze.default(squeeze_15, 0);  squeeze_15 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_249: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_248, 2);  unsqueeze_248 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_250: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_249, 3);  unsqueeze_249 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_260: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_12, 0);  squeeze_12 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_261: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_260, 2);  unsqueeze_260 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_262: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_261, 3);  unsqueeze_261 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_272: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_9, 0);  squeeze_9 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_273: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_272, 2);  unsqueeze_272 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_274: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_273, 3);  unsqueeze_273 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_284: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_6, 0);  squeeze_6 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_285: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_284, 2);  unsqueeze_284 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_286: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_285, 3);  unsqueeze_285 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_296: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze_3, 0);  squeeze_3 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_297: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_296, 2);  unsqueeze_296 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_298: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_297, 3);  unsqueeze_297 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_308: f32[1, 64] = torch.ops.aten.unsqueeze.default(squeeze, 0);  squeeze = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_309: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_308, 2);  unsqueeze_308 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_310: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_309, 3);  unsqueeze_309 = None\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         return [add_2, add_3, add, add_7, add_8, add_5, add_12, add_13, add_10, add_18, add_19, add_16, add_23, add_24, add_21, add_29, add_30, add_27, add_34, add_35, add_32, add_39, add_40, add_37, add_45, add_46, add_43, add_50, add_51, add_48, add_56, add_57, add_54, add_61, add_62, add_59, add_66, add_67, add_64, add_72, add_73, add_70, add_77, add_78, add_75, add_83, add_84, add_81, add_88, add_89, add_86, add_93, add_94, add_91, add_99, add_100, add_97, add_104, add_105, add_102, addmm, primals_1, primals_2, primals_4, primals_5, primals_7, primals_8, primals_10, primals_11, primals_13, primals_14, primals_16, primals_17, primals_19, primals_20, primals_22, primals_23, primals_25, primals_26, primals_28, primals_29, primals_31, primals_32, primals_34, primals_35, primals_37, primals_38, primals_40, primals_41, primals_43, primals_44, primals_46, primals_47, primals_49, primals_50, primals_52, primals_53, primals_55, primals_56, primals_58, primals_59, primals_123, convolution, squeeze_1, relu, getitem_2, getitem_3, convolution_1, squeeze_4, relu_1, convolution_2, squeeze_7, relu_2, convolution_3, squeeze_10, relu_3, convolution_4, squeeze_13, relu_4, convolution_5, squeeze_16, relu_5, convolution_6, squeeze_19, convolution_7, squeeze_22, relu_6, convolution_8, squeeze_25, relu_7, convolution_9, squeeze_28, relu_8, convolution_10, squeeze_31, relu_9, convolution_11, squeeze_34, convolution_12, squeeze_37, relu_10, convolution_13, squeeze_40, relu_11, convolution_14, squeeze_43, relu_12, convolution_15, squeeze_46, relu_13, convolution_16, squeeze_49, convolution_17, squeeze_52, relu_14, convolution_18, squeeze_55, relu_15, convolution_19, squeeze_58, view, permute_1, le, unsqueeze_82, unsqueeze_94, unsqueeze_106, unsqueeze_118, unsqueeze_130, unsqueeze_142, unsqueeze_154, unsqueeze_166, unsqueeze_178, unsqueeze_190, unsqueeze_202, unsqueeze_214, unsqueeze_226, unsqueeze_238, unsqueeze_250, unsqueeze_262, unsqueeze_274, unsqueeze_286, unsqueeze_298, unsqueeze_310]\n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,914] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] TRACED GRAPH\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  ===== Backward graph 23 =====\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]  <eval_with_key>.233 class GraphModule(torch.nn.Module):\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]     def forward(self, primals_1: f32[64, 3, 7, 7], primals_2: f32[64], primals_4: f32[64, 64, 3, 3], primals_5: f32[64], primals_7: f32[64, 64, 3, 3], primals_8: f32[64], primals_10: f32[64, 64, 3, 3], primals_11: f32[64], primals_13: f32[64, 64, 3, 3], primals_14: f32[64], primals_16: f32[128, 64, 3, 3], primals_17: f32[128], primals_19: f32[128, 128, 3, 3], primals_20: f32[128], primals_22: f32[128, 64, 1, 1], primals_23: f32[128], primals_25: f32[128, 128, 3, 3], primals_26: f32[128], primals_28: f32[128, 128, 3, 3], primals_29: f32[128], primals_31: f32[256, 128, 3, 3], primals_32: f32[256], primals_34: f32[256, 256, 3, 3], primals_35: f32[256], primals_37: f32[256, 128, 1, 1], primals_38: f32[256], primals_40: f32[256, 256, 3, 3], primals_41: f32[256], primals_43: f32[256, 256, 3, 3], primals_44: f32[256], primals_46: f32[512, 256, 3, 3], primals_47: f32[512], primals_49: f32[512, 512, 3, 3], primals_50: f32[512], primals_52: f32[512, 256, 1, 1], primals_53: f32[512], primals_55: f32[512, 512, 3, 3], primals_56: f32[512], primals_58: f32[512, 512, 3, 3], primals_59: f32[512], primals_123: f32[64, 3, 7, 7], convolution: f32[64, 64, 4, 4], squeeze_1: f32[64], relu: f32[64, 64, 4, 4], getitem_2: f32[64, 64, 2, 2], getitem_3: i64[64, 64, 2, 2], convolution_1: f32[64, 64, 2, 2], squeeze_4: f32[64], relu_1: f32[64, 64, 2, 2], convolution_2: f32[64, 64, 2, 2], squeeze_7: f32[64], relu_2: f32[64, 64, 2, 2], convolution_3: f32[64, 64, 2, 2], squeeze_10: f32[64], relu_3: f32[64, 64, 2, 2], convolution_4: f32[64, 64, 2, 2], squeeze_13: f32[64], relu_4: f32[64, 64, 2, 2], convolution_5: f32[64, 128, 1, 1], squeeze_16: f32[128], relu_5: f32[64, 128, 1, 1], convolution_6: f32[64, 128, 1, 1], squeeze_19: f32[128], convolution_7: f32[64, 128, 1, 1], squeeze_22: f32[128], relu_6: f32[64, 128, 1, 1], convolution_8: f32[64, 128, 1, 1], squeeze_25: f32[128], relu_7: f32[64, 128, 1, 1], convolution_9: f32[64, 128, 1, 1], squeeze_28: f32[128], relu_8: f32[64, 128, 1, 1], convolution_10: f32[64, 256, 1, 1], squeeze_31: f32[256], relu_9: f32[64, 256, 1, 1], convolution_11: f32[64, 256, 1, 1], squeeze_34: f32[256], convolution_12: f32[64, 256, 1, 1], squeeze_37: f32[256], relu_10: f32[64, 256, 1, 1], convolution_13: f32[64, 256, 1, 1], squeeze_40: f32[256], relu_11: f32[64, 256, 1, 1], convolution_14: f32[64, 256, 1, 1], squeeze_43: f32[256], relu_12: f32[64, 256, 1, 1], convolution_15: f32[64, 512, 1, 1], squeeze_46: f32[512], relu_13: f32[64, 512, 1, 1], convolution_16: f32[64, 512, 1, 1], squeeze_49: f32[512], convolution_17: f32[64, 512, 1, 1], squeeze_52: f32[512], relu_14: f32[64, 512, 1, 1], convolution_18: f32[64, 512, 1, 1], squeeze_55: f32[512], relu_15: f32[64, 512, 1, 1], convolution_19: f32[64, 512, 1, 1], squeeze_58: f32[512], view: f32[64, 512], permute_1: f32[2, 512], le: b8[64, 512, 1, 1], unsqueeze_82: f32[1, 512, 1, 1], unsqueeze_94: f32[1, 512, 1, 1], unsqueeze_106: f32[1, 512, 1, 1], unsqueeze_118: f32[1, 512, 1, 1], unsqueeze_130: f32[1, 512, 1, 1], unsqueeze_142: f32[1, 256, 1, 1], unsqueeze_154: f32[1, 256, 1, 1], unsqueeze_166: f32[1, 256, 1, 1], unsqueeze_178: f32[1, 256, 1, 1], unsqueeze_190: f32[1, 256, 1, 1], unsqueeze_202: f32[1, 128, 1, 1], unsqueeze_214: f32[1, 128, 1, 1], unsqueeze_226: f32[1, 128, 1, 1], unsqueeze_238: f32[1, 128, 1, 1], unsqueeze_250: f32[1, 128, 1, 1], unsqueeze_262: f32[1, 64, 1, 1], unsqueeze_274: f32[1, 64, 1, 1], unsqueeze_286: f32[1, 64, 1, 1], unsqueeze_298: f32[1, 64, 1, 1], unsqueeze_310: f32[1, 64, 1, 1], tangents_1: f32[64], tangents_2: f32[64], tangents_3: i64[], tangents_4: f32[64], tangents_5: f32[64], tangents_6: i64[], tangents_7: f32[64], tangents_8: f32[64], tangents_9: i64[], tangents_10: f32[64], tangents_11: f32[64], tangents_12: i64[], tangents_13: f32[64], tangents_14: f32[64], tangents_15: i64[], tangents_16: f32[128], tangents_17: f32[128], tangents_18: i64[], tangents_19: f32[128], tangents_20: f32[128], tangents_21: i64[], tangents_22: f32[128], tangents_23: f32[128], tangents_24: i64[], tangents_25: f32[128], tangents_26: f32[128], tangents_27: i64[], tangents_28: f32[128], tangents_29: f32[128], tangents_30: i64[], tangents_31: f32[256], tangents_32: f32[256], tangents_33: i64[], tangents_34: f32[256], tangents_35: f32[256], tangents_36: i64[], tangents_37: f32[256], tangents_38: f32[256], tangents_39: i64[], tangents_40: f32[256], tangents_41: f32[256], tangents_42: i64[], tangents_43: f32[256], tangents_44: f32[256], tangents_45: i64[], tangents_46: f32[512], tangents_47: f32[512], tangents_48: i64[], tangents_49: f32[512], tangents_50: f32[512], tangents_51: i64[], tangents_52: f32[512], tangents_53: f32[512], tangents_54: i64[], tangents_55: f32[512], tangents_56: f32[512], tangents_57: i64[], tangents_58: f32[512], tangents_59: f32[512], tangents_60: i64[], tangents_61: f32[64, 2]):\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:538, code: return x if pre_logits else self.fc(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mm: f32[64, 512] = torch.ops.aten.mm.default(tangents_61, permute_1);  permute_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_2: f32[2, 64] = torch.ops.aten.permute.default(tangents_61, [1, 0])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mm_1: f32[2, 512] = torch.ops.aten.mm.default(permute_2, view);  permute_2 = view = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_3: f32[512, 2] = torch.ops.aten.permute.default(mm_1, [1, 0]);  mm_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_1: f32[1, 2] = torch.ops.aten.sum.dim_IntList(tangents_61, [0], True);  tangents_61 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         view_1: f32[2] = torch.ops.aten.view.default(sum_1, [2]);  sum_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         permute_4: f32[2, 512] = torch.ops.aten.permute.default(permute_3, [1, 0]);  permute_3 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:168, code: x = self.flatten(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         view_2: f32[64, 512, 1, 1] = torch.ops.aten.view.default(mm, [64, 512, 1, 1]);  mm = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/layers/adaptive_avgmax_pool.py:167, code: x = self.pool(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         expand: f32[64, 512, 1, 1] = torch.ops.aten.expand.default(view_2, [64, 512, 1, 1]);  view_2 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         div: f32[64, 512, 1, 1] = torch.ops.aten.div.Scalar(expand, 1);  expand = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         full_default: f32[] = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where: f32[64, 512, 1, 1] = torch.ops.aten.where.self(le, full_default, div);  le = div = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_2: f32[512] = torch.ops.aten.sum.dim_IntList(where, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_20: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_19, unsqueeze_82);  convolution_19 = unsqueeze_82 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_140: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(where, sub_20)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_3: f32[512] = torch.ops.aten.sum.dim_IntList(mul_140, [0, 2, 3]);  mul_140 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_141: f32[512] = torch.ops.aten.mul.Tensor(sum_2, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_83: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_141, 0);  mul_141 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_84: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_83, 2);  unsqueeze_83 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_85: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_84, 3);  unsqueeze_84 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_142: f32[512] = torch.ops.aten.mul.Tensor(sum_3, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_143: f32[512] = torch.ops.aten.mul.Tensor(squeeze_58, squeeze_58)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_144: f32[512] = torch.ops.aten.mul.Tensor(mul_142, mul_143);  mul_142 = mul_143 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_86: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_144, 0);  mul_144 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_87: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_86, 2);  unsqueeze_86 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_88: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_87, 3);  unsqueeze_87 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_145: f32[512] = torch.ops.aten.mul.Tensor(squeeze_58, primals_59);  primals_59 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_89: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_145, 0);  mul_145 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_90: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_89, 2);  unsqueeze_89 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_91: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_90, 3);  unsqueeze_90 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_146: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_20, unsqueeze_88);  sub_20 = unsqueeze_88 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_22: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(where, mul_146);  mul_146 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_23: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(sub_22, unsqueeze_85);  sub_22 = unsqueeze_85 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_147: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_23, unsqueeze_91);  sub_23 = unsqueeze_91 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_148: f32[512] = torch.ops.aten.mul.Tensor(sum_3, squeeze_58);  sum_3 = squeeze_58 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward = torch.ops.aten.convolution_backward.default(mul_147, relu_15, primals_58, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_147 = primals_58 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_42: f32[64, 512, 1, 1] = convolution_backward[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_43: f32[512, 512, 3, 3] = convolution_backward[1];  convolution_backward = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_1: b8[64, 512, 1, 1] = torch.ops.aten.le.Scalar(relu_15, 0);  relu_15 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_1: f32[64, 512, 1, 1] = torch.ops.aten.where.self(le_1, full_default, getitem_42);  le_1 = getitem_42 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_4: f32[512] = torch.ops.aten.sum.dim_IntList(where_1, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_24: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_18, unsqueeze_94);  convolution_18 = unsqueeze_94 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_149: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(where_1, sub_24)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_5: f32[512] = torch.ops.aten.sum.dim_IntList(mul_149, [0, 2, 3]);  mul_149 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_150: f32[512] = torch.ops.aten.mul.Tensor(sum_4, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_95: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_150, 0);  mul_150 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_96: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_95, 2);  unsqueeze_95 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_97: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_96, 3);  unsqueeze_96 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_151: f32[512] = torch.ops.aten.mul.Tensor(sum_5, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_152: f32[512] = torch.ops.aten.mul.Tensor(squeeze_55, squeeze_55)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_153: f32[512] = torch.ops.aten.mul.Tensor(mul_151, mul_152);  mul_151 = mul_152 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_98: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_153, 0);  mul_153 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_99: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_98, 2);  unsqueeze_98 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_100: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_99, 3);  unsqueeze_99 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_154: f32[512] = torch.ops.aten.mul.Tensor(squeeze_55, primals_56);  primals_56 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_101: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_154, 0);  mul_154 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_102: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_101, 2);  unsqueeze_101 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_103: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_102, 3);  unsqueeze_102 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_155: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_24, unsqueeze_100);  sub_24 = unsqueeze_100 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_26: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(where_1, mul_155);  where_1 = mul_155 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_27: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(sub_26, unsqueeze_97);  sub_26 = unsqueeze_97 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_156: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_27, unsqueeze_103);  sub_27 = unsqueeze_103 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_157: f32[512] = torch.ops.aten.mul.Tensor(sum_5, squeeze_55);  sum_5 = squeeze_55 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_1 = torch.ops.aten.convolution_backward.default(mul_156, relu_14, primals_55, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_156 = primals_55 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_45: f32[64, 512, 1, 1] = convolution_backward_1[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_46: f32[512, 512, 3, 3] = convolution_backward_1[1];  convolution_backward_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_108: f32[64, 512, 1, 1] = torch.ops.aten.add.Tensor(where, getitem_45);  where = getitem_45 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_2: b8[64, 512, 1, 1] = torch.ops.aten.le.Scalar(relu_14, 0);  relu_14 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_2: f32[64, 512, 1, 1] = torch.ops.aten.where.self(le_2, full_default, add_108);  le_2 = add_108 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_6: f32[512] = torch.ops.aten.sum.dim_IntList(where_2, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_28: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_17, unsqueeze_106);  convolution_17 = unsqueeze_106 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_158: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(where_2, sub_28)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_7: f32[512] = torch.ops.aten.sum.dim_IntList(mul_158, [0, 2, 3]);  mul_158 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_159: f32[512] = torch.ops.aten.mul.Tensor(sum_6, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_107: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_159, 0);  mul_159 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_108: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_107, 2);  unsqueeze_107 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_109: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_108, 3);  unsqueeze_108 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_160: f32[512] = torch.ops.aten.mul.Tensor(sum_7, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_161: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, squeeze_52)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_162: f32[512] = torch.ops.aten.mul.Tensor(mul_160, mul_161);  mul_160 = mul_161 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_110: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_162, 0);  mul_162 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_111: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_110, 2);  unsqueeze_110 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_112: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_111, 3);  unsqueeze_111 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_163: f32[512] = torch.ops.aten.mul.Tensor(squeeze_52, primals_53);  primals_53 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_113: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_163, 0);  mul_163 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_114: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_113, 2);  unsqueeze_113 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_115: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_114, 3);  unsqueeze_114 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_164: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_28, unsqueeze_112);  sub_28 = unsqueeze_112 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_30: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(where_2, mul_164);  mul_164 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_31: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(sub_30, unsqueeze_109);  sub_30 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_165: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_31, unsqueeze_115);  sub_31 = unsqueeze_115 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_166: f32[512] = torch.ops.aten.mul.Tensor(sum_7, squeeze_52);  sum_7 = squeeze_52 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_2 = torch.ops.aten.convolution_backward.default(mul_165, relu_12, primals_52, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_165 = primals_52 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_48: f32[64, 256, 1, 1] = convolution_backward_2[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_49: f32[512, 256, 1, 1] = convolution_backward_2[1];  convolution_backward_2 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_32: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_16, unsqueeze_118);  convolution_16 = unsqueeze_118 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_167: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(where_2, sub_32)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_9: f32[512] = torch.ops.aten.sum.dim_IntList(mul_167, [0, 2, 3]);  mul_167 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_169: f32[512] = torch.ops.aten.mul.Tensor(sum_9, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_170: f32[512] = torch.ops.aten.mul.Tensor(squeeze_49, squeeze_49)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_171: f32[512] = torch.ops.aten.mul.Tensor(mul_169, mul_170);  mul_169 = mul_170 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_122: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_171, 0);  mul_171 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_123: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_122, 2);  unsqueeze_122 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_124: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_123, 3);  unsqueeze_123 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_172: f32[512] = torch.ops.aten.mul.Tensor(squeeze_49, primals_50);  primals_50 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_125: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_172, 0);  mul_172 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_126: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_125, 2);  unsqueeze_125 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_127: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_126, 3);  unsqueeze_126 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_173: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_32, unsqueeze_124);  sub_32 = unsqueeze_124 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_34: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(where_2, mul_173);  where_2 = mul_173 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_35: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(sub_34, unsqueeze_109);  sub_34 = unsqueeze_109 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_174: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_35, unsqueeze_127);  sub_35 = unsqueeze_127 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_175: f32[512] = torch.ops.aten.mul.Tensor(sum_9, squeeze_49);  sum_9 = squeeze_49 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_3 = torch.ops.aten.convolution_backward.default(mul_174, relu_13, primals_49, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_174 = primals_49 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_51: f32[64, 512, 1, 1] = convolution_backward_3[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_52: f32[512, 512, 3, 3] = convolution_backward_3[1];  convolution_backward_3 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_3: b8[64, 512, 1, 1] = torch.ops.aten.le.Scalar(relu_13, 0);  relu_13 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_3: f32[64, 512, 1, 1] = torch.ops.aten.where.self(le_3, full_default, getitem_51);  le_3 = getitem_51 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_10: f32[512] = torch.ops.aten.sum.dim_IntList(where_3, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_36: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(convolution_15, unsqueeze_130);  convolution_15 = unsqueeze_130 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_176: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(where_3, sub_36)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_11: f32[512] = torch.ops.aten.sum.dim_IntList(mul_176, [0, 2, 3]);  mul_176 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_177: f32[512] = torch.ops.aten.mul.Tensor(sum_10, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_131: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_177, 0);  mul_177 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_132: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_131, 2);  unsqueeze_131 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_133: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_132, 3);  unsqueeze_132 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_178: f32[512] = torch.ops.aten.mul.Tensor(sum_11, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_179: f32[512] = torch.ops.aten.mul.Tensor(squeeze_46, squeeze_46)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_180: f32[512] = torch.ops.aten.mul.Tensor(mul_178, mul_179);  mul_178 = mul_179 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_134: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_180, 0);  mul_180 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_135: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_134, 2);  unsqueeze_134 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_136: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_135, 3);  unsqueeze_135 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_181: f32[512] = torch.ops.aten.mul.Tensor(squeeze_46, primals_47);  primals_47 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_137: f32[1, 512] = torch.ops.aten.unsqueeze.default(mul_181, 0);  mul_181 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_138: f32[1, 512, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_137, 2);  unsqueeze_137 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_139: f32[1, 512, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_138, 3);  unsqueeze_138 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_182: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_36, unsqueeze_136);  sub_36 = unsqueeze_136 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_38: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(where_3, mul_182);  where_3 = mul_182 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_39: f32[64, 512, 1, 1] = torch.ops.aten.sub.Tensor(sub_38, unsqueeze_133);  sub_38 = unsqueeze_133 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_183: f32[64, 512, 1, 1] = torch.ops.aten.mul.Tensor(sub_39, unsqueeze_139);  sub_39 = unsqueeze_139 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_184: f32[512] = torch.ops.aten.mul.Tensor(sum_11, squeeze_46);  sum_11 = squeeze_46 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_4 = torch.ops.aten.convolution_backward.default(mul_183, relu_12, primals_46, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_183 = primals_46 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_54: f32[64, 256, 1, 1] = convolution_backward_4[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_55: f32[512, 256, 3, 3] = convolution_backward_4[1];  convolution_backward_4 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_109: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(getitem_48, getitem_54);  getitem_48 = getitem_54 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_4: b8[64, 256, 1, 1] = torch.ops.aten.le.Scalar(relu_12, 0);  relu_12 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_4: f32[64, 256, 1, 1] = torch.ops.aten.where.self(le_4, full_default, add_109);  le_4 = add_109 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_12: f32[256] = torch.ops.aten.sum.dim_IntList(where_4, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_40: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_14, unsqueeze_142);  convolution_14 = unsqueeze_142 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_185: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(where_4, sub_40)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_13: f32[256] = torch.ops.aten.sum.dim_IntList(mul_185, [0, 2, 3]);  mul_185 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_186: f32[256] = torch.ops.aten.mul.Tensor(sum_12, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_143: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_186, 0);  mul_186 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_144: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_143, 2);  unsqueeze_143 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_145: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_144, 3);  unsqueeze_144 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_187: f32[256] = torch.ops.aten.mul.Tensor(sum_13, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_188: f32[256] = torch.ops.aten.mul.Tensor(squeeze_43, squeeze_43)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_189: f32[256] = torch.ops.aten.mul.Tensor(mul_187, mul_188);  mul_187 = mul_188 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_146: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_189, 0);  mul_189 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_147: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_146, 2);  unsqueeze_146 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_148: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_147, 3);  unsqueeze_147 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_190: f32[256] = torch.ops.aten.mul.Tensor(squeeze_43, primals_44);  primals_44 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_149: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_190, 0);  mul_190 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_150: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_149, 2);  unsqueeze_149 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_151: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_150, 3);  unsqueeze_150 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_191: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_40, unsqueeze_148);  sub_40 = unsqueeze_148 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_42: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(where_4, mul_191);  mul_191 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_43: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(sub_42, unsqueeze_145);  sub_42 = unsqueeze_145 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_192: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_43, unsqueeze_151);  sub_43 = unsqueeze_151 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_193: f32[256] = torch.ops.aten.mul.Tensor(sum_13, squeeze_43);  sum_13 = squeeze_43 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_5 = torch.ops.aten.convolution_backward.default(mul_192, relu_11, primals_43, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_192 = primals_43 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_57: f32[64, 256, 1, 1] = convolution_backward_5[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_58: f32[256, 256, 3, 3] = convolution_backward_5[1];  convolution_backward_5 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_5: b8[64, 256, 1, 1] = torch.ops.aten.le.Scalar(relu_11, 0);  relu_11 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_5: f32[64, 256, 1, 1] = torch.ops.aten.where.self(le_5, full_default, getitem_57);  le_5 = getitem_57 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_14: f32[256] = torch.ops.aten.sum.dim_IntList(where_5, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_44: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_13, unsqueeze_154);  convolution_13 = unsqueeze_154 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_194: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(where_5, sub_44)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_15: f32[256] = torch.ops.aten.sum.dim_IntList(mul_194, [0, 2, 3]);  mul_194 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_195: f32[256] = torch.ops.aten.mul.Tensor(sum_14, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_155: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_195, 0);  mul_195 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_156: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_155, 2);  unsqueeze_155 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_157: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_156, 3);  unsqueeze_156 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_196: f32[256] = torch.ops.aten.mul.Tensor(sum_15, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_197: f32[256] = torch.ops.aten.mul.Tensor(squeeze_40, squeeze_40)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_198: f32[256] = torch.ops.aten.mul.Tensor(mul_196, mul_197);  mul_196 = mul_197 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_158: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_198, 0);  mul_198 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_159: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_158, 2);  unsqueeze_158 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_160: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_159, 3);  unsqueeze_159 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_199: f32[256] = torch.ops.aten.mul.Tensor(squeeze_40, primals_41);  primals_41 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_161: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_199, 0);  mul_199 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_162: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_161, 2);  unsqueeze_161 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_163: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_162, 3);  unsqueeze_162 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_200: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_44, unsqueeze_160);  sub_44 = unsqueeze_160 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_46: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(where_5, mul_200);  where_5 = mul_200 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_47: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(sub_46, unsqueeze_157);  sub_46 = unsqueeze_157 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_201: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_47, unsqueeze_163);  sub_47 = unsqueeze_163 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_202: f32[256] = torch.ops.aten.mul.Tensor(sum_15, squeeze_40);  sum_15 = squeeze_40 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_6 = torch.ops.aten.convolution_backward.default(mul_201, relu_10, primals_40, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_201 = primals_40 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_60: f32[64, 256, 1, 1] = convolution_backward_6[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_61: f32[256, 256, 3, 3] = convolution_backward_6[1];  convolution_backward_6 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_110: f32[64, 256, 1, 1] = torch.ops.aten.add.Tensor(where_4, getitem_60);  where_4 = getitem_60 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_6: b8[64, 256, 1, 1] = torch.ops.aten.le.Scalar(relu_10, 0);  relu_10 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_6: f32[64, 256, 1, 1] = torch.ops.aten.where.self(le_6, full_default, add_110);  le_6 = add_110 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_16: f32[256] = torch.ops.aten.sum.dim_IntList(where_6, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_48: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_12, unsqueeze_166);  convolution_12 = unsqueeze_166 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_203: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(where_6, sub_48)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_17: f32[256] = torch.ops.aten.sum.dim_IntList(mul_203, [0, 2, 3]);  mul_203 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_204: f32[256] = torch.ops.aten.mul.Tensor(sum_16, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_167: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_204, 0);  mul_204 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_168: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_167, 2);  unsqueeze_167 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_169: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_168, 3);  unsqueeze_168 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_205: f32[256] = torch.ops.aten.mul.Tensor(sum_17, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_206: f32[256] = torch.ops.aten.mul.Tensor(squeeze_37, squeeze_37)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_207: f32[256] = torch.ops.aten.mul.Tensor(mul_205, mul_206);  mul_205 = mul_206 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_170: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_207, 0);  mul_207 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_171: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_170, 2);  unsqueeze_170 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_172: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_171, 3);  unsqueeze_171 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_208: f32[256] = torch.ops.aten.mul.Tensor(squeeze_37, primals_38);  primals_38 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_173: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_208, 0);  mul_208 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_174: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_173, 2);  unsqueeze_173 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_175: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_174, 3);  unsqueeze_174 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_209: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_48, unsqueeze_172);  sub_48 = unsqueeze_172 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_50: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(where_6, mul_209);  mul_209 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_51: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(sub_50, unsqueeze_169);  sub_50 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_210: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_51, unsqueeze_175);  sub_51 = unsqueeze_175 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_211: f32[256] = torch.ops.aten.mul.Tensor(sum_17, squeeze_37);  sum_17 = squeeze_37 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_7 = torch.ops.aten.convolution_backward.default(mul_210, relu_8, primals_37, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_210 = primals_37 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_63: f32[64, 128, 1, 1] = convolution_backward_7[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_64: f32[256, 128, 1, 1] = convolution_backward_7[1];  convolution_backward_7 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_52: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_11, unsqueeze_178);  convolution_11 = unsqueeze_178 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_212: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(where_6, sub_52)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_19: f32[256] = torch.ops.aten.sum.dim_IntList(mul_212, [0, 2, 3]);  mul_212 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_214: f32[256] = torch.ops.aten.mul.Tensor(sum_19, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_215: f32[256] = torch.ops.aten.mul.Tensor(squeeze_34, squeeze_34)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_216: f32[256] = torch.ops.aten.mul.Tensor(mul_214, mul_215);  mul_214 = mul_215 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_182: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_216, 0);  mul_216 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_183: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_182, 2);  unsqueeze_182 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_184: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_183, 3);  unsqueeze_183 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_217: f32[256] = torch.ops.aten.mul.Tensor(squeeze_34, primals_35);  primals_35 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_185: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_217, 0);  mul_217 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_186: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_185, 2);  unsqueeze_185 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_187: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_186, 3);  unsqueeze_186 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_218: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_52, unsqueeze_184);  sub_52 = unsqueeze_184 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_54: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(where_6, mul_218);  where_6 = mul_218 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_55: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(sub_54, unsqueeze_169);  sub_54 = unsqueeze_169 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_219: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_55, unsqueeze_187);  sub_55 = unsqueeze_187 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_220: f32[256] = torch.ops.aten.mul.Tensor(sum_19, squeeze_34);  sum_19 = squeeze_34 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_8 = torch.ops.aten.convolution_backward.default(mul_219, relu_9, primals_34, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_219 = primals_34 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_66: f32[64, 256, 1, 1] = convolution_backward_8[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_67: f32[256, 256, 3, 3] = convolution_backward_8[1];  convolution_backward_8 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_7: b8[64, 256, 1, 1] = torch.ops.aten.le.Scalar(relu_9, 0);  relu_9 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_7: f32[64, 256, 1, 1] = torch.ops.aten.where.self(le_7, full_default, getitem_66);  le_7 = getitem_66 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_20: f32[256] = torch.ops.aten.sum.dim_IntList(where_7, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_56: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(convolution_10, unsqueeze_190);  convolution_10 = unsqueeze_190 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_221: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(where_7, sub_56)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_21: f32[256] = torch.ops.aten.sum.dim_IntList(mul_221, [0, 2, 3]);  mul_221 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_222: f32[256] = torch.ops.aten.mul.Tensor(sum_20, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_191: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_222, 0);  mul_222 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_192: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_191, 2);  unsqueeze_191 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_193: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_192, 3);  unsqueeze_192 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_223: f32[256] = torch.ops.aten.mul.Tensor(sum_21, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_224: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, squeeze_31)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_225: f32[256] = torch.ops.aten.mul.Tensor(mul_223, mul_224);  mul_223 = mul_224 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_194: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_225, 0);  mul_225 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_195: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_194, 2);  unsqueeze_194 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_196: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_195, 3);  unsqueeze_195 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_226: f32[256] = torch.ops.aten.mul.Tensor(squeeze_31, primals_32);  primals_32 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_197: f32[1, 256] = torch.ops.aten.unsqueeze.default(mul_226, 0);  mul_226 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_198: f32[1, 256, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_197, 2);  unsqueeze_197 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_199: f32[1, 256, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_198, 3);  unsqueeze_198 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_227: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_56, unsqueeze_196);  sub_56 = unsqueeze_196 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_58: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(where_7, mul_227);  where_7 = mul_227 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_59: f32[64, 256, 1, 1] = torch.ops.aten.sub.Tensor(sub_58, unsqueeze_193);  sub_58 = unsqueeze_193 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_228: f32[64, 256, 1, 1] = torch.ops.aten.mul.Tensor(sub_59, unsqueeze_199);  sub_59 = unsqueeze_199 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_229: f32[256] = torch.ops.aten.mul.Tensor(sum_21, squeeze_31);  sum_21 = squeeze_31 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_9 = torch.ops.aten.convolution_backward.default(mul_228, relu_8, primals_31, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_228 = primals_31 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_69: f32[64, 128, 1, 1] = convolution_backward_9[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_70: f32[256, 128, 3, 3] = convolution_backward_9[1];  convolution_backward_9 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_111: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(getitem_63, getitem_69);  getitem_63 = getitem_69 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_8: b8[64, 128, 1, 1] = torch.ops.aten.le.Scalar(relu_8, 0);  relu_8 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_8: f32[64, 128, 1, 1] = torch.ops.aten.where.self(le_8, full_default, add_111);  le_8 = add_111 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_22: f32[128] = torch.ops.aten.sum.dim_IntList(where_8, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_60: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_9, unsqueeze_202);  convolution_9 = unsqueeze_202 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_230: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(where_8, sub_60)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_23: f32[128] = torch.ops.aten.sum.dim_IntList(mul_230, [0, 2, 3]);  mul_230 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_231: f32[128] = torch.ops.aten.mul.Tensor(sum_22, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_203: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_231, 0);  mul_231 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_204: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_203, 2);  unsqueeze_203 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_205: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_204, 3);  unsqueeze_204 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_232: f32[128] = torch.ops.aten.mul.Tensor(sum_23, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_233: f32[128] = torch.ops.aten.mul.Tensor(squeeze_28, squeeze_28)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_234: f32[128] = torch.ops.aten.mul.Tensor(mul_232, mul_233);  mul_232 = mul_233 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_206: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_234, 0);  mul_234 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_207: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_206, 2);  unsqueeze_206 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_208: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_207, 3);  unsqueeze_207 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_235: f32[128] = torch.ops.aten.mul.Tensor(squeeze_28, primals_29);  primals_29 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_209: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_235, 0);  mul_235 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_210: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_209, 2);  unsqueeze_209 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_211: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_210, 3);  unsqueeze_210 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_236: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_60, unsqueeze_208);  sub_60 = unsqueeze_208 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_62: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(where_8, mul_236);  mul_236 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_63: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(sub_62, unsqueeze_205);  sub_62 = unsqueeze_205 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_237: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_63, unsqueeze_211);  sub_63 = unsqueeze_211 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_238: f32[128] = torch.ops.aten.mul.Tensor(sum_23, squeeze_28);  sum_23 = squeeze_28 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_10 = torch.ops.aten.convolution_backward.default(mul_237, relu_7, primals_28, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_237 = primals_28 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_72: f32[64, 128, 1, 1] = convolution_backward_10[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_73: f32[128, 128, 3, 3] = convolution_backward_10[1];  convolution_backward_10 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_9: b8[64, 128, 1, 1] = torch.ops.aten.le.Scalar(relu_7, 0);  relu_7 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_9: f32[64, 128, 1, 1] = torch.ops.aten.where.self(le_9, full_default, getitem_72);  le_9 = getitem_72 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_24: f32[128] = torch.ops.aten.sum.dim_IntList(where_9, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_64: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_8, unsqueeze_214);  convolution_8 = unsqueeze_214 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_239: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(where_9, sub_64)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_25: f32[128] = torch.ops.aten.sum.dim_IntList(mul_239, [0, 2, 3]);  mul_239 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_240: f32[128] = torch.ops.aten.mul.Tensor(sum_24, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_215: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_240, 0);  mul_240 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_216: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_215, 2);  unsqueeze_215 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_217: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_216, 3);  unsqueeze_216 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_241: f32[128] = torch.ops.aten.mul.Tensor(sum_25, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_242: f32[128] = torch.ops.aten.mul.Tensor(squeeze_25, squeeze_25)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_243: f32[128] = torch.ops.aten.mul.Tensor(mul_241, mul_242);  mul_241 = mul_242 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_218: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_243, 0);  mul_243 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_219: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_218, 2);  unsqueeze_218 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_220: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_219, 3);  unsqueeze_219 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_244: f32[128] = torch.ops.aten.mul.Tensor(squeeze_25, primals_26);  primals_26 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_221: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_244, 0);  mul_244 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_222: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_221, 2);  unsqueeze_221 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_223: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_222, 3);  unsqueeze_222 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_245: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_64, unsqueeze_220);  sub_64 = unsqueeze_220 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_66: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(where_9, mul_245);  where_9 = mul_245 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_67: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(sub_66, unsqueeze_217);  sub_66 = unsqueeze_217 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_246: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_67, unsqueeze_223);  sub_67 = unsqueeze_223 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_247: f32[128] = torch.ops.aten.mul.Tensor(sum_25, squeeze_25);  sum_25 = squeeze_25 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_11 = torch.ops.aten.convolution_backward.default(mul_246, relu_6, primals_25, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_246 = primals_25 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_75: f32[64, 128, 1, 1] = convolution_backward_11[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_76: f32[128, 128, 3, 3] = convolution_backward_11[1];  convolution_backward_11 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_112: f32[64, 128, 1, 1] = torch.ops.aten.add.Tensor(where_8, getitem_75);  where_8 = getitem_75 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_10: b8[64, 128, 1, 1] = torch.ops.aten.le.Scalar(relu_6, 0);  relu_6 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_10: f32[64, 128, 1, 1] = torch.ops.aten.where.self(le_10, full_default, add_112);  le_10 = add_112 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:114, code: shortcut = self.downsample(shortcut)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_26: f32[128] = torch.ops.aten.sum.dim_IntList(where_10, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_68: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_7, unsqueeze_226);  convolution_7 = unsqueeze_226 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_248: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(where_10, sub_68)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_27: f32[128] = torch.ops.aten.sum.dim_IntList(mul_248, [0, 2, 3]);  mul_248 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_249: f32[128] = torch.ops.aten.mul.Tensor(sum_26, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_227: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_249, 0);  mul_249 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_228: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_227, 2);  unsqueeze_227 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_229: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_228, 3);  unsqueeze_228 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_250: f32[128] = torch.ops.aten.mul.Tensor(sum_27, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_251: f32[128] = torch.ops.aten.mul.Tensor(squeeze_22, squeeze_22)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_252: f32[128] = torch.ops.aten.mul.Tensor(mul_250, mul_251);  mul_250 = mul_251 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_230: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_252, 0);  mul_252 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_231: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_230, 2);  unsqueeze_230 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_232: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_231, 3);  unsqueeze_231 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_253: f32[128] = torch.ops.aten.mul.Tensor(squeeze_22, primals_23);  primals_23 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_233: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_253, 0);  mul_253 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_234: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_233, 2);  unsqueeze_233 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_235: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_234, 3);  unsqueeze_234 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_254: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_68, unsqueeze_232);  sub_68 = unsqueeze_232 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_70: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(where_10, mul_254);  mul_254 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_71: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(sub_70, unsqueeze_229);  sub_70 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_255: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_71, unsqueeze_235);  sub_71 = unsqueeze_235 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_256: f32[128] = torch.ops.aten.mul.Tensor(sum_27, squeeze_22);  sum_27 = squeeze_22 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_12 = torch.ops.aten.convolution_backward.default(mul_255, relu_4, primals_22, [0], [2, 2], [0, 0], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_255 = primals_22 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_78: f32[64, 64, 2, 2] = convolution_backward_12[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_79: f32[128, 64, 1, 1] = convolution_backward_12[1];  convolution_backward_12 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_72: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_6, unsqueeze_238);  convolution_6 = unsqueeze_238 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_257: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(where_10, sub_72)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_29: f32[128] = torch.ops.aten.sum.dim_IntList(mul_257, [0, 2, 3]);  mul_257 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_259: f32[128] = torch.ops.aten.mul.Tensor(sum_29, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_260: f32[128] = torch.ops.aten.mul.Tensor(squeeze_19, squeeze_19)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_261: f32[128] = torch.ops.aten.mul.Tensor(mul_259, mul_260);  mul_259 = mul_260 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_242: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_261, 0);  mul_261 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_243: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_242, 2);  unsqueeze_242 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_244: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_243, 3);  unsqueeze_243 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_262: f32[128] = torch.ops.aten.mul.Tensor(squeeze_19, primals_20);  primals_20 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_245: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_262, 0);  mul_262 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_246: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_245, 2);  unsqueeze_245 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_247: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_246, 3);  unsqueeze_246 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_263: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_72, unsqueeze_244);  sub_72 = unsqueeze_244 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_74: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(where_10, mul_263);  where_10 = mul_263 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_75: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(sub_74, unsqueeze_229);  sub_74 = unsqueeze_229 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_264: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_75, unsqueeze_247);  sub_75 = unsqueeze_247 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_265: f32[128] = torch.ops.aten.mul.Tensor(sum_29, squeeze_19);  sum_29 = squeeze_19 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_13 = torch.ops.aten.convolution_backward.default(mul_264, relu_5, primals_19, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_264 = primals_19 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_81: f32[64, 128, 1, 1] = convolution_backward_13[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_82: f32[128, 128, 3, 3] = convolution_backward_13[1];  convolution_backward_13 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_11: b8[64, 128, 1, 1] = torch.ops.aten.le.Scalar(relu_5, 0);  relu_5 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_11: f32[64, 128, 1, 1] = torch.ops.aten.where.self(le_11, full_default, getitem_81);  le_11 = getitem_81 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_30: f32[128] = torch.ops.aten.sum.dim_IntList(where_11, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_76: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(convolution_5, unsqueeze_250);  convolution_5 = unsqueeze_250 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_266: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(where_11, sub_76)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_31: f32[128] = torch.ops.aten.sum.dim_IntList(mul_266, [0, 2, 3]);  mul_266 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_267: f32[128] = torch.ops.aten.mul.Tensor(sum_30, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_251: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_267, 0);  mul_267 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_252: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_251, 2);  unsqueeze_251 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_253: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_252, 3);  unsqueeze_252 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_268: f32[128] = torch.ops.aten.mul.Tensor(sum_31, 0.015625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_269: f32[128] = torch.ops.aten.mul.Tensor(squeeze_16, squeeze_16)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_270: f32[128] = torch.ops.aten.mul.Tensor(mul_268, mul_269);  mul_268 = mul_269 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_254: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_270, 0);  mul_270 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_255: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_254, 2);  unsqueeze_254 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_256: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_255, 3);  unsqueeze_255 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_271: f32[128] = torch.ops.aten.mul.Tensor(squeeze_16, primals_17);  primals_17 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_257: f32[1, 128] = torch.ops.aten.unsqueeze.default(mul_271, 0);  mul_271 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_258: f32[1, 128, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_257, 2);  unsqueeze_257 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_259: f32[1, 128, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_258, 3);  unsqueeze_258 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_272: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_76, unsqueeze_256);  sub_76 = unsqueeze_256 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_78: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(where_11, mul_272);  where_11 = mul_272 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_79: f32[64, 128, 1, 1] = torch.ops.aten.sub.Tensor(sub_78, unsqueeze_253);  sub_78 = unsqueeze_253 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_273: f32[64, 128, 1, 1] = torch.ops.aten.mul.Tensor(sub_79, unsqueeze_259);  sub_79 = unsqueeze_259 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_274: f32[128] = torch.ops.aten.mul.Tensor(sum_31, squeeze_16);  sum_31 = squeeze_16 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_14 = torch.ops.aten.convolution_backward.default(mul_273, relu_4, primals_16, [0], [2, 2], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_273 = primals_16 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_84: f32[64, 64, 2, 2] = convolution_backward_14[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_85: f32[128, 64, 3, 3] = convolution_backward_14[1];  convolution_backward_14 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_113: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(getitem_78, getitem_84);  getitem_78 = getitem_84 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_12: b8[64, 64, 2, 2] = torch.ops.aten.le.Scalar(relu_4, 0);  relu_4 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_12: f32[64, 64, 2, 2] = torch.ops.aten.where.self(le_12, full_default, add_113);  le_12 = add_113 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_32: f32[64] = torch.ops.aten.sum.dim_IntList(where_12, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_80: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_4, unsqueeze_262);  convolution_4 = unsqueeze_262 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_275: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(where_12, sub_80)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_33: f32[64] = torch.ops.aten.sum.dim_IntList(mul_275, [0, 2, 3]);  mul_275 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_276: f32[64] = torch.ops.aten.mul.Tensor(sum_32, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_263: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_276, 0);  mul_276 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_264: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_263, 2);  unsqueeze_263 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_265: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_264, 3);  unsqueeze_264 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_277: f32[64] = torch.ops.aten.mul.Tensor(sum_33, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_278: f32[64] = torch.ops.aten.mul.Tensor(squeeze_13, squeeze_13)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_279: f32[64] = torch.ops.aten.mul.Tensor(mul_277, mul_278);  mul_277 = mul_278 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_266: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_279, 0);  mul_279 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_267: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_266, 2);  unsqueeze_266 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_268: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_267, 3);  unsqueeze_267 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_280: f32[64] = torch.ops.aten.mul.Tensor(squeeze_13, primals_14);  primals_14 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_269: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_280, 0);  mul_280 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_270: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_269, 2);  unsqueeze_269 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_271: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_270, 3);  unsqueeze_270 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_281: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_80, unsqueeze_268);  sub_80 = unsqueeze_268 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_82: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(where_12, mul_281);  mul_281 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_83: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(sub_82, unsqueeze_265);  sub_82 = unsqueeze_265 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_282: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_83, unsqueeze_271);  sub_83 = unsqueeze_271 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_283: f32[64] = torch.ops.aten.mul.Tensor(sum_33, squeeze_13);  sum_33 = squeeze_13 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_15 = torch.ops.aten.convolution_backward.default(mul_282, relu_3, primals_13, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_282 = primals_13 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_87: f32[64, 64, 2, 2] = convolution_backward_15[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_88: f32[64, 64, 3, 3] = convolution_backward_15[1];  convolution_backward_15 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_13: b8[64, 64, 2, 2] = torch.ops.aten.le.Scalar(relu_3, 0);  relu_3 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_13: f32[64, 64, 2, 2] = torch.ops.aten.where.self(le_13, full_default, getitem_87);  le_13 = getitem_87 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_34: f32[64] = torch.ops.aten.sum.dim_IntList(where_13, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_84: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_3, unsqueeze_274);  convolution_3 = unsqueeze_274 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_284: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(where_13, sub_84)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_35: f32[64] = torch.ops.aten.sum.dim_IntList(mul_284, [0, 2, 3]);  mul_284 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_285: f32[64] = torch.ops.aten.mul.Tensor(sum_34, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_275: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_285, 0);  mul_285 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_276: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_275, 2);  unsqueeze_275 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_277: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_276, 3);  unsqueeze_276 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_286: f32[64] = torch.ops.aten.mul.Tensor(sum_35, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_287: f32[64] = torch.ops.aten.mul.Tensor(squeeze_10, squeeze_10)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_288: f32[64] = torch.ops.aten.mul.Tensor(mul_286, mul_287);  mul_286 = mul_287 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_278: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_288, 0);  mul_288 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_279: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_278, 2);  unsqueeze_278 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_280: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_279, 3);  unsqueeze_279 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_289: f32[64] = torch.ops.aten.mul.Tensor(squeeze_10, primals_11);  primals_11 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_281: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_289, 0);  mul_289 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_282: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_281, 2);  unsqueeze_281 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_283: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_282, 3);  unsqueeze_282 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_290: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_84, unsqueeze_280);  sub_84 = unsqueeze_280 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_86: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(where_13, mul_290);  where_13 = mul_290 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_87: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(sub_86, unsqueeze_277);  sub_86 = unsqueeze_277 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_291: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_87, unsqueeze_283);  sub_87 = unsqueeze_283 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_292: f32[64] = torch.ops.aten.mul.Tensor(sum_35, squeeze_10);  sum_35 = squeeze_10 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_16 = torch.ops.aten.convolution_backward.default(mul_291, relu_2, primals_10, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_291 = primals_10 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_90: f32[64, 64, 2, 2] = convolution_backward_16[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_91: f32[64, 64, 3, 3] = convolution_backward_16[1];  convolution_backward_16 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_114: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(where_12, getitem_90);  where_12 = getitem_90 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:116, code: x = self.act2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_14: b8[64, 64, 2, 2] = torch.ops.aten.le.Scalar(relu_2, 0);  relu_2 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_14: f32[64, 64, 2, 2] = torch.ops.aten.where.self(le_14, full_default, add_114);  le_14 = add_114 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:105, code: x = self.bn2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_36: f32[64] = torch.ops.aten.sum.dim_IntList(where_14, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_88: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_2, unsqueeze_286);  convolution_2 = unsqueeze_286 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_293: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(where_14, sub_88)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_37: f32[64] = torch.ops.aten.sum.dim_IntList(mul_293, [0, 2, 3]);  mul_293 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_294: f32[64] = torch.ops.aten.mul.Tensor(sum_36, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_287: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_294, 0);  mul_294 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_288: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_287, 2);  unsqueeze_287 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_289: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_288, 3);  unsqueeze_288 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_295: f32[64] = torch.ops.aten.mul.Tensor(sum_37, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_296: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, squeeze_7)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_297: f32[64] = torch.ops.aten.mul.Tensor(mul_295, mul_296);  mul_295 = mul_296 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_290: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_297, 0);  mul_297 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_291: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_290, 2);  unsqueeze_290 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_292: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_291, 3);  unsqueeze_291 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_298: f32[64] = torch.ops.aten.mul.Tensor(squeeze_7, primals_8);  primals_8 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_293: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_298, 0);  mul_298 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_294: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_293, 2);  unsqueeze_293 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_295: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_294, 3);  unsqueeze_294 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_299: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_88, unsqueeze_292);  sub_88 = unsqueeze_292 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_90: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(where_14, mul_299);  mul_299 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_91: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(sub_90, unsqueeze_289);  sub_90 = unsqueeze_289 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_300: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_91, unsqueeze_295);  sub_91 = unsqueeze_295 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_301: f32[64] = torch.ops.aten.mul.Tensor(sum_37, squeeze_7);  sum_37 = squeeze_7 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:104, code: x = self.conv2(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_17 = torch.ops.aten.convolution_backward.default(mul_300, relu_1, primals_7, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_300 = primals_7 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_93: f32[64, 64, 2, 2] = convolution_backward_17[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_94: f32[64, 64, 3, 3] = convolution_backward_17[1];  convolution_backward_17 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:101, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_15: b8[64, 64, 2, 2] = torch.ops.aten.le.Scalar(relu_1, 0);  relu_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_15: f32[64, 64, 2, 2] = torch.ops.aten.where.self(le_15, full_default, getitem_93);  le_15 = getitem_93 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:99, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_38: f32[64] = torch.ops.aten.sum.dim_IntList(where_15, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_92: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(convolution_1, unsqueeze_298);  convolution_1 = unsqueeze_298 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_302: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(where_15, sub_92)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_39: f32[64] = torch.ops.aten.sum.dim_IntList(mul_302, [0, 2, 3]);  mul_302 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_303: f32[64] = torch.ops.aten.mul.Tensor(sum_38, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_299: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_303, 0);  mul_303 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_300: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_299, 2);  unsqueeze_299 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_301: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_300, 3);  unsqueeze_300 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_304: f32[64] = torch.ops.aten.mul.Tensor(sum_39, 0.00390625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_305: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, squeeze_4)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_306: f32[64] = torch.ops.aten.mul.Tensor(mul_304, mul_305);  mul_304 = mul_305 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_302: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_306, 0);  mul_306 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_303: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_302, 2);  unsqueeze_302 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_304: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_303, 3);  unsqueeze_303 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_307: f32[64] = torch.ops.aten.mul.Tensor(squeeze_4, primals_5);  primals_5 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_305: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_307, 0);  mul_307 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_306: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_305, 2);  unsqueeze_305 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_307: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_306, 3);  unsqueeze_306 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_308: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_92, unsqueeze_304);  sub_92 = unsqueeze_304 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_94: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(where_15, mul_308);  where_15 = mul_308 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_95: f32[64, 64, 2, 2] = torch.ops.aten.sub.Tensor(sub_94, unsqueeze_301);  sub_94 = unsqueeze_301 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_309: f32[64, 64, 2, 2] = torch.ops.aten.mul.Tensor(sub_95, unsqueeze_307);  sub_95 = unsqueeze_307 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_310: f32[64] = torch.ops.aten.mul.Tensor(sum_39, squeeze_4);  sum_39 = squeeze_4 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_18 = torch.ops.aten.convolution_backward.default(mul_309, getitem_2, primals_4, [0], [1, 1], [1, 1], [1, 1], False, [0, 0], 1, [True, True, False]);  mul_309 = getitem_2 = primals_4 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_96: f32[64, 64, 2, 2] = convolution_backward_18[0]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_97: f32[64, 64, 3, 3] = convolution_backward_18[1];  convolution_backward_18 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:98, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         add_115: f32[64, 64, 2, 2] = torch.ops.aten.add.Tensor(where_14, getitem_96);  where_14 = getitem_96 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:523, code: x = self.maxpool(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         max_pool2d_with_indices_backward: f32[64, 64, 4, 4] = torch.ops.aten.max_pool2d_with_indices_backward.default(add_115, relu, [3, 3], [2, 2], [1, 1], [1, 1], False, getitem_3);  add_115 = getitem_3 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:522, code: x = self.act1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         le_16: b8[64, 64, 4, 4] = torch.ops.aten.le.Scalar(relu, 0);  relu = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         where_16: f32[64, 64, 4, 4] = torch.ops.aten.where.self(le_16, full_default, max_pool2d_with_indices_backward);  le_16 = full_default = max_pool2d_with_indices_backward = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:521, code: x = self.bn1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_40: f32[64] = torch.ops.aten.sum.dim_IntList(where_16, [0, 2, 3])\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_96: f32[64, 64, 4, 4] = torch.ops.aten.sub.Tensor(convolution, unsqueeze_310);  convolution = unsqueeze_310 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_311: f32[64, 64, 4, 4] = torch.ops.aten.mul.Tensor(where_16, sub_96)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sum_41: f32[64] = torch.ops.aten.sum.dim_IntList(mul_311, [0, 2, 3]);  mul_311 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_312: f32[64] = torch.ops.aten.mul.Tensor(sum_40, 0.0009765625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_311: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_312, 0);  mul_312 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_312: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_311, 2);  unsqueeze_311 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_313: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_312, 3);  unsqueeze_312 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_313: f32[64] = torch.ops.aten.mul.Tensor(sum_41, 0.0009765625)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_314: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, squeeze_1)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_315: f32[64] = torch.ops.aten.mul.Tensor(mul_313, mul_314);  mul_313 = mul_314 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_314: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_315, 0);  mul_315 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_315: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_314, 2);  unsqueeze_314 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_316: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_315, 3);  unsqueeze_315 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_316: f32[64] = torch.ops.aten.mul.Tensor(squeeze_1, primals_2);  primals_2 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_317: f32[1, 64] = torch.ops.aten.unsqueeze.default(mul_316, 0);  mul_316 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_318: f32[1, 64, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_317, 2);  unsqueeze_317 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         unsqueeze_319: f32[1, 64, 1, 1] = torch.ops.aten.unsqueeze.default(unsqueeze_318, 3);  unsqueeze_318 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_317: f32[64, 64, 4, 4] = torch.ops.aten.mul.Tensor(sub_96, unsqueeze_316);  sub_96 = unsqueeze_316 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_98: f32[64, 64, 4, 4] = torch.ops.aten.sub.Tensor(where_16, mul_317);  where_16 = mul_317 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         sub_99: f32[64, 64, 4, 4] = torch.ops.aten.sub.Tensor(sub_98, unsqueeze_313);  sub_98 = unsqueeze_313 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_318: f32[64, 64, 4, 4] = torch.ops.aten.mul.Tensor(sub_99, unsqueeze_319);  sub_99 = unsqueeze_319 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         mul_319: f32[64] = torch.ops.aten.mul.Tensor(sum_41, squeeze_1);  sum_41 = squeeze_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         # File: /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:520, code: x = self.conv1(x)\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         convolution_backward_19 = torch.ops.aten.convolution_backward.default(mul_318, primals_123, primals_1, [0], [2, 2], [3, 3], [1, 1], False, [0, 0], 1, [False, True, False]);  mul_318 = primals_123 = primals_1 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         getitem_100: f32[64, 3, 7, 7] = convolution_backward_19[1];  convolution_backward_19 = None\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         return [getitem_100, mul_319, sum_40, getitem_97, mul_310, sum_38, getitem_94, mul_301, sum_36, getitem_91, mul_292, sum_34, getitem_88, mul_283, sum_32, getitem_85, mul_274, sum_30, getitem_82, mul_265, sum_26, getitem_79, mul_256, sum_26, getitem_76, mul_247, sum_24, getitem_73, mul_238, sum_22, getitem_70, mul_229, sum_20, getitem_67, mul_220, sum_16, getitem_64, mul_211, sum_16, getitem_61, mul_202, sum_14, getitem_58, mul_193, sum_12, getitem_55, mul_184, sum_10, getitem_52, mul_175, sum_6, getitem_49, mul_166, sum_6, getitem_46, mul_157, sum_4, getitem_43, mul_148, sum_2, permute_4, view_1, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO]         \n",
      "[2023-09-07 14:58:48,929] [5/0] torch._functorch.aot_autograd.__aot_graphs: [INFO] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1540e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1752e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2432e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1030e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5335e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2622e-02],\n",
       "        [ 4.4532e-01,  7.0079e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0302e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AOTAutograd Lowering - forwards & backwards pass\n",
    "torch._logging.set_logs(graph_code=True, aot_graphs=True)\n",
    "torch._dynamo.reset()\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inductor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 15:00:05,880] [6/0] torch._inductor.compile_fx: [INFO] Step 3: torchinductor compiling FORWARDS graph 6\n",
      "[2023-09-07 15:00:07,022] [6/0] torch._inductor.graph: [DEBUG] Force channels last inputs for 20 conv for the current graph with id 6\n",
      "[2023-09-07 15:00:07,670] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf24\n",
      "[2023-09-07 15:00:07,670] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf37\n",
      "[2023-09-07 15:00:07,671] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf48\n",
      "[2023-09-07 15:00:07,671] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf59\n",
      "[2023-09-07 15:00:07,671] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf70\n",
      "[2023-09-07 15:00:07,672] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf78\n",
      "[2023-09-07 15:00:07,672] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf86\n",
      "[2023-09-07 15:00:07,672] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf93\n",
      "[2023-09-07 15:00:07,673] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf102\n",
      "[2023-09-07 15:00:07,673] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf110\n",
      "[2023-09-07 15:00:07,673] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf118\n",
      "[2023-09-07 15:00:07,673] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf126\n",
      "[2023-09-07 15:00:07,674] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf133\n",
      "[2023-09-07 15:00:07,674] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf142\n",
      "[2023-09-07 15:00:07,674] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf150\n",
      "[2023-09-07 15:00:07,675] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf158\n",
      "[2023-09-07 15:00:07,675] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf166\n",
      "[2023-09-07 15:00:07,675] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf173\n",
      "[2023-09-07 15:00:07,676] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf182\n",
      "[2023-09-07 15:00:07,676] [6/0] torch._inductor.scheduler: [DEBUG] removed dead node: buf190\n",
      "[2023-09-07 15:00:07,726] [6/0] torch._inductor.scheduler: [INFO] Number of scheduler nodes after fusion 102\n",
      "[2023-09-07 15:00:08,235] [6/0] torch._inductor.scheduler: [DEBUG] remove_buffer('buf194')\n",
      "[2023-09-07 15:00:08,295] [6/0] torch._inductor.graph: [DEBUG] Output code written to: /tmp/torchinductor_root/iq/ciqegoc3cigmvkqeaytmfiekrtinzr4hgvnrgl4fhnlec5v75iha.py\n",
      "[2023-09-07 15:00:08,296] [6/0] torch._inductor.compile_fx: [INFO] Step 3: torchinductor done compiling FORWARDS graph 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1540e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1752e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2432e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1030e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5335e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2622e-02],\n",
       "        [ 4.4532e-01,  7.0079e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0301e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._logging.set_logs(inductor=logging.DEBUG)\n",
    "torch._dynamo.reset()\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 15:00:49,059] [7/0] torch._inductor.graph.__output_code: [INFO] Output code written to: /tmp/torchinductor_root/iq/ciqegoc3cigmvkqeaytmfiekrtinzr4hgvnrgl4fhnlec5v75iha.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] Output code: \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from ctypes import c_void_p, c_long\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import torch\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import math\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import random\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import os\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import tempfile\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from math import inf, nan\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.hooks import run_intermediate_hooks\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import maybe_profile\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch import empty_strided, device\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.codecache import AsyncCompile\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.select_algorithm import extern_kernels\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] aten = torch.ops.aten\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] assert_size_stride = torch._C._dynamo.guards.assert_size_stride\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] reinterpret_tensor = torch.ops.inductor._reinterpret_tensor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] async_compile = AsyncCompile()\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/sy/csy4pmse4puptclk7z2xiyyi4zbmpcmg5hmjoflfywzjtvq3cuww.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_0 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[256, 64], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 192\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 49\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 3)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (49*y3)), xmask & ymask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (3*x2) + (147*y1)), tmp0, xmask & ymask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import grid, start_graph, end_graph\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._C import _cuda_getCurrentRawStream as get_cuda_stream\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/ol/colrzzexyhjdujnvcfmofznluxqvsmcb7x56ttirnena5enimaul.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_1 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[4096, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 4096\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/62/c62fdytygikocg3pibr7jlauh5wp4cinzfjcxwpugorr6tjv5kve.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_2 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8192, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_2', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 8192\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (64*x2) + (576*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/4y/c4ypx3l3marie4pnhfburbcf6k3rdgcb7fsfywfj3gc7cvvs57kn.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_3 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_3', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 128)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/jy/cjyhajnkyz6dvjwxjcudgvqbtknthiwov7gietc3yuevvyq4kskc.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_4 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[32768, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_4', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 32768\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 128)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (128*x2) + (1152*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/zs/czskyzdpm4ayyq6bmxyn3xsufc3hv3mrqaipw2hvnbb5bqthwu56.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_5 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[65536, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_5', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 65536\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 256\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 256)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/nc/cncsm62kamdb4sha5joqf2yobxdszg545bzjm6kcqxuezbdoffys.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_6 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[131072, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_6', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 131072\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 256\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 256)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (256*x2) + (2304*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/w3/cw3vjzv7u2xtbnbupkyqdbhkpk4ejswkooh5tdzhrghqkkpm5clv.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_7 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[262144, 16], tile_hint=TileHint.SQUARE,filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_7', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(2,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, ynumel, xnumel, YBLOCK : tl.constexpr, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ynumel = 262144\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yoffset = tl.program_id(1) * YBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     yindex = yoffset + tl.arange(0, YBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     ymask = yindex < ynumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y3 = yindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y0 = yindex % 512\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     y1 = (yindex // 512)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2 + (9*y3)), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (y0 + (512*x2) + (4608*y1)), tmp0, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/6h/c6hcr3omrvqxb3mg3uaakhudlxycmolkcneqedvsy4zrf5kgm2hp.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => var_mean\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_8 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 128],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_8', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 512\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/32/c32amhlgadqa6rn4muxjjrirjmourlzwd7ueincmc2cbzacp7et7.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => add_1, add_2, add_3, mul_1, mul_2, mul_3, mul_4, mul_5, rsqrt, squeeze_1, var_mean\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_9 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[64, 8],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_9', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10, 11))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 1024.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.0009775171065494\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/ce/ccemgqzplispn4u3vtypnmgulozohkcgv5dw42i7mrnsfj3zbt4r.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___act1, l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___act1 => relu\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => add_1, add_4, mul, mul_6, rsqrt, sub, var_mean\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_10 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[65536], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_10', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 65536\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 1024.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/vc/cvciwzcqdzlmpjnturthvidmzahmoosfg3mnvnlkorumzqncgiyp.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___maxpool], Original ATen: [aten.max_pool2d_with_indices]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___maxpool => getitem_2, getitem_3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_max_pool2d_with_indices_11 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*i64', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_max_pool2d_with_indices_11', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(3,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = (xindex // 128) % 2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 64) % 2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x5 = (xindex // 128)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x6 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = (-1) + (2*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.full([1], 0, tl.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 >= tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.full([1], 4, tl.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp0 < tmp3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp2 & tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = (-1) + (2*x1)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp6 >= tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tmp6 < tmp3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp7 & tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp5 & tmp9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tl.load(in_ptr0 + ((-320) + x0 + (128*x1) + (512*x5)), tmp10, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.where(tmp10, tmp11, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = 2*x1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp13 >= tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 < tmp3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 & tmp15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp5 & tmp16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tl.load(in_ptr0 + ((-256) + x0 + (128*x1) + (512*x5)), tmp17, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tl.where(tmp17, tmp18, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = triton_helpers.maximum(tmp19, tmp12)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1 + (2*x1)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp21 >= tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 < tmp3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 & tmp23\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp5 & tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tl.load(in_ptr0 + ((-192) + x0 + (128*x1) + (512*x5)), tmp25, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tl.where(tmp25, tmp26, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = triton_helpers.maximum(tmp27, tmp20)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = 2*x2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tmp29 >= tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp29 < tmp3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp30 & tmp31\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp33 = tmp32 & tmp9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp34 = tl.load(in_ptr0 + ((-64) + x0 + (128*x1) + (512*x5)), tmp33, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp35 = tl.where(tmp33, tmp34, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp36 = triton_helpers.maximum(tmp35, tmp28)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp37 = tmp32 & tmp16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp38 = tl.load(in_ptr0 + (x0 + (128*x1) + (512*x5)), tmp37, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp39 = tl.where(tmp37, tmp38, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp40 = triton_helpers.maximum(tmp39, tmp36)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp41 = tmp32 & tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp42 = tl.load(in_ptr0 + (64 + x0 + (128*x1) + (512*x5)), tmp41, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp43 = tl.where(tmp41, tmp42, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp44 = triton_helpers.maximum(tmp43, tmp40)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp45 = 1 + (2*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp46 = tmp45 >= tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp47 = tmp45 < tmp3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp48 = tmp46 & tmp47\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp49 = tmp48 & tmp9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp50 = tl.load(in_ptr0 + (192 + x0 + (128*x1) + (512*x5)), tmp49, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp51 = tl.where(tmp49, tmp50, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp52 = triton_helpers.maximum(tmp51, tmp44)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp53 = tmp48 & tmp16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp54 = tl.load(in_ptr0 + (256 + x0 + (128*x1) + (512*x5)), tmp53, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp55 = tl.where(tmp53, tmp54, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp56 = triton_helpers.maximum(tmp55, tmp52)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp57 = tmp48 & tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp58 = tl.load(in_ptr0 + (320 + x0 + (128*x1) + (512*x5)), tmp57, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp59 = tl.where(tmp57, tmp58, float(\"-inf\"))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp60 = triton_helpers.maximum(tmp59, tmp56)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp61 = tmp19 > tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp62 = (-4) + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp63 = (-5) + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp64 = tl.where(tmp61, tmp62, tmp63)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp65 = tmp27 > tmp20\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp66 = (-3) + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp67 = tl.where(tmp65, tmp66, tmp64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp68 = tmp35 > tmp28\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp69 = (-1) + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp70 = tl.where(tmp68, tmp69, tmp67)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp71 = tmp39 > tmp36\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp72 = (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp73 = tl.where(tmp71, tmp72, tmp70)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp74 = tmp43 > tmp40\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp75 = 1 + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp76 = tl.where(tmp74, tmp75, tmp73)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp77 = tmp51 > tmp44\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp78 = 3 + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp79 = tl.where(tmp77, tmp78, tmp76)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp80 = tmp55 > tmp52\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp81 = 4 + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp82 = tl.where(tmp80, tmp81, tmp79)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp83 = tmp59 > tmp56\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp84 = 5 + (2*x1) + (8*x2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp85 = tl.where(tmp83, tmp84, tmp82)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x6), tmp60, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x6), tmp85, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/zs/czsxljwwrzy6cbtrsepuniiswfzvfw5ay3bawfu7txxucb66cwmq.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn1 => var_mean_1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_red_fused__native_batch_norm_legit_functional_12 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[128, 128],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: 'i32', 5: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_red_fused__native_batch_norm_legit_functional_12', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(4, 5))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, out_ptr1, out_ptr2, xnumel, rnumel, XBLOCK : tl.constexpr, RBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rbase = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x1 = (xindex // 64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_mean = tl.zeros([XBLOCK, RBLOCK], tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_m2 = tl.zeros([XBLOCK, RBLOCK], tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_weight = tl.zeros([XBLOCK, RBLOCK], tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x3 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     for roffset in range(0, rnumel, RBLOCK):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         rindex = roffset + rbase\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         r2 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp0 = tl.load(in_ptr0 + (x0 + (64*r2) + (8192*x1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean_next, tmp2_m2_next, tmp2_weight_next = triton_helpers.welford_reduce(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]             tmp1, tmp2_mean, tmp2_m2, tmp2_weight,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean = tl.where(rmask & xmask, tmp2_mean_next, tmp2_mean)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_m2 = tl.where(rmask & xmask, tmp2_m2_next, tmp2_m2)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_weight = tl.where(rmask & xmask, tmp2_weight_next, tmp2_weight)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2_tmp, tmp3_tmp, tmp4_tmp = triton_helpers.welford(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         tmp2_mean, tmp2_m2, tmp2_weight, 1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp2_tmp[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp3_tmp[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tmp4_tmp[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x3), tmp2, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x3), tmp3, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x3), tmp4, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/oc/cochqjx5aejxcqostxzsjflrpgtzo3xecaesfdukhukm7wpbsmbk.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn1 => add_6, add_7, add_8, mul_10, mul_11, mul_12, mul_8, mul_9, rsqrt_1, squeeze_4, var_mean_1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_13 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[64, 2],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.OUTER_TINY,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: 'i32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_13', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(10,))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (64*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0 + (64*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.load(in_ptr2 + (x0 + (64*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tl.load(in_ptr3 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tl.load(in_ptr4 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tl.broadcast_to(tmp2, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.where(rmask & xmask, tmp3, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.where(rmask & xmask, tmp4, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tl.where(rmask & xmask, tmp5, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10, tmp11, tmp12 = triton_helpers.welford(tmp7, tmp8, tmp9, 1)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp10[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tmp11[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp12[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = 256.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tmp14 / tmp16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp17 + tmp18\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = 1.003921568627451\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tmp17 * tmp21\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = 0.1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tmp22 * tmp23\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = 0.9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = tmp25 * tmp26\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp24 + tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp13 * tmp23\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tmp30 * tmp26\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp29 + tmp31\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp20, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp28, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp32, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp13, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp14, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/qu/cqupbf6pq4hvfgbvtslwutids6pszazvy66otpjlqxzdklw46d3b.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___act1, getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___act1 => relu_1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn1 => add_6, add_9, mul_13, mul_7, rsqrt_1, sub_1, var_mean_1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_14 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_14', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 256.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/gm/cgm2ak4wxirxsdcge6khr2jesrtaxfrrah4mkynj4erwapgby7pn.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer1___0___act2, getattr_l__self___layer1___0___bn2, iadd], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___act2 => relu_2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer1___0___bn2 => add_11, add_14, mul_14, mul_20, rsqrt_2, sub_2, var_mean_2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd => add_15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_15 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_15', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 256.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/vn/cvnshr3wnh2bet66bhlfb63zcjlx5xftiwpgpmcao4s4eytqwaml.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn1 => add_28, add_29, add_30, mul_36, mul_37, mul_38, mul_39, mul_40, rsqrt_5, squeeze_16, var_mean_5\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_16 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[128, 64],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.INNER,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_16', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (128*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.where(rmask & xmask, tmp1, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tl.where(rmask & xmask, tmp4, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.sum(tmp6, 1)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.full([XBLOCK, 1], 64, tl.int32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp8.to(tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp7 / tmp9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp1 - tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp11 * tmp11\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tl.broadcast_to(tmp12, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.where(rmask & xmask, tmp13, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tl.sum(tmp15, 1)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp16 / tmp17\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp18 + tmp19\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tl.math.rsqrt(tmp20)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = 1.0158730158730158\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp18 * tmp22\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = 0.1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 * tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = 0.9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp26 * tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp25 + tmp28\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tmp10 * tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp31 * tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp33 = tmp30 + tmp32\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp21, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp29, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp33, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp10, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp16, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/ne/cnetcl6lewpfkgzetsfbq55zf66gjm2uv3a4gzcbyropzmrhpfws.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___act1, getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___act1 => relu_5\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn1 => add_28, add_31, mul_35, mul_41, rsqrt_5, sub_5, var_mean_5\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_17 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8192], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_17', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 8192\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/6x/c6x3luqwxl4hsbq2h57wxaaadahhwzr7r4hku5d3ofbcarayuo6q.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___0___act2, getattr_l__self___layer2___0___bn2, getattr_l__self___layer2___0___downsample_1, iadd_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___act2 => relu_6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___bn2 => add_33, add_36, mul_42, mul_48, rsqrt_6, sub_6, var_mean_6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___0___downsample_1 => add_38, add_41, mul_49, mul_55, rsqrt_7, sub_7, var_mean_7\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_2 => add_42\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_18 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8192], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_18', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 8192\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/yd/cydgx6twni35hsfxm7ozgmc5ks7blxynxvvofswvyjbjo3qpmzkm.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer2___1___act2, getattr_l__self___layer2___1___bn2, iadd_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___1___act2 => relu_8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer2___1___bn2 => add_49, add_52, mul_63, mul_69, rsqrt_9, sub_9, var_mean_9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_3 => add_53\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_19 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[8192], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_19', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 8192\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 128\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/3d/c3dvk2vf2lcfj7jap7wwa46gbalrnjqetercwiut6wquksqb6vxs.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn1 => add_55, add_56, add_57, mul_71, mul_72, mul_73, mul_74, mul_75, rsqrt_10, squeeze_31, var_mean_10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_20 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[256, 64],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.INNER,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_20', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 256\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (256*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.where(rmask & xmask, tmp1, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tl.where(rmask & xmask, tmp4, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.sum(tmp6, 1)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.full([XBLOCK, 1], 64, tl.int32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp8.to(tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp7 / tmp9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp1 - tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp11 * tmp11\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tl.broadcast_to(tmp12, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.where(rmask & xmask, tmp13, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tl.sum(tmp15, 1)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp16 / tmp17\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp18 + tmp19\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tl.math.rsqrt(tmp20)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = 1.0158730158730158\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp18 * tmp22\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = 0.1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 * tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = 0.9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp26 * tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp25 + tmp28\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tmp10 * tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp31 * tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp33 = tmp30 + tmp32\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp21, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp29, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp33, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp10, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp16, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/hk/chkcwkalniwaafmovfklbqac7c3g4qrhvlmjwtiiev2nd7skza2c.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___act1, getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___act1 => relu_9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn1 => add_55, add_58, mul_70, mul_76, rsqrt_10, sub_10, var_mean_10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_21 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_21', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/hb/chbcffbhhwnwdtljnfd4o66jiysm4ylkyge35h623w655i5qo4bd.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___0___act2, getattr_l__self___layer3___0___bn2, getattr_l__self___layer3___0___downsample_1, iadd_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___act2 => relu_10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___bn2 => add_60, add_63, mul_77, mul_83, rsqrt_11, sub_11, var_mean_11\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___0___downsample_1 => add_65, add_68, mul_84, mul_90, rsqrt_12, sub_12, var_mean_12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_4 => add_69\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_22 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_22', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/3a/c3ak2vn5rdncevfxeg5awtrigdcu5sseg2rm5ubzddgw2hfiht7e.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer3___1___act2, getattr_l__self___layer3___1___bn2, iadd_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___1___act2 => relu_12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer3___1___bn2 => add_76, add_79, mul_104, mul_98, rsqrt_14, sub_14, var_mean_14\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_5 => add_80\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_23 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[16384], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_23', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(7,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 16384\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 256\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp16, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/34/c34zaxu6afzsrmcyg66cjos555ygez7syixdaipj6cttz74ajowl.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn1 => add_82, add_83, add_84, mul_106, mul_107, mul_108, mul_109, mul_110, rsqrt_15, squeeze_46, var_mean_15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_per_fused__native_batch_norm_legit_functional_24 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, persistent_reduction\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @persistent_reduction(\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     size_hints=[512, 64],\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     reduction_hint=ReductionHint.INNER,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     filename=__file__,\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: 'i32', 9: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_per_fused__native_batch_norm_legit_functional_24', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8, 9))]}\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, out_ptr0, out_ptr1, out_ptr2, out_ptr3, out_ptr4, xnumel, rnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 512\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rnumel = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     RBLOCK: tl.constexpr = 64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rindex = tl.arange(0, RBLOCK)[None, :]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     rmask = rindex < rnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     r1 = rindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x0 + (512*r1)), rmask & xmask, other=0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tl.load(in_ptr1 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp31 = tl.load(in_ptr2 + (x0), xmask, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.where(rmask & xmask, tmp1, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = tl.broadcast_to(tmp1, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = tl.where(rmask & xmask, tmp4, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tl.sum(tmp6, 1)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.full([XBLOCK, 1], 64, tl.int32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp8.to(tl.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tmp7 / tmp9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp1 - tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tmp11 * tmp11\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tl.broadcast_to(tmp12, [XBLOCK, RBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.where(rmask & xmask, tmp13, 0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tl.sum(tmp15, 1)[:, None]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp16 / tmp17\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp18 + tmp19\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tl.math.rsqrt(tmp20)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = 1.0158730158730158\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp18 * tmp22\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = 0.1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 * tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = 0.9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp28 = tmp26 * tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp29 = tmp25 + tmp28\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp30 = tmp10 * tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp32 = tmp31 * tmp27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp33 = tmp30 + tmp32\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x0), tmp21, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr3 + (x0), tmp29, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr4 + (x0), tmp33, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x0), tmp10, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x0), tmp16, xmask)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/cc/cccww3wjjtsgplekonfh7xb2j6fa4t3eewxheolvqwcrxlp7fkwb.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___act1, getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___act1 => relu_13\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn1 => add_82, add_85, mul_105, mul_111, rsqrt_15, sub_15, var_mean_15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_relu_25 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[32768], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_relu_25', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(6,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 32768\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = triton_helpers.maximum(0, tmp13)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (x2), tmp14, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/bq/cbqcqorfc64knklkf5ap22nomp76oivcjcmha526uprprgwpglee.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___0___act2, getattr_l__self___layer4___0___bn2, getattr_l__self___layer4___0___downsample_1, iadd_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___act2 => relu_14\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___bn2 => add_87, add_90, mul_112, mul_118, rsqrt_16, sub_16, var_mean_16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___0___downsample_1 => add_92, add_95, mul_119, mul_125, rsqrt_17, sub_17, var_mean_17\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_6 => add_96\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_relu_26 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[32768], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*fp32', 8: '*fp32', 9: '*fp32', 10: '*fp32', 11: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': ['in_out_ptr0'], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_relu_26', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(11,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_out_ptr0, in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, in_ptr6, in_ptr7, in_ptr8, in_ptr9, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 32768\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tl.load(in_ptr6 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = tl.load(in_ptr7 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp22 = tl.load(in_ptr8 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp24 = tl.load(in_ptr9 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = tmp14 - tmp15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp17 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = tmp18 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tl.math.rsqrt(tmp19)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp21 = tmp16 * tmp20\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp23 = tmp21 * tmp22\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp25 = tmp23 + tmp24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp26 = tmp13 + tmp25\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp27 = triton_helpers.maximum(0, tmp26)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(in_out_ptr0 + (x2), tmp27, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/c2/cc27w67nspky6gngfzckz3ahwapysfqwhlvipqoquqsvamnwnais.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [getattr_l__self___layer4___1___act2, getattr_l__self___layer4___1___bn2, iadd_7, l__self___global_pool_flatten, l__self___global_pool_pool], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.mean, aten.relu, aten.threshold_backward, aten.view]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___1___act2 => relu_16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # getattr_l__self___layer4___1___bn2 => add_103, add_106, mul_133, mul_139, rsqrt_19, sub_19, var_mean_19\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # iadd_7 => add_107\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___global_pool_flatten => view\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___global_pool_pool => mean\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused__native_batch_norm_legit_functional_add_mean_relu_threshold_backward_view_27 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[32768], filename=__file__, meta={'signature': {0: '*fp32', 1: '*fp32', 2: '*fp32', 3: '*fp32', 4: '*fp32', 5: '*fp32', 6: '*fp32', 7: '*i1', 8: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused__native_batch_norm_legit_functional_add_mean_relu_threshold_backward_view_27', 'configs': [instance_descriptor(divisible_by_16=(0, 1, 2, 3, 4, 5, 6, 7, 8), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=(8,))]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, in_ptr1, in_ptr2, in_ptr3, in_ptr4, in_ptr5, out_ptr1, out_ptr2, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 32768\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x2 = xindex\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     x0 = xindex % 512\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.load(in_ptr1 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tl.load(in_ptr2 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp10 = tl.load(in_ptr3 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp12 = tl.load(in_ptr4 + (x0), None, eviction_policy='evict_last')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp14 = tl.load(in_ptr5 + (x2), None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tmp0 - tmp1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp4 = 64.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp5 = tmp3 / tmp4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp6 = 1e-05\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp7 = tmp5 + tmp6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp8 = tl.math.rsqrt(tmp7)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp9 = tmp2 * tmp8\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp11 = tmp9 * tmp10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp13 = tmp11 + tmp12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp15 = tmp13 + tmp14\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp16 = triton_helpers.maximum(0, tmp15)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp17 = 1.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp18 = tmp16 / tmp17\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp19 = 0.0\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp20 = tmp16 <= tmp19\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr1 + (x2), tmp18, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr2 + (x2), tmp20, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # kernel path: /tmp/torchinductor_root/4a/c4ahaceoyfba2amavegjgffbkchee6eqtlq732f6cxrvtlqiehae.py\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # Source Nodes: [l__self___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] # l__self___bn1 => add\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] triton_poi_fused_add_28 = async_compile.triton('triton_', '''\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] import triton.language as tl\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import ReductionHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.ir import TileHint\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.triton_heuristics import AutotuneHint, pointwise\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor.utils import instance_descriptor\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] from torch._inductor import triton_helpers\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @pointwise(size_hints=[1], filename=__file__, meta={'signature': {0: '*i64', 1: '*i64', 2: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'mutated_arg_names': [], 'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_add_28', 'configs': [instance_descriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]})\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] @triton.jit\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def triton_(in_ptr0, out_ptr0, xnumel, XBLOCK : tl.constexpr):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xnumel = 1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xoffset = tl.program_id(0) * XBLOCK\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xindex = xoffset + tl.arange(0, XBLOCK)[:]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     xmask = xindex < xnumel\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp0 = tl.load(in_ptr0 + (0))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp1 = tl.broadcast_to(tmp0, [XBLOCK])\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp2 = tl.full([1], 1, tl.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tmp3 = tmp1 + tmp2\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     tl.store(out_ptr0 + (tl.full([XBLOCK], 0, tl.int32)), tmp3, None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] ''')\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] async_compile.wait(globals())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] del async_compile\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def call(args):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123 = args\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     args.clear()\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_1, (64, 3, 7, 7), (147, 49, 7, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_2, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_3, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_4, (64, 64, 3, 3), (576, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_5, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_6, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_7, (64, 64, 3, 3), (576, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_8, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_9, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_10, (64, 64, 3, 3), (576, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_11, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_12, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_13, (64, 64, 3, 3), (576, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_14, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_15, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_16, (128, 64, 3, 3), (576, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_17, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_18, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_19, (128, 128, 3, 3), (1152, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_20, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_21, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_22, (128, 64, 1, 1), (64, 1, 64, 64))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_23, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_24, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_25, (128, 128, 3, 3), (1152, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_26, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_27, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_28, (128, 128, 3, 3), (1152, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_29, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_30, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_31, (256, 128, 3, 3), (1152, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_32, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_33, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_34, (256, 256, 3, 3), (2304, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_35, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_36, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_37, (256, 128, 1, 1), (128, 1, 128, 128))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_38, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_39, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_40, (256, 256, 3, 3), (2304, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_41, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_42, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_43, (256, 256, 3, 3), (2304, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_44, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_45, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_46, (512, 256, 3, 3), (2304, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_47, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_48, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_49, (512, 512, 3, 3), (4608, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_50, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_51, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_52, (512, 256, 1, 1), (256, 1, 256, 256))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_53, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_54, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_55, (512, 512, 3, 3), (4608, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_56, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_57, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_58, (512, 512, 3, 3), (4608, 9, 3, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_59, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_60, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_61, (2, 512), (512, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_62, (2, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_63, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_64, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_65, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_66, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_67, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_68, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_69, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_70, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_71, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_72, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_73, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_74, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_75, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_76, (64, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_77, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_78, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_79, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_80, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_81, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_82, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_83, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_84, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_85, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_86, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_87, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_88, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_89, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_90, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_91, (128, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_92, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_93, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_94, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_95, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_96, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_97, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_98, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_99, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_100, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_101, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_102, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_103, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_104, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_105, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_106, (256, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_107, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_108, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_109, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_110, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_111, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_112, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_113, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_114, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_115, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_116, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_117, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_118, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_119, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_120, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_121, (512, ), (1, ))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_122, (), ())\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     assert_size_stride(primals_123, (64, 3, 7, 7), (147, 49, 7, 1))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     with torch.cuda._DeviceGuard(0):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         torch.cuda.set_device(0) # no-op to ensure context\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf0 = empty_strided((64, 3, 7, 7), (147, 1, 21, 3), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         stream0 = get_cuda_stream(0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_0.run(primals_1, buf0, 192, 49, grid=grid(192, 49), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_1\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf1 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_4, buf1, 4096, 9, grid=grid(4096, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_4\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf2 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_7, buf2, 4096, 9, grid=grid(4096, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_7\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf3 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_10, buf3, 4096, 9, grid=grid(4096, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_10\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf4 = empty_strided((64, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_1.run(primals_13, buf4, 4096, 9, grid=grid(4096, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_13\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf5 = empty_strided((128, 64, 3, 3), (576, 1, 192, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_2.run(primals_16, buf5, 8192, 9, grid=grid(8192, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_16\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf6 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_19, buf6, 16384, 9, grid=grid(16384, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_19\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf7 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_25, buf7, 16384, 9, grid=grid(16384, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_25\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf8 = empty_strided((128, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_3.run(primals_28, buf8, 16384, 9, grid=grid(16384, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_28\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf9 = empty_strided((256, 128, 3, 3), (1152, 1, 384, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_4.run(primals_31, buf9, 32768, 9, grid=grid(32768, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_31\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf10 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_5.run(primals_34, buf10, 65536, 9, grid=grid(65536, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_34\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf11 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_5.run(primals_40, buf11, 65536, 9, grid=grid(65536, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_40\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf12 = empty_strided((256, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_5.run(primals_43, buf12, 65536, 9, grid=grid(65536, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_43\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf13 = empty_strided((512, 256, 3, 3), (2304, 1, 768, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_6.run(primals_46, buf13, 131072, 9, grid=grid(131072, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_46\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf14 = empty_strided((512, 512, 3, 3), (4608, 1, 1536, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_7.run(primals_49, buf14, 262144, 9, grid=grid(262144, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_49\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf15 = empty_strided((512, 512, 3, 3), (4608, 1, 1536, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_7.run(primals_55, buf15, 262144, 9, grid=grid(262144, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_55\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf16 = empty_strided((512, 512, 3, 3), (4608, 1, 1536, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_7.run(primals_58, buf16, 262144, 9, grid=grid(262144, 9), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_58\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf17 = empty_strided((64, 3, 7, 7), (147, 1, 21, 3), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [], Original ATen: []\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_0.run(primals_123, buf17, 192, 49, grid=grid(192, 49), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_123\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf18 = extern_kernels.convolution(buf17, buf0, stride=(2, 2), padding=(3, 3), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf18, (64, 64, 4, 4), (1024, 1, 256, 64))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf19 = empty_strided((1, 64, 1, 1, 8), (512, 1, 512, 512, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf20 = empty_strided((1, 64, 1, 1, 8), (512, 1, 512, 512, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf21 = empty_strided((1, 64, 1, 1, 8), (512, 1, 512, 512, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_8.run(buf18, buf19, buf20, buf21, 512, 128, grid=grid(512), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf22 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf23 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf25 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf27 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf26 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_9.run(buf19, buf20, buf21, primals_64, primals_63, buf22, buf23, buf25, buf27, buf26, 64, 8, grid=grid(64), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_63\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_64\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf28 = empty_strided((64, 64, 4, 4), (1024, 1, 256, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___act1, l__self___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_10.run(buf18, buf22, buf23, primals_2, primals_3, buf28, 65536, grid=grid(65536), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_3\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf29 = empty_strided((64, 64, 2, 2), (256, 1, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf30 = empty_strided((64, 64, 2, 2), (256, 1, 128, 64), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___maxpool], Original ATen: [aten.max_pool2d_with_indices]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_max_pool2d_with_indices_11.run(buf28, buf29, buf30, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf31 = extern_kernels.convolution(buf29, buf1, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf31, (64, 64, 2, 2), (256, 1, 128, 64))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf32 = empty_strided((1, 64, 1, 1, 2), (128, 1, 128, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf33 = empty_strided((1, 64, 1, 1, 2), (128, 1, 128, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf34 = empty_strided((1, 64, 1, 1, 2), (128, 1, 128, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf31, buf32, buf33, buf34, 128, 128, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf35 = buf23; del buf23  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf36 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf38 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf40 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf39 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf32, buf33, buf34, primals_67, primals_66, buf35, buf36, buf38, buf40, buf39, 64, 2, grid=grid(64), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_66\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_67\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf41 = empty_strided((64, 64, 2, 2), (256, 1, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___act1, getattr_l__self___layer1___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf31, buf35, buf36, primals_5, primals_6, buf41, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_6\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf42 = extern_kernels.convolution(buf41, buf2, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf42, (64, 64, 2, 2), (256, 1, 128, 64))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf43 = buf34; del buf34  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf44 = buf33; del buf33  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf45 = buf32; del buf32  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf42, buf43, buf44, buf45, 128, 128, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf46 = buf36; del buf36  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf47 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf49 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf51 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf50 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf43, buf44, buf45, primals_70, primals_69, buf46, buf47, buf49, buf51, buf50, 64, 2, grid=grid(64), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_69\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_70\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf52 = empty_strided((64, 64, 2, 2), (256, 1, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___act2, getattr_l__self___layer1___0___bn2, iadd], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf42, buf46, buf47, primals_8, primals_9, buf29, buf52, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_9\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf53 = extern_kernels.convolution(buf52, buf3, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf53, (64, 64, 2, 2), (256, 1, 128, 64))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf54 = buf45; del buf45  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf55 = buf44; del buf44  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf56 = buf43; del buf43  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf53, buf54, buf55, buf56, 128, 128, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf57 = buf47; del buf47  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf58 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf60 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf62 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf61 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf54, buf55, buf56, primals_73, primals_72, buf57, buf58, buf60, buf62, buf61, 64, 2, grid=grid(64), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_72\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_73\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf63 = empty_strided((64, 64, 2, 2), (256, 1, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___act1, getattr_l__self___layer1___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_14.run(buf53, buf57, buf58, primals_11, primals_12, buf63, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_12\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf64 = extern_kernels.convolution(buf63, buf4, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf64, (64, 64, 2, 2), (256, 1, 128, 64))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf65 = buf56; del buf56  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf66 = buf55; del buf55  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf67 = buf54; del buf54  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_red_fused__native_batch_norm_legit_functional_12.run(buf64, buf65, buf66, buf67, 128, 128, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf68 = buf58; del buf58  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf69 = empty_strided((1, 64, 1, 1), (64, 1, 64, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf71 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf73 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf72 = empty_strided((64, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_13.run(buf65, buf66, buf67, primals_76, primals_75, buf68, buf69, buf71, buf73, buf72, 64, 2, grid=grid(64), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_75\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_76\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf74 = empty_strided((64, 64, 2, 2), (256, 1, 128, 64), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___act2, getattr_l__self___layer1___1___bn2, iadd_1], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_15.run(buf64, buf68, buf69, primals_14, primals_15, buf52, buf74, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del buf69\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_15\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf75 = extern_kernels.convolution(buf74, buf5, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf75, (64, 128, 1, 1), (128, 1, 128, 128))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf76 = reinterpret_tensor(buf67, (1, 128, 1, 1), (128, 1, 128, 128)); del buf67  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf77 = reinterpret_tensor(buf66, (1, 128, 1, 1), (128, 1, 128, 128)); del buf66  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf79 = reinterpret_tensor(buf65, (128, ), (1, )); del buf65  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf81 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf80 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_16.run(buf75, primals_79, primals_78, buf76, buf77, buf79, buf81, buf80, 128, 64, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_78\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_79\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf82 = empty_strided((64, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___act1, getattr_l__self___layer2___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_17.run(buf75, buf76, buf77, primals_17, primals_18, buf82, 8192, grid=grid(8192), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_18\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf83 = extern_kernels.convolution(buf82, buf6, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf83, (64, 128, 1, 1), (128, 1, 128, 128))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf84 = buf77; del buf77  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf85 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf87 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf89 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf88 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_16.run(buf83, primals_82, primals_81, buf84, buf85, buf87, buf89, buf88, 128, 64, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_81\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_82\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_0], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf90 = extern_kernels.convolution(buf74, primals_22, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf90, (64, 128, 1, 1), (128, 1, 128, 128))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf91 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf92 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf94 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf96 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf95 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_16.run(buf90, primals_85, primals_84, buf91, buf92, buf94, buf96, buf95, 128, 64, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_84\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_85\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf97 = empty_strided((64, 128, 1, 1), (128, 1, 8192, 8192), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf98 = reinterpret_tensor(buf97, (64, 128, 1, 1), (128, 1, 128, 128)); del buf97  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___act2, getattr_l__self___layer2___0___bn2, getattr_l__self___layer2___0___downsample_1, iadd_2], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_18.run(buf98, buf83, buf84, buf85, primals_20, primals_21, buf90, buf91, buf92, primals_23, primals_24, 8192, grid=grid(8192), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_21\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_24\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf99 = extern_kernels.convolution(buf98, buf7, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf99, (64, 128, 1, 1), (128, 1, 128, 128))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf100 = buf92; del buf92  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf101 = buf85; del buf85  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf103 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf105 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf104 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_16.run(buf99, primals_88, primals_87, buf100, buf101, buf103, buf105, buf104, 128, 64, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_87\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_88\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf106 = empty_strided((64, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___act1, getattr_l__self___layer2___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_17.run(buf99, buf100, buf101, primals_26, primals_27, buf106, 8192, grid=grid(8192), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_27\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf107 = extern_kernels.convolution(buf106, buf8, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf107, (64, 128, 1, 1), (128, 1, 128, 128))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf108 = buf101; del buf101  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf109 = empty_strided((1, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf111 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf113 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf112 = empty_strided((128, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_16.run(buf107, primals_91, primals_90, buf108, buf109, buf111, buf113, buf112, 128, 64, grid=grid(128), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_90\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_91\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf114 = empty_strided((64, 128, 1, 1), (128, 1, 128, 128), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___act2, getattr_l__self___layer2___1___bn2, iadd_3], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_19.run(buf107, buf108, buf109, primals_29, primals_30, buf98, buf114, 8192, grid=grid(8192), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_30\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf115 = extern_kernels.convolution(buf114, buf9, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf115, (64, 256, 1, 1), (256, 1, 256, 256))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf116 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf117 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf119 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf121 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf120 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_20.run(buf115, primals_94, primals_93, buf116, buf117, buf119, buf121, buf120, 256, 64, grid=grid(256), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_93\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_94\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf122 = empty_strided((64, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___act1, getattr_l__self___layer3___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_21.run(buf115, buf116, buf117, primals_32, primals_33, buf122, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_33\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf123 = extern_kernels.convolution(buf122, buf10, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf123, (64, 256, 1, 1), (256, 1, 256, 256))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf124 = buf117; del buf117  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf125 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf127 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf129 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf128 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_20.run(buf123, primals_97, primals_96, buf124, buf125, buf127, buf129, buf128, 256, 64, grid=grid(256), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_96\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_97\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_0], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf130 = extern_kernels.convolution(buf114, primals_37, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf130, (64, 256, 1, 1), (256, 1, 256, 256))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf131 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf132 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf134 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf136 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf135 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_20.run(buf130, primals_100, primals_99, buf131, buf132, buf134, buf136, buf135, 256, 64, grid=grid(256), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_100\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_99\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf137 = empty_strided((64, 256, 1, 1), (256, 1, 16384, 16384), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf138 = reinterpret_tensor(buf137, (64, 256, 1, 1), (256, 1, 256, 256)); del buf137  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___act2, getattr_l__self___layer3___0___bn2, getattr_l__self___layer3___0___downsample_1, iadd_4], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_22.run(buf138, buf123, buf124, buf125, primals_35, primals_36, buf130, buf131, buf132, primals_38, primals_39, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_36\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_39\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf139 = extern_kernels.convolution(buf138, buf11, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf139, (64, 256, 1, 1), (256, 1, 256, 256))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf140 = buf132; del buf132  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf141 = buf125; del buf125  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf143 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf145 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf144 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_20.run(buf139, primals_103, primals_102, buf140, buf141, buf143, buf145, buf144, 256, 64, grid=grid(256), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_102\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_103\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf146 = empty_strided((64, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___act1, getattr_l__self___layer3___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_21.run(buf139, buf140, buf141, primals_41, primals_42, buf146, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_42\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf147 = extern_kernels.convolution(buf146, buf12, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf147, (64, 256, 1, 1), (256, 1, 256, 256))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf148 = buf141; del buf141  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf149 = empty_strided((1, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf151 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf153 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf152 = empty_strided((256, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_20.run(buf147, primals_106, primals_105, buf148, buf149, buf151, buf153, buf152, 256, 64, grid=grid(256), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_105\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_106\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf154 = empty_strided((64, 256, 1, 1), (256, 1, 256, 256), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___act2, getattr_l__self___layer3___1___bn2, iadd_5], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_23.run(buf147, buf148, buf149, primals_44, primals_45, buf138, buf154, 16384, grid=grid(16384), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del buf149\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_45\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf155 = extern_kernels.convolution(buf154, buf13, stride=(2, 2), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf155, (64, 512, 1, 1), (512, 1, 512, 512))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf156 = reinterpret_tensor(buf21, (1, 512, 1, 1), (512, 1, 512, 512)); del buf21  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf157 = reinterpret_tensor(buf20, (1, 512, 1, 1), (512, 1, 512, 512)); del buf20  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf159 = reinterpret_tensor(buf19, (512, ), (1, )); del buf19  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf161 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf160 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_24.run(buf155, primals_109, primals_108, buf156, buf157, buf159, buf161, buf160, 512, 64, grid=grid(512), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_108\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_109\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf162 = empty_strided((64, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___act1, getattr_l__self___layer4___0___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_25.run(buf155, buf156, buf157, primals_47, primals_48, buf162, 32768, grid=grid(32768), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_48\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf163 = extern_kernels.convolution(buf162, buf14, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf163, (64, 512, 1, 1), (512, 1, 512, 512))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf164 = buf157; del buf157  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf165 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf167 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf169 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf168 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_24.run(buf163, primals_112, primals_111, buf164, buf165, buf167, buf169, buf168, 512, 64, grid=grid(512), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_111\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_112\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_0], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf170 = extern_kernels.convolution(buf154, primals_52, stride=(2, 2), padding=(0, 0), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf170, (64, 512, 1, 1), (512, 1, 512, 512))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf171 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf172 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf174 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf176 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf175 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_24.run(buf170, primals_115, primals_114, buf171, buf172, buf174, buf176, buf175, 512, 64, grid=grid(512), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_114\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_115\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf177 = empty_strided((64, 512, 1, 1), (512, 1, 32768, 32768), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf178 = reinterpret_tensor(buf177, (64, 512, 1, 1), (512, 1, 512, 512)); del buf177  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___act2, getattr_l__self___layer4___0___bn2, getattr_l__self___layer4___0___downsample_1, iadd_6], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_relu_26.run(buf178, buf163, buf164, buf165, primals_50, primals_51, buf170, buf171, buf172, primals_53, primals_54, 32768, grid=grid(32768), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_51\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_54\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___conv1], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf179 = extern_kernels.convolution(buf178, buf15, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf179, (64, 512, 1, 1), (512, 1, 512, 512))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf180 = buf172; del buf172  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf181 = buf165; del buf165  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf183 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf185 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf184 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_24.run(buf179, primals_118, primals_117, buf180, buf181, buf183, buf185, buf184, 512, 64, grid=grid(512), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_117\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_118\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf186 = empty_strided((64, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___act1, getattr_l__self___layer4___1___bn1], Original ATen: [aten._native_batch_norm_legit_functional, aten.relu]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_relu_25.run(buf179, buf180, buf181, primals_56, primals_57, buf186, 32768, grid=grid(32768), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_57\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___conv2], Original ATen: [aten.convolution]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf187 = extern_kernels.convolution(buf186, buf16, stride=(1, 1), padding=(1, 1), dilation=(1, 1), transposed=False, output_padding=(0, 0), groups=1, bias=None)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         assert_size_stride(buf187, (64, 512, 1, 1), (512, 1, 512, 512))\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf188 = buf181; del buf181  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf189 = empty_strided((1, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf191 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf193 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf192 = empty_strided((512, ), (1, ), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn2], Original ATen: [aten._native_batch_norm_legit_functional]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_per_fused__native_batch_norm_legit_functional_24.run(buf187, primals_121, primals_120, buf188, buf189, buf191, buf193, buf192, 512, 64, grid=grid(512), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_120\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_121\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf195 = empty_strided((64, 512), (512, 1), device='cuda', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf197 = empty_strided((64, 512, 1, 1), (512, 1, 512, 512), device='cuda', dtype=torch.bool)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___act2, getattr_l__self___layer4___1___bn2, iadd_7, l__self___global_pool_flatten, l__self___global_pool_pool], Original ATen: [aten._native_batch_norm_legit_functional, aten.add, aten.mean, aten.relu, aten.threshold_backward, aten.view]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused__native_batch_norm_legit_functional_add_mean_relu_threshold_backward_view_27.run(buf187, buf188, buf189, primals_59, primals_60, buf178, buf195, buf197, 32768, grid=grid(32768), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del buf189\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_60\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf196 = reinterpret_tensor(buf109, (64, 2), (2, 1)); del buf109  # reuse\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___fc], Original ATen: [aten.addmm]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         extern_kernels.addmm(primals_62, buf195, reinterpret_tensor(primals_61, (512, 2), (1, 512), 0), alpha=1, beta=1, out=buf196)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_62\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf198 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [l__self___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_65, buf198, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_65\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf199 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_68, buf199, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_68\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf200 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___0___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_71, buf200, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_71\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf201 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_74, buf201, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_74\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf202 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer1___1___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_77, buf202, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_77\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf203 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_80, buf203, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_80\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf204 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_83, buf204, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_83\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf205 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___0___downsample_1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_86, buf205, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_86\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf206 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_89, buf206, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_89\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf207 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer2___1___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_92, buf207, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_92\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf208 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_95, buf208, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_95\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf209 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_98, buf209, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_98\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf210 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___0___downsample_1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_101, buf210, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_101\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf211 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_104, buf211, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_104\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf212 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer3___1___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_107, buf212, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_107\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf213 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_110, buf213, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_110\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf214 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_113, buf214, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_113\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf215 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___0___downsample_1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_116, buf215, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_116\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf216 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn1], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_119, buf216, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_119\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         buf217 = empty_strided((), (), device='cuda', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         # Source Nodes: [getattr_l__self___layer4___1___bn2], Original ATen: [aten.add]\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         triton_poi_fused_add_28.run(primals_122, buf217, 1, grid=grid(1), stream=stream0)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         del primals_122\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]         return (buf26, buf27, buf198, buf39, buf40, buf199, buf50, buf51, buf200, buf61, buf62, buf201, buf72, buf73, buf202, buf80, buf81, buf203, buf88, buf89, buf204, buf95, buf96, buf205, buf104, buf105, buf206, buf112, buf113, buf207, buf120, buf121, buf208, buf128, buf129, buf209, buf135, buf136, buf210, buf144, buf145, buf211, buf152, buf153, buf212, buf160, buf161, buf213, buf168, buf169, buf214, buf175, buf176, buf215, buf184, buf185, buf216, buf192, buf193, buf217, buf196, buf0, primals_2, buf1, primals_5, buf2, primals_8, buf3, primals_11, buf4, primals_14, buf5, primals_17, buf6, primals_20, primals_22, primals_23, buf7, primals_26, buf8, primals_29, buf9, primals_32, buf10, primals_35, primals_37, primals_38, buf11, primals_41, buf12, primals_44, buf13, primals_47, buf14, primals_50, primals_52, primals_53, buf15, primals_56, buf16, primals_59, buf17, buf18, buf25, buf28, buf29, buf30, buf31, buf38, buf41, buf42, buf49, buf52, buf53, buf60, buf63, buf64, buf71, buf74, buf75, buf79, buf82, buf83, buf87, buf90, buf94, buf98, buf99, buf103, buf106, buf107, buf111, buf114, buf115, buf119, buf122, buf123, buf127, buf130, buf134, buf138, buf139, buf143, buf146, buf147, buf151, buf154, buf155, buf159, buf162, buf163, buf167, buf170, buf174, buf178, buf179, buf183, buf186, buf187, buf191, buf195, reinterpret_tensor(primals_61, (2, 512), (512, 1), 0), buf197, reinterpret_tensor(buf188, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf180, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf171, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf164, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf156, (1, 512, 1, 1), (512, 1, 1, 1), 0), reinterpret_tensor(buf148, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf140, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf131, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf124, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf116, (1, 256, 1, 1), (256, 1, 1, 1), 0), reinterpret_tensor(buf108, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf100, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf91, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf84, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf76, (1, 128, 1, 1), (128, 1, 1, 1), 0), reinterpret_tensor(buf68, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf57, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf46, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf35, (1, 64, 1, 1), (64, 1, 1, 1), 0), reinterpret_tensor(buf22, (1, 64, 1, 1), (64, 1, 1, 1), 0), )\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] def benchmark_compiled_module(times=10, repeat=10):\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     from torch._dynamo.testing import rand_strided\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     from torch._inductor.utils import print_performance\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_1 = rand_strided((64, 3, 7, 7), (147, 49, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_2 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_3 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_4 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_5 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_6 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_7 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_8 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_9 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_10 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_11 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_12 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_13 = rand_strided((64, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_14 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_15 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_16 = rand_strided((128, 64, 3, 3), (576, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_17 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_18 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_19 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_20 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_21 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_22 = rand_strided((128, 64, 1, 1), (64, 1, 64, 64), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_23 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_24 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_25 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_26 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_27 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_28 = rand_strided((128, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_29 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_30 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_31 = rand_strided((256, 128, 3, 3), (1152, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_32 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_33 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_34 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_35 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_36 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_37 = rand_strided((256, 128, 1, 1), (128, 1, 128, 128), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_38 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_39 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_40 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_41 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_42 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_43 = rand_strided((256, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_44 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_45 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_46 = rand_strided((512, 256, 3, 3), (2304, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_47 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_48 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_49 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_50 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_51 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_52 = rand_strided((512, 256, 1, 1), (256, 1, 256, 256), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_53 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_54 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_55 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_56 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_57 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_58 = rand_strided((512, 512, 3, 3), (4608, 9, 3, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_59 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_60 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_61 = rand_strided((2, 512), (512, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_62 = rand_strided((2, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_63 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_64 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_65 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_66 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_67 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_68 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_69 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_70 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_71 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_72 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_73 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_74 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_75 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_76 = rand_strided((64, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_77 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_78 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_79 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_80 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_81 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_82 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_83 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_84 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_85 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_86 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_87 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_88 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_89 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_90 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_91 = rand_strided((128, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_92 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_93 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_94 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_95 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_96 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_97 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_98 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_99 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_100 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_101 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_102 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_103 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_104 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_105 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_106 = rand_strided((256, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_107 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_108 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_109 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_110 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_111 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_112 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_113 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_114 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_115 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_116 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_117 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_118 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_119 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_120 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_121 = rand_strided((512, ), (1, ), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_122 = rand_strided((), (), device='cuda:0', dtype=torch.int64)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     primals_123 = rand_strided((64, 3, 7, 7), (147, 49, 7, 1), device='cuda:0', dtype=torch.float32)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     return print_performance(lambda: call([primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123]), times=times, repeat=repeat)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] if __name__ == \"__main__\":\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     from torch._inductor.wrapper_benchmark import compiled_module_main\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG]     compiled_module_main('None', benchmark_compiled_module)\n",
      "[2023-09-07 15:00:49,060] [7/0] torch._inductor.graph.__output_code: [DEBUG] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.7302e-01,  1.6953e-01],\n",
       "        [ 3.1415e-01, -1.9879e-01],\n",
       "        [ 2.2843e-01, -5.1540e-02],\n",
       "        [ 1.3476e-01, -5.3632e-01],\n",
       "        [ 2.5758e-01,  3.6784e-01],\n",
       "        [-2.0255e-01,  2.4212e-01],\n",
       "        [-7.0895e-01,  4.0644e-02],\n",
       "        [ 8.6189e-01, -1.9660e-01],\n",
       "        [ 1.3331e-01, -2.1293e-01],\n",
       "        [ 3.6175e-01,  1.1752e-01],\n",
       "        [ 8.8030e-02, -7.1310e-01],\n",
       "        [ 7.2991e-02,  1.0708e-01],\n",
       "        [-1.9656e-02, -4.7510e-01],\n",
       "        [-2.2430e-03,  2.8744e-01],\n",
       "        [ 3.5546e-02, -4.8751e-01],\n",
       "        [-5.6303e-01, -1.1960e-01],\n",
       "        [ 5.1516e-01,  6.0561e-01],\n",
       "        [-4.4132e-01,  1.2456e-01],\n",
       "        [ 3.2252e-01,  1.1030e-03],\n",
       "        [ 4.3625e-01, -1.1928e-01],\n",
       "        [ 7.4601e-02, -1.4681e-01],\n",
       "        [ 2.1566e-01, -2.3239e-01],\n",
       "        [ 5.0469e-01, -1.1591e+00],\n",
       "        [ 1.0509e-01, -2.8289e-01],\n",
       "        [ 4.7329e-02, -5.1647e-01],\n",
       "        [-3.4204e-02,  4.6150e-01],\n",
       "        [ 1.0979e-01,  3.5335e-02],\n",
       "        [ 3.9531e-01, -4.2405e-01],\n",
       "        [ 4.9346e-01, -4.5728e-01],\n",
       "        [-1.7324e-01, -5.8312e-02],\n",
       "        [ 1.0762e-02, -2.4348e-01],\n",
       "        [ 3.6024e-01, -3.8429e-01],\n",
       "        [ 4.1611e-01, -3.7404e-01],\n",
       "        [-2.1200e-01,  1.4651e-01],\n",
       "        [-2.9402e-01,  1.2758e-01],\n",
       "        [ 1.3001e-02,  4.4739e-01],\n",
       "        [ 2.2750e-01, -4.2109e-01],\n",
       "        [-2.1997e-01,  3.5581e-01],\n",
       "        [-1.4012e-01, -2.6673e-01],\n",
       "        [ 1.0484e-01, -3.3742e-02],\n",
       "        [ 2.6205e-01, -7.0527e-02],\n",
       "        [ 1.9120e-01, -9.3681e-01],\n",
       "        [-3.6782e-01,  1.6968e-01],\n",
       "        [ 4.8278e-01, -1.4261e-01],\n",
       "        [ 1.8941e-01, -5.2623e-02],\n",
       "        [ 4.4532e-01,  7.0079e-02],\n",
       "        [ 5.0623e-01, -3.5777e-01],\n",
       "        [ 4.9815e-01, -3.8865e-01],\n",
       "        [-2.6873e-01,  7.2218e-01],\n",
       "        [-2.4384e-01, -2.3203e-01],\n",
       "        [ 2.3418e-01, -1.2870e-01],\n",
       "        [ 2.0108e-01,  1.2045e-01],\n",
       "        [-1.0798e-01,  3.8627e-02],\n",
       "        [ 1.0725e-01, -7.3489e-01],\n",
       "        [ 5.5117e-01, -1.1573e-01],\n",
       "        [ 3.1140e-01, -9.4745e-01],\n",
       "        [ 1.8062e-01,  4.3827e-01],\n",
       "        [ 3.3181e-01, -4.0579e-01],\n",
       "        [ 3.9594e-01, -5.3252e-01],\n",
       "        [ 4.6882e-01,  2.2899e-02],\n",
       "        [ 4.0966e-01,  2.0302e-02],\n",
       "        [ 4.4001e-01,  2.7282e-01],\n",
       "        [-2.6539e-02, -2.9749e-02],\n",
       "        [ 6.7463e-02,  3.6170e-01]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch._logging.set_logs(output_code=True)\n",
    "torch._dynamo.reset()\n",
    "opt_model(input_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PT2.0 Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regular torch.profile()\n",
    "Warmup helps clean up the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-07 15:29:36 988556:988556 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-09-07 15:29:44 988556:988556 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-09-07 15:29:44 988556:988556 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "model = resnet18().cuda()\n",
    "inputs = [torch.randn((5, 3, 224, 224), device='cuda') for _ in range(10)]\n",
    "\n",
    "model_c = torch.compile(model)\n",
    "\n",
    "def fwd_bwd(inp):\n",
    "    out = model_c(inp)\n",
    "    out.sum().backward()\n",
    "\n",
    "# warm up\n",
    "fwd_bwd(inputs[0])\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    for i in range(1, 4):\n",
    "        fwd_bwd(inputs[i])\n",
    "        prof.step()\n",
    "\n",
    "prof.export_chrome_trace(\"cold.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding compilation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2023-09-07 16:19:26 988556:988556 ActivityProfilerController.cpp:312] Completed Stage: Warm Up\n",
      "STAGE:2023-09-07 16:19:35 988556:988556 ActivityProfilerController.cpp:318] Completed Stage: Collection\n",
      "STAGE:2023-09-07 16:19:35 988556:988556 ActivityProfilerController.cpp:322] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchDynamo compilation metrics:\n",
      "Function                              Runtimes (s)\n",
      "------------------------------------  --------------\n",
      "_compile.<locals>.compile_inner       6.1978\n",
      "OutputGraph.call_user_compiler        5.8156\n",
      "create_aot_dispatcher_function        5.8038\n",
      "compile_fx.<locals>.fw_compiler_base  3.9522\n",
      "GraphLowering.run                     0.6129, 0.6465\n",
      "GraphLowering.compile_to_module       2.7241, 1.0656\n",
      "Scheduler.__init__                    1.7208, 0.5109\n",
      "Scheduler.codegen                     0.9591, 0.5100\n",
      "WrapperCodeGen.generate               0.0371, 0.0307\n",
      "compile_fx.<locals>.bw_compiler       2.1654\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "model = resnet18().cuda()\n",
    "inputs = [torch.randn((5, 3, 224, 224), device='cuda') for _ in range(10)]\n",
    "\n",
    "model_c = torch.compile(model)\n",
    "\n",
    "def fwd_bwd(inp):\n",
    "    out = model_c(inp)\n",
    "    out.sum().backward()\n",
    "\n",
    "with torch.profiler.profile() as prof:\n",
    "    with torch.profiler.record_function(\"resnet18 compile\"):\n",
    "        fwd_bwd(inputs[0])\n",
    "\n",
    "prof.export_chrome_trace(\"trace_compile.json\")\n",
    "\n",
    "print(torch._dynamo.utils.compile_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.33.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/.local/lib/python3.8/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchDynamo compilation metrics:\n",
      "Function                                Runtimes (s)\n",
      "--------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "_compile.<locals>.compile_inner         15.2372\n",
      "OutputGraph.call_user_compiler          13.0239\n",
      "create_aot_dispatcher_function          0.0161, 0.0159, 0.0154, 0.0155, 0.0156, 0.0290, 0.0159, 0.0168, 0.0156, 0.0155, 0.0156, 0.0156, 0.0160, 0.0165, 0.0155, 0.0156, 0.0156, 0.0156, 0.0157, 0.0163, 0.0156, 0.0155, 0.0155, 0.0154, 12.9635\n",
      "compile_fx.<locals>.fw_compiler_base    5.3141\n",
      "GraphLowering.run                       0.7436\n",
      "GraphLowering.compile_to_module         3.2785\n",
      "Scheduler.__init__                      0.9226\n",
      "Scheduler.codegen                       0.5623\n",
      "WrapperCodeGen.generate                 0.0579\n",
      "CachingAutotuner.benchmark_all_configs  0.1817, 0.0926, 0.0926, 0.0963\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device=\"cuda:0\")\n",
    "model = torch.compile(model, backend=\"inductor\", dynamic=False, fullgraph=False) # This is the only line of code that we changed\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "output = model(**encoded_input)\n",
    "\n",
    "print(torch._dynamo.utils.compile_times())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 16:35:12,266] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 12, actual 4\")\n"
     ]
    }
   ],
   "source": [
    "torch._logging.set_logs(recompiles=True, graph_breaks=True)\n",
    "\n",
    "text = \"Testing purposes\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 16:36:22,141] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 12, actual 5\")\n",
      "[2023-09-07 16:36:36,570] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 5, actual 6\")\n",
      "[2023-09-07 16:36:51,075] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 6, actual 9\")\n",
      "[2023-09-07 16:37:07,950] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 9, actual 7\")\n",
      "[2023-09-07 16:37:23,657] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 7, actual 10\")\n",
      "[2023-09-07 16:37:40,647] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 10, actual 8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1424,  0.1335, -0.1291,  ..., -0.3597, -0.0562,  0.3605],\n",
      "         [-0.3506,  0.1042,  0.6244,  ..., -0.1761,  0.4834,  0.0644],\n",
      "         [-0.2451, -0.1573,  0.6945,  ..., -0.5654, -0.0894, -0.1856],\n",
      "         [-0.8248, -0.9119, -0.6561,  ...,  0.5074, -0.1939, -0.1659],\n",
      "         [ 0.8767,  0.0352, -0.1233,  ...,  0.2720, -0.6369, -0.1585]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-8.9756e-01, -3.3040e-01, -7.6942e-01,  7.5799e-01,  4.6678e-01,\n",
      "         -1.2035e-01,  9.1835e-01,  1.8087e-01, -7.2716e-01, -9.9991e-01,\n",
      "         -4.4723e-01,  8.9104e-01,  9.6621e-01,  5.4915e-01,  9.4344e-01,\n",
      "         -7.6605e-01, -6.0469e-01, -6.1654e-01,  4.0572e-01, -7.4644e-01,\n",
      "          6.1739e-01,  9.9974e-01,  3.2991e-02,  2.5414e-01,  4.3106e-01,\n",
      "          9.7732e-01, -8.4328e-01,  9.2297e-01,  9.4871e-01,  6.3994e-01,\n",
      "         -7.3620e-01,  9.0956e-02, -9.7607e-01, -1.9115e-01, -8.1717e-01,\n",
      "         -9.7907e-01,  3.1635e-01, -7.2013e-01,  1.6124e-01,  5.1999e-02,\n",
      "         -8.9102e-01,  2.3002e-01,  9.9967e-01,  1.1503e-02,  1.1176e-01,\n",
      "         -3.5556e-01, -1.0000e+00,  2.8487e-01, -8.3339e-01,  8.0987e-01,\n",
      "          7.4664e-01,  6.2762e-01,  1.9847e-01,  4.5185e-01,  4.7242e-01,\n",
      "         -3.9162e-03, -1.0570e-01,  9.3340e-02, -1.8906e-01, -5.1946e-01,\n",
      "         -5.7823e-01,  2.8046e-01, -8.2281e-01, -8.9764e-01,  9.1890e-01,\n",
      "          7.4117e-01, -5.9993e-02, -3.1655e-01,  2.8232e-03, -1.4652e-01,\n",
      "          9.0953e-01,  2.5587e-01,  5.4494e-02, -8.4187e-01,  5.7771e-01,\n",
      "          2.4804e-01, -6.1732e-01,  1.0000e+00, -6.4891e-01, -9.5425e-01,\n",
      "          5.5482e-01,  6.8866e-01,  5.5711e-01, -3.3463e-01,  4.7904e-01,\n",
      "         -1.0000e+00,  3.4197e-01, -1.1332e-01, -9.7818e-01,  2.2887e-01,\n",
      "          4.5161e-01, -1.5720e-01,  1.6195e-01,  5.1240e-01, -5.7138e-01,\n",
      "         -3.7296e-01, -2.8502e-01, -8.0263e-01, -2.1937e-01, -2.2406e-01,\n",
      "         -5.1872e-03, -2.6417e-01, -2.2839e-01, -3.7414e-01,  2.6933e-01,\n",
      "         -4.5077e-01, -5.5173e-01,  4.8430e-01,  4.7177e-02,  6.6727e-01,\n",
      "          3.3201e-01, -2.9447e-01,  5.0653e-01, -9.4933e-01,  6.1857e-01,\n",
      "         -2.4586e-01, -9.7565e-01, -5.3396e-01, -9.7924e-01,  5.8934e-01,\n",
      "         -2.3402e-01, -2.7536e-01,  9.4687e-01,  1.5282e-01,  3.0223e-01,\n",
      "          1.1186e-02, -7.3234e-01, -1.0000e+00, -6.9951e-01, -5.0531e-01,\n",
      "         -2.7527e-01, -2.0676e-01, -9.5607e-01, -9.1109e-01,  5.1232e-01,\n",
      "          9.3519e-01,  1.3547e-01,  9.9877e-01, -2.0620e-01,  9.2237e-01,\n",
      "         -4.9195e-01, -7.0814e-01,  6.5990e-01, -4.0702e-01,  7.4080e-01,\n",
      "          4.4237e-01, -6.9697e-01,  1.7959e-01, -2.0311e-01,  2.8031e-01,\n",
      "         -6.5004e-01, -2.2036e-01, -6.8982e-01, -9.2266e-01, -3.2942e-01,\n",
      "          9.3754e-01, -4.7618e-01, -8.9325e-01, -1.4759e-01, -1.4892e-01,\n",
      "         -5.3520e-01,  8.4738e-01,  7.0655e-01,  3.8488e-01, -4.0430e-01,\n",
      "          3.9196e-01,  2.2351e-01,  5.5196e-01, -8.1159e-01, -1.8874e-01,\n",
      "          3.3696e-01, -3.6883e-01, -6.5580e-01, -9.7058e-01, -3.4790e-01,\n",
      "          4.8676e-01,  9.8414e-01,  7.1667e-01,  2.3032e-01,  7.0561e-01,\n",
      "         -8.2327e-02,  7.3910e-01, -9.2162e-01,  9.5893e-01, -3.3638e-01,\n",
      "          2.3401e-01,  6.1110e-02,  4.1919e-01, -8.5576e-01,  1.5276e-01,\n",
      "          8.8090e-01, -6.3311e-01, -8.3712e-01,  6.5171e-02, -4.3054e-01,\n",
      "         -3.4557e-01, -5.9076e-01,  5.1503e-01, -2.6207e-01, -2.4693e-01,\n",
      "          6.1307e-02,  8.7691e-01,  9.8752e-01,  8.0232e-01,  1.4752e-01,\n",
      "          6.8812e-01, -8.9320e-01, -5.4703e-01,  4.8356e-02,  2.1540e-01,\n",
      "          2.3904e-01,  9.9014e-01, -4.9880e-01, -1.3789e-01, -9.2269e-01,\n",
      "         -9.7721e-01, -9.4688e-02, -9.0299e-01, -1.3468e-01, -7.0078e-01,\n",
      "          5.1663e-01,  2.4403e-01,  6.1268e-01,  3.6200e-01, -9.9236e-01,\n",
      "         -7.4132e-01,  3.4922e-01, -2.3057e-01,  3.8191e-01, -1.6780e-01,\n",
      "          3.9556e-02,  8.9809e-01, -5.3350e-01,  8.3722e-01,  8.8839e-01,\n",
      "         -7.2514e-01, -7.3965e-01,  8.9407e-01, -2.3408e-01,  8.7030e-01,\n",
      "         -5.6373e-01,  9.7425e-01,  8.4706e-01,  8.3270e-01, -8.9631e-01,\n",
      "         -5.6269e-01, -9.0159e-01, -6.9972e-01,  6.1690e-02,  9.8558e-02,\n",
      "          8.7749e-01,  5.6404e-01,  3.4049e-01,  3.7582e-01, -6.7834e-01,\n",
      "          9.9827e-01, -3.3602e-02, -9.2002e-01,  2.7571e-01, -3.0865e-01,\n",
      "         -9.6896e-01,  7.2166e-01,  3.3953e-01, -4.0745e-03, -4.1497e-01,\n",
      "         -6.4642e-01, -9.2770e-01,  9.3160e-01,  6.0920e-02,  9.9071e-01,\n",
      "          4.6196e-02, -9.3994e-01, -6.6822e-01, -8.9785e-01, -3.0716e-01,\n",
      "         -2.0500e-01, -3.8714e-01, -8.1208e-02, -9.4563e-01,  4.3475e-01,\n",
      "          4.1566e-01,  4.9148e-01, -6.9445e-01,  9.9830e-01,  1.0000e+00,\n",
      "          9.3747e-01,  8.9366e-01,  9.2651e-01, -9.9799e-01, -2.9389e-01,\n",
      "          9.9995e-01, -9.7730e-01, -1.0000e+00, -9.1234e-01, -6.9568e-01,\n",
      "          3.7277e-01, -1.0000e+00, -2.0609e-01,  1.7125e-01, -8.7448e-01,\n",
      "          5.9412e-01,  9.6720e-01,  9.9095e-01, -1.0000e+00,  6.5990e-01,\n",
      "          9.2648e-01, -6.0201e-01,  9.5347e-01, -3.2178e-01,  9.5794e-01,\n",
      "          6.5932e-01,  1.1768e-01, -2.4565e-01,  3.2490e-01, -8.8230e-01,\n",
      "         -8.7855e-01, -4.5894e-01, -6.2306e-01,  9.8882e-01,  1.1127e-01,\n",
      "         -8.1504e-01, -8.9768e-01, -2.5663e-02, -2.0069e-01, -3.3576e-01,\n",
      "         -9.4615e-01, -1.0597e-01,  5.6197e-01,  7.7034e-01,  9.0875e-02,\n",
      "          3.0440e-01, -6.8938e-01,  2.5243e-01, -1.7008e-01,  3.3678e-01,\n",
      "          6.2607e-01, -9.2541e-01, -6.4668e-01, -4.1812e-01, -1.5776e-01,\n",
      "         -5.8090e-01, -9.3592e-01,  9.5067e-01, -4.7707e-01,  7.9794e-01,\n",
      "          1.0000e+00,  1.2838e-01, -8.6789e-01,  6.2421e-01,  2.0468e-01,\n",
      "          4.3402e-03,  1.0000e+00,  7.7308e-01, -9.5914e-01, -4.9383e-01,\n",
      "          5.1447e-01, -5.0643e-01, -4.6023e-01,  9.9656e-01, -2.7889e-01,\n",
      "         -6.0374e-01, -3.1379e-01,  9.4870e-01, -9.7579e-01,  9.8235e-01,\n",
      "         -8.9237e-01, -9.4238e-01,  9.3981e-01,  9.0497e-01, -6.8348e-01,\n",
      "         -4.2984e-01,  1.2406e-01, -6.3880e-01,  3.0334e-01, -9.6749e-01,\n",
      "          7.3108e-01,  5.1503e-01,  4.4069e-02,  8.4879e-01, -9.0855e-01,\n",
      "         -4.6638e-01,  2.9909e-01, -7.3568e-01, -2.1431e-01,  7.7439e-01,\n",
      "          5.1014e-01, -3.0549e-01,  9.3042e-02, -3.4041e-01,  2.4432e-01,\n",
      "         -9.6357e-01,  3.4927e-01,  1.0000e+00, -2.4683e-01,  4.8418e-01,\n",
      "         -5.1474e-01,  5.1816e-02, -1.7388e-01,  4.7761e-01,  5.5868e-01,\n",
      "         -2.4163e-01, -8.0916e-01,  7.3723e-01, -9.7524e-01, -9.7020e-01,\n",
      "          8.5261e-01,  1.8727e-01, -2.7090e-01,  9.9998e-01,  4.6983e-01,\n",
      "          9.6978e-02,  3.6851e-01,  9.7414e-01, -8.3773e-04,  6.4376e-01,\n",
      "          8.7053e-01,  9.6059e-01, -1.8756e-01,  5.1957e-01,  8.7386e-01,\n",
      "         -8.3668e-01, -2.7663e-01, -5.9559e-01, -1.2339e-02, -8.8570e-01,\n",
      "          8.2444e-02, -9.3376e-01,  9.5201e-01,  8.6130e-01,  3.3720e-01,\n",
      "          2.3967e-01,  5.4095e-01,  1.0000e+00,  1.3089e-01,  7.5866e-01,\n",
      "         -6.5313e-01,  9.1302e-01, -9.9812e-01, -8.6791e-01, -3.1752e-01,\n",
      "         -9.1606e-03, -7.3271e-01, -3.1350e-01,  2.6582e-01, -9.5944e-01,\n",
      "          7.4126e-01,  4.9215e-01, -9.9320e-01, -9.8625e-01, -2.1465e-01,\n",
      "          9.0425e-01, -4.9062e-02, -9.3739e-01, -7.3878e-01, -5.6868e-01,\n",
      "          5.5593e-01, -2.0358e-01, -9.3490e-01, -1.9005e-01, -2.3025e-01,\n",
      "          4.5899e-01, -7.0443e-02,  5.4063e-01,  7.6846e-01,  5.9393e-01,\n",
      "         -1.9536e-01, -1.4414e-01, -2.6515e-02, -8.3050e-01,  8.8996e-01,\n",
      "         -8.3560e-01, -8.2514e-01, -1.7632e-01,  1.0000e+00, -5.3209e-01,\n",
      "          7.4747e-01,  7.9880e-01,  8.0815e-01, -1.0571e-01,  9.6487e-02,\n",
      "          8.7753e-01,  2.1673e-01, -7.5100e-01, -8.1242e-01, -9.0104e-01,\n",
      "         -3.2831e-01,  6.3693e-01,  8.2345e-03,  5.5376e-01,  7.1281e-01,\n",
      "          6.4975e-01,  1.4424e-01,  3.0209e-02, -1.5367e-01,  9.9958e-01,\n",
      "         -2.4823e-01, -4.5267e-02, -4.9861e-01,  8.4451e-03, -3.3764e-01,\n",
      "         -7.4455e-01,  1.0000e+00,  2.2909e-01,  3.0400e-01, -9.8225e-01,\n",
      "         -7.7581e-01, -9.3825e-01,  9.9999e-01,  8.0493e-01, -6.9461e-01,\n",
      "          6.7583e-01,  7.1560e-01, -7.5955e-02,  8.8280e-01, -8.8796e-02,\n",
      "         -3.6776e-01,  3.0358e-01,  9.0578e-02,  9.3570e-01, -5.4713e-01,\n",
      "         -9.4064e-01, -5.1854e-01,  3.6407e-01, -9.4587e-01,  9.9884e-01,\n",
      "         -4.6634e-01, -2.2036e-01, -4.2909e-01,  1.9812e-01,  8.0296e-01,\n",
      "         -1.1237e-01, -9.7593e-01,  3.2546e-03,  2.2387e-01,  9.4407e-01,\n",
      "          2.3152e-01, -5.3741e-01, -9.0152e-01,  7.2972e-01,  6.4678e-01,\n",
      "         -8.5261e-01, -9.2280e-01,  9.4217e-01, -9.8578e-01,  6.6755e-01,\n",
      "          1.0000e+00,  3.4225e-01, -1.6761e-01,  7.7093e-02, -3.9836e-01,\n",
      "          2.2625e-01, -2.2041e-01,  7.3612e-01, -9.2743e-01, -3.6491e-01,\n",
      "         -1.7540e-01,  2.9468e-01, -1.1303e-01,  2.6402e-01,  6.9200e-01,\n",
      "          1.5430e-01, -4.0083e-01, -5.2640e-01,  2.4087e-02,  4.3949e-01,\n",
      "          8.6077e-01, -2.6866e-01, -1.0388e-01,  7.5583e-03, -1.2241e-01,\n",
      "         -9.1376e-01, -2.1348e-01, -2.9673e-01, -9.9988e-01,  6.9455e-01,\n",
      "         -1.0000e+00,  2.8368e-01,  8.6733e-02, -1.2220e-01,  7.9206e-01,\n",
      "          1.5489e-02,  4.9311e-01, -7.3105e-01, -8.1444e-01,  5.0827e-01,\n",
      "          7.2358e-01, -2.9349e-01, -5.1790e-01, -6.9774e-01,  2.4637e-01,\n",
      "         -1.5526e-02,  2.1339e-01, -5.1806e-01,  7.8137e-01, -1.7301e-01,\n",
      "          1.0000e+00,  1.9527e-01, -7.5410e-01, -9.8262e-01,  1.5416e-01,\n",
      "         -2.1457e-01,  1.0000e+00, -9.3285e-01, -9.1573e-01,  2.9430e-01,\n",
      "         -6.9617e-01, -8.3260e-01,  2.6819e-01, -3.4682e-02, -7.8862e-01,\n",
      "         -8.5820e-01,  9.5101e-01,  9.4690e-01, -5.5200e-01,  4.5879e-01,\n",
      "         -3.4441e-01, -5.6057e-01, -4.5147e-02,  7.0248e-01,  9.7133e-01,\n",
      "          2.6254e-01,  8.9137e-01,  4.2302e-01, -7.3707e-02,  9.4970e-01,\n",
      "          1.6445e-01,  6.1382e-01,  1.0270e-01,  1.0000e+00,  2.7983e-01,\n",
      "         -8.8676e-01,  1.4404e-01, -9.7244e-01, -1.6864e-01, -9.5221e-01,\n",
      "          2.6231e-01,  2.7997e-01,  8.9316e-01, -2.3383e-01,  9.4295e-01,\n",
      "         -5.3833e-01,  4.3593e-02, -7.9243e-01, -3.1933e-01,  3.5616e-01,\n",
      "         -9.0270e-01, -9.7206e-01, -9.7301e-01,  6.8435e-01, -4.2106e-01,\n",
      "          4.4724e-02,  1.2440e-01,  7.1743e-03,  3.5916e-01,  4.4393e-01,\n",
      "         -1.0000e+00,  9.2962e-01,  3.8557e-01,  8.5492e-01,  9.2992e-01,\n",
      "          7.0625e-01,  4.8370e-01,  2.3270e-01, -9.7541e-01, -9.8218e-01,\n",
      "         -3.2932e-01, -2.1163e-01,  7.5084e-01,  6.3202e-01,  8.8856e-01,\n",
      "          4.3251e-01, -5.0404e-01, -6.7028e-02, -2.9505e-01, -3.2807e-01,\n",
      "         -9.8568e-01,  4.3446e-01, -5.8658e-01, -9.7724e-01,  9.3651e-01,\n",
      "         -1.3708e-01, -1.3665e-01, -9.2903e-02, -6.6635e-01,  9.7278e-01,\n",
      "          7.0707e-01,  4.3204e-01,  8.7915e-02,  4.7217e-01,  8.3990e-01,\n",
      "          9.4993e-01,  9.7219e-01, -6.7202e-01,  8.3279e-01, -5.4167e-01,\n",
      "          4.1125e-01,  3.4719e-01, -9.0791e-01,  9.1832e-02,  2.0505e-01,\n",
      "         -2.8610e-01,  1.5352e-01, -1.1304e-01, -9.8395e-01,  1.8631e-01,\n",
      "         -2.0863e-01,  6.1166e-01, -2.9382e-01,  5.8579e-02, -3.7076e-01,\n",
      "         -3.7402e-02, -6.2659e-01, -7.5935e-01,  5.6508e-01,  5.0258e-01,\n",
      "          8.7703e-01,  8.0735e-01, -6.9027e-02, -6.4556e-01, -2.2308e-01,\n",
      "         -7.0203e-01, -8.9239e-01,  9.4453e-01, -2.7452e-02, -3.4130e-01,\n",
      "          5.0977e-01, -1.5005e-01,  5.0155e-01,  9.2491e-02, -3.1371e-01,\n",
      "         -3.9861e-01, -6.5197e-01,  8.3609e-01,  4.2015e-02, -5.3505e-01,\n",
      "         -7.0400e-01,  5.6731e-01,  3.1090e-01,  9.9974e-01, -6.7131e-01,\n",
      "         -8.3116e-01, -1.6593e-01, -3.9197e-01,  2.8166e-01, -4.2960e-01,\n",
      "         -1.0000e+00,  3.9846e-01, -3.7210e-01,  6.3236e-01, -6.8413e-01,\n",
      "          4.8827e-01, -7.2434e-01, -9.8220e-01, -1.6252e-01,  4.2167e-02,\n",
      "          6.8658e-01, -4.7085e-01, -7.6191e-01,  4.8094e-01, -1.6688e-01,\n",
      "          9.5317e-01,  8.1554e-01, -3.6865e-01,  1.1302e-01,  6.0376e-01,\n",
      "         -6.5595e-01, -6.1998e-01,  9.0952e-01]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0573,  0.1625, -0.4028,  ..., -0.4454,  0.2880,  0.3058],\n",
      "         [-0.1744, -0.4683, -0.2665,  ..., -0.2229,  0.7547, -0.4456],\n",
      "         [ 0.3816, -0.6513,  0.3829,  ..., -0.7144,  0.1510, -0.7006],\n",
      "         [-0.1328, -0.6548,  0.9204,  ..., -0.4545,  0.3768, -1.0013],\n",
      "         [-0.0467, -0.7707, -0.9214,  ...,  0.1693,  0.3671, -0.2546],\n",
      "         [ 0.6713, -0.0606, -0.2756,  ...,  0.1626, -0.3611, -0.2107]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-0.9639, -0.4993, -0.9370,  0.9181,  0.6590, -0.2347,  0.9709,  0.3910,\n",
      "         -0.8730, -1.0000, -0.6252,  0.9708,  0.9868,  0.7147,  0.9811, -0.9054,\n",
      "         -0.6828, -0.7329,  0.3840, -0.8714,  0.8462,  1.0000, -0.1027,  0.4062,\n",
      "          0.6092,  0.9969, -0.9039,  0.9731,  0.9827,  0.7820, -0.8712,  0.1885,\n",
      "         -0.9914, -0.2279, -0.9189, -0.9961,  0.4929, -0.8633, -0.1680, -0.0422,\n",
      "         -0.9448,  0.3537,  1.0000,  0.2448,  0.4656, -0.4160, -1.0000,  0.3710,\n",
      "         -0.9528,  0.9701,  0.9430,  0.8852,  0.3447,  0.5873,  0.5981, -0.1670,\n",
      "          0.0284,  0.1660, -0.3779, -0.6841, -0.6573,  0.6169, -0.9182, -0.9448,\n",
      "          0.9527,  0.8685, -0.2310, -0.3400, -0.2363, -0.0459,  0.9648,  0.3784,\n",
      "          0.0015, -0.9229,  0.7714,  0.3504, -0.8224,  1.0000, -0.8578, -0.9867,\n",
      "          0.8529,  0.8783,  0.7610, -0.4921,  0.5866, -1.0000,  0.7434, -0.1500,\n",
      "         -0.9944,  0.3092,  0.6802, -0.3913,  0.4249,  0.7614, -0.7716, -0.5902,\n",
      "         -0.4421, -0.8968, -0.4131, -0.4213,  0.1690, -0.3365, -0.6165, -0.5304,\n",
      "          0.4636, -0.5859, -0.7818,  0.4761,  0.0640,  0.7744,  0.5892, -0.4240,\n",
      "          0.6625, -0.9849,  0.7946, -0.4982, -0.9932, -0.7690, -0.9928,  0.7947,\n",
      "         -0.4692, -0.3429,  0.9878, -0.2252,  0.6162, -0.1899, -0.9633, -1.0000,\n",
      "         -0.8550, -0.6835, -0.3601, -0.4255, -0.9867, -0.9773,  0.7461,  0.9780,\n",
      "          0.3300,  1.0000, -0.4687,  0.9732, -0.4603, -0.7008,  0.7487, -0.6143,\n",
      "          0.8269,  0.7566, -0.8236,  0.2973, -0.4219,  0.6640, -0.8196, -0.3078,\n",
      "         -0.8190, -0.9741, -0.4802,  0.9728, -0.5953, -0.9732, -0.0724, -0.4220,\n",
      "         -0.6787,  0.9119,  0.8096,  0.5509, -0.4881,  0.5235,  0.5619,  0.7361,\n",
      "         -0.9376, -0.2613,  0.6226, -0.4266, -0.8814, -0.9843, -0.5397,  0.6765,\n",
      "          0.9952,  0.8805,  0.4681,  0.8854, -0.3759,  0.8607, -0.9751,  0.9881,\n",
      "         -0.3364,  0.3848,  0.1099,  0.4441, -0.9595,  0.1625,  0.9457, -0.7576,\n",
      "         -0.9179, -0.2893, -0.5712, -0.5417, -0.8286,  0.7414, -0.4026, -0.3658,\n",
      "         -0.1692,  0.9522,  0.9966,  0.9020,  0.2979,  0.8393, -0.9540, -0.6894,\n",
      "          0.1825,  0.4281,  0.1870,  0.9973, -0.7403, -0.2360, -0.9683, -0.9922,\n",
      "          0.0485, -0.9644, -0.2205, -0.7313,  0.7964,  0.1598,  0.7443,  0.6463,\n",
      "         -0.9982, -0.8792,  0.5282, -0.6203,  0.5653, -0.3124,  0.3869,  0.9590,\n",
      "         -0.7478,  0.9321,  0.9450, -0.8777, -0.8455,  0.9289, -0.4548,  0.9536,\n",
      "         -0.7856,  0.9961,  0.9635,  0.9318, -0.9671, -0.7757, -0.9608, -0.8807,\n",
      "         -0.1498,  0.3246,  0.9498,  0.7949,  0.5329,  0.2485, -0.8161,  0.9999,\n",
      "         -0.3527, -0.9770,  0.0037, -0.3620, -0.9924,  0.9177,  0.4558,  0.2058,\n",
      "         -0.5407, -0.8518, -0.9781,  0.9580,  0.2718,  0.9968, -0.2733, -0.9850,\n",
      "         -0.7317, -0.9557, -0.0782, -0.4049, -0.4331, -0.1381, -0.9814,  0.6231,\n",
      "          0.6514,  0.6933, -0.8871,  0.9999,  1.0000,  0.9832,  0.9480,  0.9792,\n",
      "         -1.0000, -0.4907,  1.0000, -0.9972, -1.0000, -0.9637, -0.7868,  0.5556,\n",
      "         -1.0000, -0.2827, -0.1662, -0.9524,  0.8380,  0.9865,  0.9993, -1.0000,\n",
      "          0.8841,  0.9749, -0.8301,  0.9880, -0.5627,  0.9809,  0.6562,  0.3913,\n",
      "         -0.4112,  0.4981, -0.9584, -0.9537, -0.6507, -0.7746,  0.9988,  0.3178,\n",
      "         -0.8923, -0.9569,  0.4846, -0.2291, -0.2566, -0.9813, -0.2779,  0.7789,\n",
      "          0.9105,  0.2398,  0.4435, -0.8275,  0.4358, -0.0067,  0.5701,  0.8237,\n",
      "         -0.9564, -0.7212, -0.4226, -0.1180, -0.7685, -0.9754,  0.9858, -0.5656,\n",
      "          0.9535,  1.0000,  0.1815, -0.9606,  0.7683,  0.3945, -0.2715,  1.0000,\n",
      "          0.8628, -0.9854, -0.7557,  0.6681, -0.6831, -0.7360,  0.9999, -0.2509,\n",
      "         -0.7722, -0.5705,  0.9849, -0.9924,  0.9971, -0.9724, -0.9825,  0.9837,\n",
      "          0.9621, -0.8634, -0.7938,  0.3014, -0.8191,  0.3442, -0.9889,  0.8583,\n",
      "          0.7474, -0.2749,  0.9386, -0.9649, -0.7691,  0.4106, -0.7648, -0.2074,\n",
      "          0.9649,  0.6622, -0.4458,  0.1391, -0.4272, -0.2285, -0.9903,  0.4343,\n",
      "          1.0000, -0.3728,  0.7500, -0.6096, -0.0782, -0.0467,  0.5787,  0.7230,\n",
      "         -0.4480, -0.9231,  0.8529, -0.9942, -0.9883,  0.9108,  0.2968, -0.4507,\n",
      "          1.0000,  0.6721,  0.2267,  0.4615,  0.9947,  0.1456,  0.8221,  0.9437,\n",
      "          0.9908, -0.3572,  0.7612,  0.9592, -0.9562, -0.4870, -0.7562,  0.0359,\n",
      "         -0.9192, -0.1009, -0.9800,  0.9813,  0.9810,  0.5379,  0.3425,  0.6109,\n",
      "          1.0000, -0.3027,  0.7574, -0.7509,  0.9638, -0.9998, -0.9582, -0.5514,\n",
      "         -0.2216, -0.8854, -0.4296,  0.4852, -0.9855,  0.9070,  0.7439, -0.9990,\n",
      "         -0.9959, -0.2874,  0.9608,  0.2318, -0.9910, -0.8865, -0.6975,  0.7487,\n",
      "         -0.4122, -0.9673, -0.3669, -0.4526,  0.6604, -0.3187,  0.7298,  0.9125,\n",
      "          0.4807, -0.6056, -0.4237, -0.1390, -0.9107,  0.9518, -0.9408, -0.9633,\n",
      "         -0.3652,  1.0000, -0.6232,  0.9462,  0.8387,  0.8843, -0.2297,  0.3219,\n",
      "          0.9521,  0.3487, -0.8649, -0.9282, -0.9284, -0.5327,  0.8448,  0.3688,\n",
      "          0.7981,  0.8851,  0.7787,  0.2426, -0.1275,  0.0627,  1.0000, -0.3206,\n",
      "         -0.2520, -0.6673, -0.1260, -0.5247, -0.7049,  1.0000,  0.4109,  0.5311,\n",
      "         -0.9940, -0.9166, -0.9730,  1.0000,  0.8794, -0.9183,  0.8293,  0.7381,\n",
      "         -0.2460,  0.9386, -0.2837, -0.4118,  0.3727,  0.2090,  0.9740, -0.6829,\n",
      "         -0.9815, -0.7682,  0.5797, -0.9837,  1.0000, -0.7271, -0.3817, -0.5546,\n",
      "         -0.3283,  0.7684, -0.0143, -0.9911, -0.3802,  0.3628,  0.9782,  0.4206,\n",
      "         -0.8047, -0.9602,  0.8745,  0.8764, -0.9573, -0.9632,  0.9773, -0.9949,\n",
      "          0.7125,  1.0000,  0.4571,  0.2506,  0.3976, -0.6670,  0.5187, -0.3151,\n",
      "          0.8834, -0.9821, -0.3898, -0.2883,  0.4084, -0.2781, -0.2061,  0.8508,\n",
      "          0.2817, -0.7630, -0.7728, -0.2177,  0.5364,  0.9567, -0.3668, -0.3175,\n",
      "          0.2292, -0.2774, -0.9759, -0.3111, -0.6086, -1.0000,  0.8677, -1.0000,\n",
      "          0.6034,  0.4101, -0.3864,  0.9284,  0.1872,  0.6729, -0.8836, -0.9023,\n",
      "          0.3494,  0.8616, -0.4054, -0.7423, -0.8551,  0.4803, -0.1593,  0.2331,\n",
      "         -0.6162,  0.8185, -0.3419,  1.0000,  0.2587, -0.8902, -0.9961,  0.2707,\n",
      "         -0.3756,  1.0000, -0.9811, -0.9696,  0.5954, -0.8535, -0.9130,  0.4765,\n",
      "          0.1160, -0.8599, -0.9679,  0.9881,  0.9737, -0.7367,  0.5846, -0.4798,\n",
      "         -0.7181,  0.1214,  0.8910,  0.9905,  0.5837,  0.9690,  0.6102, -0.1811,\n",
      "          0.9854,  0.3214,  0.7951,  0.2239,  1.0000,  0.4570, -0.9499,  0.0648,\n",
      "         -0.9921, -0.3552, -0.9790,  0.4716,  0.3796,  0.9339, -0.2584,  0.9850,\n",
      "         -0.8884,  0.1191, -0.8238, -0.5894,  0.5726, -0.9569, -0.9890, -0.9905,\n",
      "          0.6442, -0.5990, -0.1902,  0.2571,  0.2937,  0.5793,  0.5846, -1.0000,\n",
      "          0.9707,  0.6047,  0.9628,  0.9769,  0.7969,  0.5512,  0.3688, -0.9935,\n",
      "         -0.9973, -0.4643, -0.3199,  0.8706,  0.7476,  0.9571,  0.5946, -0.5784,\n",
      "         -0.1496, -0.5475, -0.3116, -0.9961,  0.6147, -0.7207, -0.9945,  0.9781,\n",
      "         -0.1213, -0.2692, -0.1053, -0.8538,  0.9879,  0.9060,  0.6091,  0.0540,\n",
      "          0.5773,  0.9452,  0.9863,  0.9897, -0.8878,  0.9530, -0.7677,  0.6045,\n",
      "          0.6884, -0.9590,  0.2035,  0.6452, -0.6606,  0.4414, -0.3820, -0.9940,\n",
      "          0.7435, -0.4090,  0.7173, -0.5816, -0.0113, -0.5246, -0.1963, -0.8200,\n",
      "         -0.8477,  0.7834,  0.7695,  0.9511,  0.7920, -0.0710, -0.8780, -0.3213,\n",
      "         -0.8836, -0.9467,  0.9839, -0.1764, -0.5626,  0.6764,  0.0374,  0.7217,\n",
      "          0.2637, -0.4755, -0.4506, -0.8280,  0.9425, -0.5586, -0.6535, -0.7009,\n",
      "          0.8099,  0.4119,  1.0000, -0.8556, -0.9608, -0.5079, -0.4905,  0.5642,\n",
      "         -0.7158, -1.0000,  0.5819, -0.5215,  0.7922, -0.8036,  0.8845, -0.8239,\n",
      "         -0.9957, -0.3756,  0.5139,  0.7862, -0.5883, -0.8074,  0.7892, -0.4830,\n",
      "          0.9881,  0.9518, -0.7551,  0.0959,  0.8097, -0.7260, -0.8043,  0.9666]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0112,  0.2276, -0.0150,  ..., -0.6444,  0.2925,  0.2402],\n",
      "         [ 0.4941, -0.5178, -0.4269,  ..., -0.0328,  0.5467, -0.3338],\n",
      "         [ 0.3900, -0.6383,  0.4965,  ..., -0.5439,  0.6108, -0.0625],\n",
      "         ...,\n",
      "         [ 0.6872, -1.0918,  0.6246,  ..., -0.3236, -0.4004, -0.3162],\n",
      "         [ 0.1942, -0.4999, -0.8440,  ..., -0.3182,  0.4230, -0.4486],\n",
      "         [ 0.7494, -0.0389, -0.1210,  ...,  0.1700, -0.3332, -0.2397]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-9.3796e-01, -4.5639e-01, -8.7191e-01,  8.6433e-01,  5.6887e-01,\n",
      "         -2.0286e-01,  9.5178e-01,  4.8838e-01, -7.4416e-01, -9.9999e-01,\n",
      "         -4.3665e-01,  9.2300e-01,  9.8893e-01,  4.5803e-01,  9.6810e-01,\n",
      "         -8.6178e-01, -3.9088e-01, -7.1988e-01,  3.3063e-01, -7.7680e-01,\n",
      "          7.2246e-01,  9.9996e-01,  9.3832e-02,  4.0559e-01,  5.3566e-01,\n",
      "          9.7530e-01, -8.4023e-01,  9.6424e-01,  9.6352e-01,  7.4691e-01,\n",
      "         -8.1352e-01,  3.0470e-01, -9.8933e-01, -2.2735e-01, -8.0476e-01,\n",
      "         -9.9477e-01,  4.6690e-01, -8.2299e-01, -5.3728e-02, -9.4489e-03,\n",
      "         -9.1209e-01,  3.1884e-01,  9.9997e-01, -2.2249e-01,  2.7557e-01,\n",
      "         -3.8768e-01, -1.0000e+00,  3.4691e-01, -9.1258e-01,  8.9415e-01,\n",
      "          8.2539e-01,  7.6101e-01,  1.8143e-01,  5.3361e-01,  5.0755e-01,\n",
      "         -1.0178e-01, -3.6825e-02,  1.0154e-01, -2.7839e-01, -6.8477e-01,\n",
      "         -6.8634e-01,  5.3980e-01, -8.2470e-01, -9.3372e-01,  8.6837e-01,\n",
      "          7.4750e-01, -2.3483e-01, -3.6898e-01, -8.6857e-02,  9.5936e-03,\n",
      "          9.5421e-01,  2.5728e-01, -1.5095e-01, -8.8833e-01,  6.0409e-01,\n",
      "          3.3821e-01, -7.1792e-01,  1.0000e+00, -7.1743e-01, -9.8361e-01,\n",
      "          7.5573e-01,  7.7695e-01,  6.3965e-01, -3.5758e-01,  4.4487e-01,\n",
      "         -1.0000e+00,  5.9332e-01, -1.1371e-01, -9.9233e-01,  2.8997e-01,\n",
      "          6.1824e-01, -2.9646e-01,  5.1327e-01,  6.1448e-01, -6.6476e-01,\n",
      "         -4.2770e-01, -3.1199e-01, -7.5532e-01, -3.0451e-01, -2.5479e-01,\n",
      "          2.5993e-02, -2.7143e-01, -4.9260e-01, -3.8388e-01,  3.2146e-01,\n",
      "         -6.1635e-01, -7.1673e-01,  4.7151e-01,  1.3447e-01,  7.6567e-01,\n",
      "          5.1490e-01, -3.5399e-01,  5.5817e-01, -9.6962e-01,  6.8431e-01,\n",
      "         -4.0214e-01, -9.8956e-01, -6.5675e-01, -9.9031e-01,  6.9889e-01,\n",
      "         -4.0487e-01, -2.6590e-01,  9.7606e-01, -1.2457e-01,  5.6913e-01,\n",
      "         -2.4496e-01, -8.8245e-01, -1.0000e+00, -6.9750e-01, -5.1447e-01,\n",
      "         -3.0390e-01, -3.3219e-01, -9.8135e-01, -9.6432e-01,  7.4041e-01,\n",
      "          9.6655e-01,  3.0915e-01,  9.9993e-01, -4.0900e-01,  9.6044e-01,\n",
      "         -3.1093e-01, -6.6115e-01,  5.7602e-01, -6.1817e-01,  7.6059e-01,\n",
      "          4.8931e-01, -7.6807e-01,  3.0899e-01, -3.6114e-01,  3.8804e-01,\n",
      "         -7.7127e-01, -3.5798e-01, -6.8781e-01, -9.4723e-01, -4.1623e-01,\n",
      "          9.5885e-01, -5.7497e-01, -8.9085e-01,  9.7553e-02, -3.2545e-01,\n",
      "         -5.5680e-01,  8.8117e-01,  7.2305e-01,  4.8335e-01, -5.0901e-01,\n",
      "          5.0437e-01,  3.9893e-01,  6.1459e-01, -9.3456e-01, -5.7925e-02,\n",
      "          5.1767e-01, -4.0285e-01, -8.2365e-01, -9.8071e-01, -3.8662e-01,\n",
      "          6.5571e-01,  9.9121e-01,  8.8139e-01,  2.7173e-01,  7.6377e-01,\n",
      "         -3.5425e-01,  7.1958e-01, -9.6475e-01,  9.8376e-01, -1.5803e-01,\n",
      "          3.8444e-01,  1.4669e-01,  3.1524e-01, -8.9199e-01,  6.3987e-02,\n",
      "          8.9924e-01, -6.0546e-01, -8.6349e-01, -1.3026e-01, -4.8746e-01,\n",
      "         -5.0538e-01, -7.7258e-01,  6.0858e-01, -3.6179e-01, -4.3114e-01,\n",
      "         -1.5046e-01,  9.4845e-01,  9.9195e-01,  7.9365e-01,  1.3036e-01,\n",
      "          7.2408e-01, -9.4057e-01, -5.9960e-01,  1.4926e-01,  3.2584e-01,\n",
      "          1.5289e-01,  9.9477e-01, -5.6944e-01, -2.3594e-01, -9.3457e-01,\n",
      "         -9.8594e-01,  7.0223e-02, -9.3330e-01, -1.4924e-01, -6.7024e-01,\n",
      "          7.1288e-01,  1.6387e-01,  5.4182e-01,  5.3818e-01, -9.9615e-01,\n",
      "         -8.6020e-01,  4.3160e-01, -5.1649e-01,  5.0269e-01, -2.4477e-01,\n",
      "          5.2255e-01,  9.2544e-01, -7.0024e-01,  9.0391e-01,  9.1832e-01,\n",
      "         -8.5636e-01, -7.5490e-01,  8.8893e-01, -3.7485e-01,  9.0497e-01,\n",
      "         -7.5052e-01,  9.9352e-01,  8.4403e-01,  8.0089e-01, -9.4393e-01,\n",
      "         -6.6387e-01, -9.4282e-01, -7.7028e-01, -1.0031e-01,  1.9083e-01,\n",
      "          8.8188e-01,  6.6681e-01,  5.6007e-01,  3.2362e-01, -7.2911e-01,\n",
      "          9.9946e-01, -7.2196e-01, -9.6779e-01,  1.0968e-01, -3.5105e-01,\n",
      "         -9.8867e-01,  8.6564e-01,  4.4529e-01,  1.2120e-01, -4.8673e-01,\n",
      "         -8.1753e-01, -9.6839e-01,  9.2300e-01,  2.9925e-01,  9.9623e-01,\n",
      "         -2.7520e-01, -9.5892e-01, -7.5331e-01, -9.3836e-01, -1.2379e-01,\n",
      "         -2.3372e-01, -3.0976e-01, -1.0830e-01, -9.7283e-01,  5.8506e-01,\n",
      "          6.2309e-01,  6.1709e-01, -8.1664e-01,  9.9968e-01,  1.0000e+00,\n",
      "          9.7567e-01,  9.3658e-01,  9.5232e-01, -9.9981e-01, -4.2281e-01,\n",
      "          1.0000e+00, -9.8903e-01, -1.0000e+00, -9.5267e-01, -7.2007e-01,\n",
      "          4.4821e-01, -1.0000e+00, -3.7494e-01, -1.1219e-01, -9.2438e-01,\n",
      "          5.8919e-01,  9.8184e-01,  9.9765e-01, -1.0000e+00,  8.8102e-01,\n",
      "          9.5745e-01, -6.8831e-01,  9.4348e-01, -4.2240e-01,  9.8159e-01,\n",
      "          7.0669e-01,  5.9908e-01, -3.8497e-01,  5.2630e-01, -9.2749e-01,\n",
      "         -9.1200e-01, -5.3026e-01, -6.9961e-01,  9.9569e-01,  2.3607e-01,\n",
      "         -8.5195e-01, -9.2357e-01,  2.9236e-01, -3.0775e-01, -3.3229e-01,\n",
      "         -9.7085e-01, -2.3508e-01,  5.2943e-01,  7.8933e-01,  2.1700e-01,\n",
      "          4.2329e-01, -7.9819e-01,  2.8265e-01, -1.2315e-01,  4.4652e-01,\n",
      "          7.4088e-01, -9.5776e-01, -7.1025e-01, -1.4926e-01, -2.6174e-01,\n",
      "         -6.8333e-01, -9.6948e-01,  9.7130e-01, -5.3216e-01,  8.2028e-01,\n",
      "          1.0000e+00,  3.3517e-02, -9.3264e-01,  6.2659e-01,  3.1402e-01,\n",
      "         -3.3944e-01,  1.0000e+00,  8.3238e-01, -9.8364e-01, -6.3075e-01,\n",
      "          7.1833e-01, -6.7665e-01, -6.5941e-01,  9.9971e-01, -2.6111e-01,\n",
      "         -5.8889e-01, -4.9665e-01,  9.7990e-01, -9.9052e-01,  9.9090e-01,\n",
      "         -9.4575e-01, -9.6623e-01,  9.6848e-01,  9.5193e-01, -6.9344e-01,\n",
      "         -7.0390e-01,  2.0196e-01, -7.1583e-01,  3.5347e-01, -9.7882e-01,\n",
      "          7.8600e-01,  6.4839e-01, -1.8125e-01,  9.1431e-01, -9.2974e-01,\n",
      "         -6.0866e-01,  4.2264e-01, -6.9926e-01, -6.0686e-02,  9.3412e-01,\n",
      "          5.6366e-01, -3.2068e-01,  1.0100e-01, -3.1704e-01, -2.7615e-01,\n",
      "         -9.8620e-01,  2.7832e-01,  1.0000e+00, -3.7348e-01,  5.1810e-01,\n",
      "         -5.9606e-01, -3.5571e-02, -8.7877e-02,  6.1152e-01,  6.6165e-01,\n",
      "         -3.7003e-01, -8.7516e-01,  7.0967e-01, -9.8835e-01, -9.8963e-01,\n",
      "          8.4721e-01,  3.2398e-01, -4.1496e-01,  1.0000e+00,  3.8194e-01,\n",
      "          2.6910e-01,  3.2004e-01,  9.7279e-01, -5.0395e-05,  6.9989e-01,\n",
      "          8.2429e-01,  9.8338e-01, -3.1790e-01,  6.2947e-01,  9.2902e-01,\n",
      "         -8.9190e-01, -4.0000e-01, -7.4560e-01,  2.6484e-02, -9.0910e-01,\n",
      "          1.9482e-02, -9.6879e-01,  9.7149e-01,  8.8675e-01,  4.5112e-01,\n",
      "          3.0600e-01,  4.6610e-01,  1.0000e+00, -2.8056e-01,  7.2082e-01,\n",
      "         -6.7319e-01,  9.3001e-01, -9.9941e-01, -9.1553e-01, -5.1648e-01,\n",
      "         -1.0512e-01, -7.8981e-01, -3.2613e-01,  4.0283e-01, -9.7887e-01,\n",
      "          7.2015e-01,  6.3523e-01, -9.9613e-01, -9.9281e-01, -7.8243e-02,\n",
      "          9.0156e-01,  1.9726e-01, -9.7777e-01, -8.0760e-01, -6.5229e-01,\n",
      "          6.4635e-01, -3.6661e-01, -9.5192e-01, -2.8108e-02, -4.1001e-01,\n",
      "          5.3584e-01, -2.6198e-01,  6.1048e-01,  7.6029e-01,  6.0507e-01,\n",
      "         -3.2127e-01, -3.5011e-01, -2.4539e-01, -8.6214e-01,  9.0668e-01,\n",
      "         -9.1785e-01, -9.0692e-01, -3.1306e-01,  1.0000e+00, -6.1025e-01,\n",
      "          8.4087e-01,  8.0477e-01,  8.5718e-01, -1.6916e-01,  3.2906e-01,\n",
      "          9.1084e-01,  3.7824e-01, -8.0655e-01, -8.5161e-01, -8.2089e-01,\n",
      "         -4.1947e-01,  7.7120e-01,  2.7562e-01,  6.8130e-01,  8.4650e-01,\n",
      "          6.5782e-01,  1.9705e-01, -5.6161e-02,  1.2667e-01,  9.9991e-01,\n",
      "         -1.7862e-01, -2.2632e-01, -6.4235e-01, -4.9246e-02, -5.1074e-01,\n",
      "         -5.3649e-01,  1.0000e+00,  3.2107e-01,  2.8045e-01, -9.9160e-01,\n",
      "         -8.0769e-01, -9.5752e-01,  1.0000e+00,  8.5579e-01, -8.3203e-01,\n",
      "          7.7643e-01,  6.3110e-01, -2.5523e-01,  8.6840e-01, -2.9126e-01,\n",
      "         -3.3699e-01,  3.6213e-01,  1.4742e-01,  9.6472e-01, -6.3368e-01,\n",
      "         -9.7183e-01, -6.1220e-01,  4.9750e-01, -9.7158e-01,  9.9983e-01,\n",
      "         -6.4006e-01, -3.2116e-01, -4.1722e-01, -1.6351e-01,  7.5517e-01,\n",
      "         -3.5306e-02, -9.8741e-01, -2.9176e-01,  2.0565e-01,  9.7089e-01,\n",
      "          2.9646e-01, -6.5550e-01, -9.3518e-01,  7.9744e-01,  7.4100e-01,\n",
      "         -8.8394e-01, -9.3781e-01,  9.7469e-01, -9.8755e-01,  6.8726e-01,\n",
      "          1.0000e+00,  4.1896e-01,  9.7253e-03,  2.7835e-01, -6.3315e-01,\n",
      "          3.8476e-01, -2.7720e-01,  7.9414e-01, -9.6234e-01, -4.4804e-01,\n",
      "         -2.2576e-01,  2.9514e-01, -1.6359e-01, -1.0597e-02,  7.6082e-01,\n",
      "          2.1818e-01, -6.2617e-01, -7.2549e-01, -1.7870e-01,  5.3287e-01,\n",
      "          9.0186e-01, -3.0489e-01, -2.6265e-01,  2.1240e-01, -2.1160e-01,\n",
      "         -9.6016e-01, -4.4614e-01, -5.1887e-01, -9.9999e-01,  8.2718e-01,\n",
      "         -1.0000e+00,  3.6685e-01,  1.1652e-01, -3.3873e-01,  8.7443e-01,\n",
      "          4.1933e-01,  4.8444e-01, -8.2084e-01, -8.4346e-01,  3.6160e-01,\n",
      "          7.9975e-01, -2.7987e-01, -5.3426e-01, -7.7407e-01,  3.9329e-01,\n",
      "         -1.0031e-01,  2.8169e-01, -4.4536e-01,  7.7280e-01, -3.6826e-01,\n",
      "          1.0000e+00,  1.9949e-01, -7.2470e-01, -9.9175e-01,  2.6351e-01,\n",
      "         -2.9133e-01,  1.0000e+00, -9.6945e-01, -9.6028e-01,  4.9719e-01,\n",
      "         -7.8205e-01, -8.7267e-01,  3.5224e-01,  1.1533e-01, -7.7260e-01,\n",
      "         -9.0588e-01,  9.8117e-01,  9.3635e-01, -6.5007e-01,  3.5720e-01,\n",
      "         -4.4577e-01, -6.1963e-01,  9.8853e-03,  7.8745e-01,  9.8971e-01,\n",
      "          5.4093e-01,  9.5943e-01,  4.4588e-01,  1.4106e-01,  9.7798e-01,\n",
      "          2.8178e-01,  6.6311e-01,  1.9087e-01,  1.0000e+00,  4.2474e-01,\n",
      "         -9.3007e-01,  2.6606e-01, -9.9048e-01, -2.6733e-01, -9.6294e-01,\n",
      "          3.7953e-01,  2.9244e-01,  9.1332e-01, -2.5191e-01,  9.7750e-01,\n",
      "         -6.9635e-01,  3.6142e-02, -6.5948e-01, -2.3770e-01,  5.1397e-01,\n",
      "         -9.3979e-01, -9.8769e-01, -9.8916e-01,  6.5590e-01, -4.6088e-01,\n",
      "         -3.2247e-02,  3.0057e-01,  2.5001e-01,  5.6239e-01,  5.8574e-01,\n",
      "         -1.0000e+00,  9.5663e-01,  5.1506e-01,  8.8709e-01,  9.6850e-01,\n",
      "          7.0077e-01,  4.9535e-01,  3.2203e-01, -9.9094e-01, -9.9216e-01,\n",
      "         -4.3320e-01, -2.9127e-01,  8.1973e-01,  7.2801e-01,  9.2285e-01,\n",
      "          5.2126e-01, -5.7812e-01, -2.9294e-01, -3.5909e-01, -5.2496e-01,\n",
      "         -9.9485e-01,  5.4699e-01, -6.2327e-01, -9.8553e-01,  9.6425e-01,\n",
      "         -2.0937e-01, -1.3226e-01,  3.9002e-03, -8.0717e-01,  9.7631e-01,\n",
      "          7.8991e-01,  4.2068e-01,  2.0805e-01,  5.1534e-01,  9.2356e-01,\n",
      "          9.7419e-01,  9.8765e-01, -7.7340e-01,  8.6260e-01, -6.6901e-01,\n",
      "          5.4461e-01,  5.7461e-01, -9.4813e-01,  1.7795e-01,  4.1712e-01,\n",
      "         -4.9300e-01,  3.0565e-01, -3.1719e-01, -9.9178e-01,  3.8906e-01,\n",
      "         -4.0618e-01,  6.8184e-01, -4.7981e-01, -6.7477e-02, -4.6495e-01,\n",
      "         -3.0796e-01, -7.3534e-01, -7.5588e-01,  7.1417e-01,  6.2997e-01,\n",
      "          9.2121e-01,  7.5968e-01, -1.1824e-01, -7.4771e-01, -2.8825e-01,\n",
      "         -7.7698e-01, -9.2430e-01,  9.6947e-01, -1.8299e-01, -3.7291e-01,\n",
      "          4.5085e-01,  8.5473e-02,  7.0168e-01,  1.9175e-01, -5.0246e-01,\n",
      "         -4.5489e-01, -8.1968e-01,  9.0003e-01, -4.0964e-01, -6.6526e-01,\n",
      "         -6.5062e-01,  7.8865e-01,  4.1885e-01,  9.9997e-01, -7.7076e-01,\n",
      "         -8.8480e-01, -4.5413e-01, -4.3713e-01,  5.0499e-01, -6.0242e-01,\n",
      "         -1.0000e+00,  4.9490e-01, -4.5851e-01,  5.9232e-01, -6.6642e-01,\n",
      "          8.6667e-01, -7.2215e-01, -9.8958e-01, -2.8763e-01,  2.6078e-01,\n",
      "          6.7329e-01, -5.1772e-01, -6.9760e-01,  6.7070e-01, -1.0597e-01,\n",
      "          9.6481e-01,  9.0712e-01, -5.5242e-01,  7.2148e-02,  7.0953e-01,\n",
      "         -6.5712e-01, -7.6322e-01,  9.4339e-01]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.3071,  0.0565, -0.2852,  ..., -0.0963,  0.2926,  0.4157],\n",
      "         [ 0.6676,  0.0325, -0.5913,  ..., -0.0449,  0.7467,  0.1695],\n",
      "         [ 0.9672,  0.7228,  0.1272,  ...,  0.1569,  0.2548, -0.0648],\n",
      "         ...,\n",
      "         [ 0.3668,  0.7574,  0.1329,  ...,  0.1216,  0.4169, -0.5457],\n",
      "         [ 0.4219, -0.0629, -0.3383,  ...,  0.5036,  0.0316, -0.6235],\n",
      "         [ 0.8446,  0.0112, -0.0683,  ...,  0.5099, -0.3756, -0.3977]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-0.8971, -0.4367, -0.8893,  0.7439,  0.7662, -0.2192,  0.8322,  0.3274,\n",
      "         -0.8485, -1.0000, -0.5804,  0.9755,  0.9810,  0.4674,  0.9184, -0.7365,\n",
      "         -0.3483, -0.6026,  0.1920, -0.4244,  0.6814,  1.0000, -0.1255,  0.3346,\n",
      "          0.4673,  0.9953, -0.7777,  0.9180,  0.9474,  0.6943, -0.5975,  0.2539,\n",
      "         -0.9911, -0.1037, -0.8065, -0.9910,  0.5120, -0.7051,  0.0970,  0.0819,\n",
      "         -0.8913,  0.3614,  1.0000, -0.2117,  0.4989, -0.2747, -1.0000,  0.2662,\n",
      "         -0.8811,  0.9360,  0.8637,  0.9312,  0.1469,  0.4974,  0.5417, -0.2588,\n",
      "         -0.1650,  0.0374, -0.2217, -0.6442, -0.6817,  0.4325, -0.8478, -0.8630,\n",
      "          0.9524,  0.7854, -0.1393, -0.2606, -0.0508, -0.1250,  0.8972,  0.2113,\n",
      "         -0.3216, -0.8650,  0.6737,  0.1980, -0.6080,  1.0000, -0.5247, -0.9811,\n",
      "          0.8449,  0.7474,  0.5121, -0.3068,  0.3337, -1.0000,  0.6194, -0.0466,\n",
      "         -0.9906,  0.2109,  0.6462, -0.3079,  0.5001,  0.5405, -0.3866, -0.5132,\n",
      "         -0.2844, -0.8121, -0.1694, -0.5020,  0.0467, -0.1345, -0.3536, -0.3261,\n",
      "          0.2983, -0.6187, -0.5582,  0.4871,  0.2096,  0.6982,  0.3700, -0.3274,\n",
      "          0.4672, -0.9529,  0.6315, -0.2915, -0.9867, -0.5656, -0.9901,  0.6959,\n",
      "         -0.2471, -0.2105,  0.9495, -0.0887,  0.4249, -0.0274, -0.9509, -1.0000,\n",
      "         -0.7269, -0.3911, -0.3708, -0.3643, -0.9769, -0.9623,  0.6042,  0.9513,\n",
      "          0.2233,  0.9998, -0.2836,  0.9331, -0.3577, -0.7174,  0.7601, -0.4514,\n",
      "          0.7078,  0.0763, -0.4058,  0.1898, -0.4223,  0.4480, -0.7168, -0.2072,\n",
      "         -0.7133, -0.9189, -0.2825,  0.9417, -0.6015, -0.9311, -0.0523, -0.1794,\n",
      "         -0.3567,  0.7682,  0.7657,  0.3437, -0.4712,  0.4380, -0.0896,  0.5410,\n",
      "         -0.8242, -0.2937,  0.4583, -0.4061, -0.8002, -0.9832, -0.2927,  0.4986,\n",
      "          0.9896,  0.7207,  0.1684,  0.8759, -0.2043,  0.8095, -0.9431,  0.9852,\n",
      "         -0.1675,  0.2881, -0.3978,  0.3998, -0.8500, -0.0371,  0.7645, -0.8055,\n",
      "         -0.8565, -0.1294, -0.4604, -0.4132, -0.8309,  0.5064, -0.2762, -0.3949,\n",
      "         -0.1532,  0.9165,  0.9649,  0.7501,  0.2557,  0.6986, -0.9016, -0.5175,\n",
      "          0.1247,  0.1605,  0.1995,  0.9947, -0.5315, -0.1669, -0.9275, -0.9856,\n",
      "         -0.0884, -0.9091, -0.2363, -0.6625,  0.6502, -0.3764,  0.5797,  0.4432,\n",
      "         -0.9796, -0.7741,  0.4051, -0.4613,  0.3989, -0.3288,  0.9233,  0.9308,\n",
      "         -0.5859,  0.5551,  0.9037, -0.8892, -0.7474,  0.7373, -0.2299,  0.8631,\n",
      "         -0.6253,  0.9824,  0.9071,  0.8916, -0.9128, -0.6692, -0.8465, -0.6776,\n",
      "         -0.1242, -0.0609,  0.9070,  0.6026,  0.5259,  0.5991, -0.5593,  0.9962,\n",
      "         -0.9570, -0.9537, -0.5092, -0.2638, -0.9907,  0.8472,  0.2503,  0.4031,\n",
      "         -0.4623, -0.6533, -0.9678,  0.7885,  0.0853,  0.9781, -0.3766, -0.8887,\n",
      "         -0.7073, -0.9303, -0.1553, -0.1738, -0.5343, -0.0847, -0.9530,  0.5095,\n",
      "          0.5421,  0.6169, -0.8082,  0.9981,  1.0000,  0.9777,  0.8687,  0.8630,\n",
      "         -0.9998, -0.6508,  1.0000, -0.9962, -1.0000, -0.9103, -0.6817,  0.2558,\n",
      "         -1.0000, -0.2044,  0.1273, -0.9113,  0.6663,  0.9757,  0.9887, -1.0000,\n",
      "          0.7851,  0.9355, -0.5653,  0.9815, -0.4100,  0.9704,  0.5354,  0.5856,\n",
      "         -0.1654,  0.4037, -0.9341, -0.8065, -0.5890, -0.7902,  0.9983,  0.1304,\n",
      "         -0.7581, -0.8857,  0.6494, -0.2798, -0.2571, -0.9608, -0.2450,  0.6567,\n",
      "          0.7935,  0.1916,  0.2988, -0.6258,  0.2726, -0.2474,  0.1678,  0.6151,\n",
      "         -0.9191, -0.5582, -0.1596, -0.1015, -0.5543, -0.9564,  0.9591, -0.3928,\n",
      "          0.8940,  1.0000,  0.2713, -0.8622,  0.6250,  0.2730, -0.1943,  1.0000,\n",
      "          0.8580, -0.9840, -0.4891,  0.6471, -0.6537, -0.7112,  0.9989, -0.3347,\n",
      "         -0.7042, -0.4372,  0.9830, -0.9900,  0.9955, -0.8938, -0.9709,  0.9614,\n",
      "          0.9471, -0.6506, -0.5912,  0.0524, -0.4930,  0.2333, -0.9301,  0.7545,\n",
      "          0.4101, -0.0850,  0.9005, -0.7302, -0.5600,  0.3010, -0.6742, -0.1675,\n",
      "          0.9264,  0.4949, -0.1459,  0.1132, -0.2119, -0.7966, -0.9761,  0.6290,\n",
      "          1.0000, -0.3206,  0.8068, -0.5268,  0.0305, -0.0763,  0.5913,  0.5500,\n",
      "         -0.3109, -0.8054,  0.8249, -0.9548, -0.9898,  0.6264,  0.1408, -0.2420,\n",
      "          1.0000,  0.3652,  0.2032,  0.4813,  0.9927, -0.1351,  0.3858,  0.8821,\n",
      "          0.9795, -0.2119,  0.5323,  0.8494, -0.9029, -0.2930, -0.6666,  0.0162,\n",
      "         -0.9307,  0.1515, -0.9560,  0.9596,  0.9534,  0.3613,  0.1606,  0.6590,\n",
      "          1.0000, -0.7813,  0.5643,  0.0368,  0.6966, -0.9998, -0.8120, -0.4588,\n",
      "         -0.0428, -0.8490, -0.3794,  0.2531, -0.9670,  0.7947,  0.7038, -0.9775,\n",
      "         -0.9865, -0.4022,  0.7920, -0.0025, -0.9860, -0.7703, -0.6199,  0.7266,\n",
      "         -0.2469, -0.9391, -0.2045, -0.2844,  0.4936, -0.1959,  0.5144,  0.7945,\n",
      "          0.7984, -0.6258, -0.3346, -0.0594, -0.7215,  0.8640, -0.7818, -0.9502,\n",
      "         -0.1146,  1.0000, -0.5628,  0.8710,  0.6523,  0.7065, -0.1398,  0.2064,\n",
      "          0.9039,  0.2650, -0.6703, -0.8749, -0.1754, -0.3687,  0.6465,  0.5256,\n",
      "          0.5505,  0.8049,  0.8200,  0.2925,  0.0120,  0.0266,  0.9993, -0.1609,\n",
      "         -0.2701, -0.4681,  0.0232, -0.3679,  0.1290,  1.0000,  0.2943,  0.3590,\n",
      "         -0.9916, -0.8880, -0.8571,  1.0000,  0.8372, -0.7797,  0.7659,  0.7354,\n",
      "         -0.1140,  0.7016, -0.1306, -0.1851,  0.2935,  0.0425,  0.9495, -0.6146,\n",
      "         -0.9727, -0.5166,  0.5461, -0.9685,  0.9999, -0.5947, -0.2721, -0.4259,\n",
      "         -0.2721, -0.2579, -0.1367, -0.9854, -0.2116,  0.1870,  0.9618,  0.2361,\n",
      "         -0.5004, -0.8353,  0.8388,  0.7628, -0.9380, -0.9296,  0.9638, -0.9756,\n",
      "          0.7292,  1.0000,  0.3448,  0.2384,  0.2918, -0.4288,  0.3760, -0.4613,\n",
      "          0.6810, -0.9596, -0.4285, -0.2187,  0.2583, -0.1096, -0.4463,  0.5834,\n",
      "          0.2627, -0.4844, -0.6738, -0.1754,  0.4168,  0.8307, -0.1224, -0.1148,\n",
      "          0.1564, -0.1330, -0.8939, -0.4735, -0.5366, -1.0000,  0.6073, -1.0000,\n",
      "          0.4524,  0.0926, -0.1893,  0.7785,  0.7631,  0.6481, -0.7030, -0.8628,\n",
      "          0.4683,  0.7692, -0.3477, -0.6166, -0.6263,  0.4454, -0.0440,  0.2764,\n",
      "         -0.5917,  0.6931, -0.3720,  1.0000,  0.1515, -0.6139, -0.9751,  0.2063,\n",
      "         -0.2982,  1.0000, -0.8707, -0.9585,  0.3143, -0.7521, -0.7909,  0.3333,\n",
      "          0.0121, -0.8034, -0.9586,  0.9290,  0.7947, -0.5642,  0.6377, -0.2763,\n",
      "         -0.5824, -0.0842,  0.8798,  0.9883,  0.3697,  0.8860, -0.1950, -0.2634,\n",
      "          0.9703,  0.2110,  0.0936,  0.0012,  1.0000,  0.3333, -0.8979, -0.0379,\n",
      "         -0.9775, -0.1573, -0.9400,  0.3582,  0.1787,  0.9038, -0.2485,  0.9614,\n",
      "         -0.8069,  0.0334, -0.6983, -0.4733,  0.3806, -0.9184, -0.9834, -0.9811,\n",
      "          0.6841, -0.4197,  0.0372,  0.2245,  0.0429,  0.3857,  0.4765, -1.0000,\n",
      "          0.9152,  0.4779,  0.8712,  0.9678,  0.7518,  0.5881,  0.2390, -0.9826,\n",
      "         -0.9758, -0.3565, -0.2423,  0.6887,  0.6973,  0.8585,  0.4520, -0.5010,\n",
      "         -0.5904, -0.5705, -0.9097, -0.9928,  0.4106, -0.6446, -0.9435,  0.9493,\n",
      "         -0.4618, -0.0578, -0.0452, -0.8207,  0.9077,  0.6932,  0.1733,  0.0400,\n",
      "          0.3933,  0.8814,  0.9115,  0.9793, -0.8359,  0.6729, -0.8398,  0.4279,\n",
      "          0.8653, -0.9211,  0.1582,  0.4454, -0.2170,  0.3566, -0.2082, -0.9556,\n",
      "          0.4962, -0.2792,  0.5606, -0.3429,  0.0622, -0.3667, -0.1974, -0.6947,\n",
      "         -0.7082,  0.6154,  0.4465,  0.8871,  0.8596, -0.0666, -0.7325, -0.1427,\n",
      "         -0.7474, -0.9158,  0.8968, -0.0445, -0.1112,  0.6802, -0.0253,  0.8565,\n",
      "          0.0534, -0.4230, -0.4077, -0.7597,  0.8745, -0.6575, -0.5695, -0.5025,\n",
      "          0.7570,  0.3467,  1.0000, -0.7571, -0.9423, -0.6390, -0.4338,  0.3728,\n",
      "         -0.5016, -1.0000,  0.3761, -0.6529,  0.6942, -0.7748,  0.8982, -0.7884,\n",
      "         -0.9689, -0.2302,  0.6647,  0.7402, -0.4974, -0.7449,  0.4961, -0.5145,\n",
      "          0.9893,  0.8340, -0.2273,  0.1095,  0.6348, -0.7498, -0.6909,  0.9010]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.2947, -0.0052,  0.1255,  ..., -0.1608,  0.1746, -0.0389],\n",
      "         [-0.6526, -1.0057, -0.0175,  ..., -0.3800,  1.0211, -0.4375],\n",
      "         [ 0.5253, -0.3733,  0.2634,  ..., -0.2097, -0.0966, -0.5096],\n",
      "         ...,\n",
      "         [ 0.4643, -0.0028,  0.2810,  ..., -0.4068,  0.5225, -0.5280],\n",
      "         [ 0.1468, -0.5417, -0.0206,  ...,  0.6515,  0.4722, -0.5317],\n",
      "         [ 0.7691,  0.1002, -0.0979,  ...,  0.0292, -0.6732, -0.2299]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-7.4841e-01, -2.2510e-01,  3.2347e-01,  2.1023e-01, -2.9930e-02,\n",
      "         -3.4075e-02,  6.6223e-01,  1.4555e-01,  1.5122e-02, -9.9878e-01,\n",
      "          3.5961e-02,  2.2337e-01,  9.5627e-01, -2.8378e-01,  8.6860e-01,\n",
      "         -2.3950e-01,  9.0992e-02, -4.7086e-01,  2.7658e-01, -2.2223e-01,\n",
      "          4.6999e-01,  9.3020e-01,  5.8646e-01,  1.5700e-01,  3.2350e-01,\n",
      "          3.8507e-01, -5.1566e-01,  8.7715e-01,  8.8917e-01,  5.7493e-01,\n",
      "         -4.0160e-01,  9.7106e-02, -9.6566e-01, -1.3324e-01,  2.3663e-01,\n",
      "         -9.5324e-01,  1.1340e-01, -6.2071e-01,  1.5082e-01,  7.3489e-02,\n",
      "         -8.2083e-01,  1.1259e-01,  9.9007e-01, -4.7323e-01, -1.6472e-01,\n",
      "         -3.1342e-01, -9.9831e-01,  1.7247e-01, -7.1041e-01, -2.1334e-01,\n",
      "         -2.2313e-01, -3.5156e-01,  9.9215e-02,  2.7346e-01,  2.1994e-01,\n",
      "          2.3324e-01, -1.6960e-01,  4.5933e-02, -6.7325e-02, -4.4090e-01,\n",
      "         -5.3810e-01,  9.6704e-02, -1.2986e-01, -8.2794e-01,  4.6540e-02,\n",
      "         -2.0348e-01,  1.9959e-02, -1.6190e-01,  2.2963e-02,  4.7271e-04,\n",
      "          7.2174e-01,  1.3364e-01,  2.2219e-01, -7.5790e-01, -2.4497e-01,\n",
      "          1.8987e-01, -3.3924e-01,  9.9998e-01,  2.5817e-01, -9.3580e-01,\n",
      "          8.7997e-02, -7.4683e-02,  2.5501e-01,  5.2769e-01, -3.4113e-01,\n",
      "         -9.9982e-01,  1.8636e-01, -2.2524e-02, -9.7417e-01,  1.5122e-01,\n",
      "          2.8264e-01, -1.7878e-01, -2.9007e-01,  3.0676e-01, -1.3367e-01,\n",
      "         -1.2021e-01, -9.5164e-02,  4.6842e-02, -6.8199e-02,  9.5888e-02,\n",
      "         -8.3229e-02, -1.3026e-01, -1.7809e-02, -2.2060e-01,  7.8886e-02,\n",
      "         -2.5331e-01, -7.4979e-02,  9.6230e-02, -2.3370e-01,  4.9051e-01,\n",
      "          2.7909e-01, -2.0503e-01,  1.5113e-01, -9.0779e-01,  4.4888e-01,\n",
      "         -1.0685e-01, -9.6046e-01, -3.7196e-01, -9.7723e-01,  4.3316e-01,\n",
      "          1.0697e-01, -8.7520e-02,  8.9622e-01,  5.3214e-01,  2.0524e-01,\n",
      "          1.3773e-01,  2.6110e-01, -9.9999e-01, -1.5833e-02,  8.6710e-02,\n",
      "          1.4262e-01, -1.1032e-01, -9.2498e-01, -9.0360e-01,  4.3806e-01,\n",
      "          9.0094e-01,  8.0732e-02,  9.8768e-01, -6.0919e-02,  8.6819e-01,\n",
      "          1.2129e-01, -9.6118e-02, -1.7529e-01, -3.2426e-01,  2.3160e-01,\n",
      "         -1.4763e-02, -2.3091e-01,  1.7984e-01,  3.1845e-01, -2.2388e-01,\n",
      "          1.9600e-02, -5.3206e-02,  1.2721e-01, -8.8934e-01, -3.3167e-01,\n",
      "          8.7727e-01,  6.8363e-02,  1.3911e-01,  5.0833e-01, -4.3711e-02,\n",
      "         -1.2627e-01,  6.3164e-01,  1.9796e-01,  2.2280e-01,  9.8458e-02,\n",
      "          2.3044e-01, -2.7918e-01,  3.0724e-01, -6.0827e-01,  3.3429e-01,\n",
      "          2.6811e-01, -1.7026e-01,  3.1908e-01, -9.5034e-01, -2.1538e-01,\n",
      "          3.5650e-01,  9.6250e-01,  6.1359e-01,  1.2138e-01,  8.9103e-02,\n",
      "         -3.5625e-02,  2.9866e-01, -8.8072e-01,  9.3769e-01, -1.3015e-01,\n",
      "          2.5010e-01,  2.5705e-01,  7.1933e-02, -6.8296e-01, -3.4992e-01,\n",
      "          5.7721e-01, -1.4153e-01, -6.7529e-01,  1.6430e-01, -3.2981e-01,\n",
      "         -2.3906e-01,  3.1954e-02,  2.1719e-01, -2.0431e-01, -2.7938e-01,\n",
      "          8.6725e-02,  8.7231e-01,  8.1467e-01,  5.9262e-01, -4.5796e-01,\n",
      "          3.4431e-01, -8.0888e-01, -3.0150e-01, -4.1567e-03,  7.2806e-02,\n",
      "          1.2531e-01,  9.7789e-01,  1.7799e-02, -5.9029e-02, -8.5611e-01,\n",
      "         -9.6348e-01, -1.1921e-01, -7.7289e-01, -8.9103e-03, -4.8621e-01,\n",
      "          1.1693e-01,  3.0279e-01, -2.0846e-02,  1.5637e-01, -9.0697e-01,\n",
      "         -5.7969e-01,  1.8156e-01, -1.4344e-01,  2.7793e-01, -1.5427e-01,\n",
      "          5.8604e-01, -3.2813e-02, -2.9355e-01,  3.6808e-01,  7.9352e-01,\n",
      "          6.3336e-02, -6.4379e-01,  5.3366e-01, -1.4514e-01,  6.7320e-01,\n",
      "         -4.4363e-01,  9.0806e-01, -3.8094e-02,  3.9402e-01, -8.3045e-01,\n",
      "          1.6355e-01, -7.2205e-01,  1.9897e-01, -6.8266e-02, -5.7049e-01,\n",
      "          3.3058e-02,  3.1870e-01,  2.3870e-01,  7.7205e-01, -1.6782e-01,\n",
      "          9.5424e-01, -7.3907e-01, -8.7447e-01, -2.5704e-01,  3.5038e-02,\n",
      "         -9.5486e-01, -1.8876e-02,  2.0463e-01, -4.9817e-01, -2.5958e-01,\n",
      "         -2.5671e-01, -8.8666e-01,  5.7442e-01,  1.4574e-02,  9.0258e-01,\n",
      "          1.1221e-01, -6.3327e-01, -1.3021e-01, -8.2648e-01, -2.3920e-01,\n",
      "         -6.2333e-02,  3.3864e-01, -1.6489e-01, -9.0990e-01,  3.4049e-01,\n",
      "          2.8308e-01,  3.1693e-01,  3.3119e-01,  9.7533e-01,  9.9754e-01,\n",
      "          9.3468e-01,  7.8471e-01,  7.9235e-01, -8.2144e-01, -4.8280e-01,\n",
      "          9.9948e-01, -4.4755e-01, -9.9970e-01, -8.5482e-01, -2.8868e-01,\n",
      "          1.3999e-01, -9.9999e-01, -1.0584e-01,  6.4407e-02, -8.5138e-01,\n",
      "         -2.5529e-01,  9.4049e-01,  9.2041e-01, -9.9997e-01,  6.9194e-01,\n",
      "          8.6990e-01, -3.3625e-01,  3.5661e-01,  4.5278e-02,  9.3199e-01,\n",
      "          3.6481e-01,  2.5168e-01, -1.4972e-01,  2.3651e-01, -7.9166e-02,\n",
      "         -6.1389e-01,  2.7583e-01,  1.6034e-01,  6.0264e-01,  4.9604e-02,\n",
      "         -3.8690e-01, -8.2845e-01, -1.1053e-01, -7.2945e-02, -3.5696e-01,\n",
      "         -9.2625e-01,  6.5955e-03, -2.3757e-01,  4.0783e-01, -6.6668e-03,\n",
      "          1.5715e-01, -4.7830e-01,  7.1129e-02, -5.5878e-01,  1.5278e-01,\n",
      "          4.4867e-01, -8.7889e-01, -2.9583e-01,  3.4151e-02, -4.8182e-01,\n",
      "          1.6303e-01, -9.1703e-01,  9.1725e-01, -2.9644e-01, -3.2671e-01,\n",
      "          9.9998e-01, -2.6590e-01, -6.4372e-01,  2.2606e-01,  5.3202e-02,\n",
      "         -1.6607e-01,  9.9992e-01,  3.9711e-01, -9.4127e-01, -3.1068e-01,\n",
      "          7.9149e-02, -3.2806e-01, -1.9917e-01,  9.8766e-01, -1.6056e-01,\n",
      "          1.0381e-01,  3.0857e-01,  9.3323e-01, -9.6119e-01,  4.5698e-01,\n",
      "         -7.9192e-01, -9.2580e-01,  9.2181e-01,  8.8241e-01, -1.1137e-01,\n",
      "         -3.3302e-01,  6.2964e-02,  8.7624e-02,  1.8164e-01, -8.7919e-01,\n",
      "          3.3324e-01,  1.8856e-01,  2.1161e-02,  8.0261e-01, -4.9513e-01,\n",
      "         -3.0453e-01,  2.2026e-01,  8.3212e-03,  3.2055e-01, -1.0450e-01,\n",
      "          2.9878e-01, -5.0734e-02, -2.8988e-03, -1.4929e-01, -2.3674e-01,\n",
      "         -9.5463e-01,  2.2273e-02,  9.9994e-01,  9.6773e-03, -3.0581e-01,\n",
      "         -9.1243e-02, -3.1737e-02, -3.0753e-01,  2.3010e-01,  3.6947e-01,\n",
      "         -1.4300e-01, -7.1795e-01,  4.6652e-02, -8.0691e-01, -9.5953e-01,\n",
      "          5.3770e-01,  1.3666e-01, -1.0238e-01,  9.8622e-01,  1.4043e-01,\n",
      "         -6.2013e-03, -4.4455e-03,  3.5580e-01, -1.0238e-01,  4.1289e-01,\n",
      "         -5.2989e-02,  9.2720e-01, -8.2797e-02,  2.6004e-01,  6.0481e-01,\n",
      "          9.5057e-02, -1.6060e-01, -4.2360e-01,  1.0888e-03, -8.5801e-01,\n",
      "          1.8342e-01, -8.8404e-01,  9.2191e-01, -3.6744e-01,  1.8831e-01,\n",
      "          1.0967e-01, -1.3962e-01,  9.9997e-01, -3.1976e-01,  3.9492e-01,\n",
      "          7.8329e-02,  4.9404e-01, -8.8526e-01, -5.6863e-01, -2.5240e-01,\n",
      "          1.1881e-01,  2.1896e-01, -1.6466e-01,  1.3976e-01, -9.2610e-01,\n",
      "         -1.9529e-01, -1.9346e-01, -9.0606e-01, -9.6921e-01,  4.2094e-01,\n",
      "          3.8606e-01,  5.0948e-02, -3.5896e-01, -4.1525e-01, -3.9879e-01,\n",
      "          6.6109e-02, -6.2698e-02, -8.9441e-01,  4.8042e-01, -1.2346e-01,\n",
      "          3.1349e-01, -1.7857e-01,  3.1657e-01, -2.4051e-01,  8.1399e-01,\n",
      "          4.1697e-01,  1.4709e-01,  2.3330e-02, -5.5817e-01,  4.9412e-01,\n",
      "         -5.2498e-01,  1.0758e-01, -6.0799e-02,  9.9998e-01, -3.4981e-01,\n",
      "          2.4307e-02,  4.5575e-01,  3.9525e-01, -1.2622e-02,  4.9077e-02,\n",
      "         -8.4344e-02,  6.9638e-02,  1.6440e-01,  2.4715e-01, -2.9458e-01,\n",
      "         -1.5517e-01,  1.7569e-01, -2.5563e-01, -2.6822e-01,  6.2576e-01,\n",
      "          3.5536e-01,  2.6383e-02,  1.1253e-01, -8.8079e-02,  9.8168e-01,\n",
      "          5.2336e-02, -3.1027e-02, -2.9190e-01,  1.3604e-01, -2.5287e-01,\n",
      "          6.0964e-02,  9.9989e-01,  1.8688e-01, -1.3866e-01, -9.6644e-01,\n",
      "          1.2456e-01, -7.2335e-01,  9.9482e-01,  7.0884e-01, -6.1478e-01,\n",
      "          2.0685e-01,  2.1059e-01, -7.4956e-02,  4.0509e-01, -4.0500e-02,\n",
      "         -1.8471e-01,  1.5504e-01,  1.0867e-01,  9.0494e-01, -3.7532e-01,\n",
      "         -9.1338e-01, -2.6099e-01,  2.1689e-01, -9.1572e-01,  8.8558e-01,\n",
      "         -3.5315e-01, -7.3060e-02, -1.9453e-01,  4.2417e-01, -3.8579e-02,\n",
      "         -1.4909e-01, -9.5635e-01, -5.9137e-02,  1.1795e-03,  9.1521e-01,\n",
      "          3.1673e-02, -2.9685e-01, -7.8556e-01, -4.1330e-01, -1.3283e-01,\n",
      "          1.4565e-01, -8.7138e-01,  9.2500e-01, -9.6084e-01,  3.8554e-01,\n",
      "          9.9951e-01,  2.0090e-01, -7.4923e-01,  2.1777e-02, -1.4174e-01,\n",
      "          1.9804e-01,  1.7806e-01,  2.7258e-01, -9.1417e-01, -2.7314e-01,\n",
      "         -3.0235e-03,  1.0258e-01, -1.1150e-03,  3.9345e-01,  4.6038e-01,\n",
      "          9.6880e-02, -2.0785e-01, -3.9104e-01,  1.0192e-01,  3.0707e-01,\n",
      "          5.6535e-01, -1.9902e-01, -7.6130e-02, -9.7610e-02,  9.4701e-03,\n",
      "         -8.0181e-01, -1.4124e-01, -6.9919e-02, -9.7115e-01,  4.8901e-01,\n",
      "         -9.9997e-01, -3.6158e-01, -5.3195e-01, -1.4544e-01,  6.7410e-01,\n",
      "          5.0991e-01,  7.0674e-02, -5.3094e-01,  1.3617e-02,  7.9145e-01,\n",
      "          4.8649e-01,  1.3776e-04,  3.2348e-01, -3.7082e-01,  2.4187e-02,\n",
      "          2.0801e-02,  2.6723e-01,  2.2906e-01,  6.0538e-01, -1.3005e-01,\n",
      "          9.9999e-01,  5.3905e-02, -9.4685e-02, -8.6824e-01,  1.3201e-01,\n",
      "         -5.2122e-02,  9.9878e-01, -6.2415e-01, -8.8837e-01,  1.9429e-01,\n",
      "         -2.3898e-01, -7.1566e-01,  1.5842e-01, -1.2700e-01, -4.6754e-01,\n",
      "         -1.3984e-01,  8.5966e-01,  6.4348e-01, -3.8395e-01,  2.6281e-01,\n",
      "         -2.0896e-01, -2.3075e-01, -1.2993e-01, -3.3849e-01,  9.6854e-01,\n",
      "          1.7608e-01,  6.3344e-01,  1.2475e-01, -3.7186e-02,  9.1970e-01,\n",
      "          1.2985e-02,  5.4321e-02,  2.8054e-02,  9.9977e-01,  1.1335e-01,\n",
      "         -8.3643e-01,  3.8843e-01, -9.3748e-01, -7.6305e-02, -8.9178e-01,\n",
      "          1.5125e-01,  5.5685e-02,  8.2049e-01, -2.4195e-01,  8.3823e-01,\n",
      "          2.9724e-01,  1.5191e-02,  1.0150e-01,  5.2377e-01,  2.3647e-01,\n",
      "         -8.2607e-01, -9.5942e-01, -9.6025e-01,  2.5532e-01, -2.4741e-01,\n",
      "          2.7846e-02,  1.5154e-01, -6.3663e-02,  1.9011e-01,  3.3207e-01,\n",
      "         -9.9978e-01,  8.4319e-01,  1.6004e-01, -8.2317e-02,  9.1368e-01,\n",
      "          3.7051e-01,  1.7052e-01,  1.3645e-01, -9.5226e-01, -8.8451e-01,\n",
      "         -1.9105e-01, -1.6720e-01,  4.3244e-01,  3.9839e-01,  7.8341e-01,\n",
      "          1.7316e-01, -4.1507e-01, -2.4466e-01,  1.4404e-01, -7.4690e-01,\n",
      "         -9.7881e-01,  2.7145e-01,  2.3396e-01, -7.9672e-01,  8.9761e-01,\n",
      "         -3.8255e-01, -7.0537e-02,  4.7890e-01, -2.1887e-02,  7.7304e-01,\n",
      "          6.2846e-01,  2.3826e-02,  9.7960e-02,  2.6884e-01,  7.5187e-01,\n",
      "          8.1355e-01,  9.5188e-01,  2.1293e-01,  4.7667e-01,  2.5378e-01,\n",
      "          2.0958e-01,  6.0655e-01, -8.6122e-01, -2.9812e-04, -1.1799e-01,\n",
      "          2.0438e-01,  5.6529e-02, -4.2399e-02, -8.6885e-01,  1.0789e-01,\n",
      "         -1.8772e-02,  2.6155e-01, -2.8382e-01,  1.4241e-01, -2.9558e-01,\n",
      "         -5.7207e-02, -4.4568e-01, -3.1024e-01,  4.2087e-01, -8.0679e-02,\n",
      "          8.1821e-01,  2.7331e-01,  9.0965e-03, -2.3323e-01,  1.0035e-02,\n",
      "          2.3530e-01, -8.5394e-01,  7.2714e-01,  1.3466e-01,  4.1440e-01,\n",
      "         -3.0863e-01, -1.3765e-01,  7.1279e-01, -4.1447e-01, -2.1217e-01,\n",
      "         -2.1012e-01, -4.2069e-01,  7.0901e-01, -1.0305e-01, -3.6454e-01,\n",
      "         -2.3410e-01,  5.6727e-01,  1.8714e-01,  9.4094e-01,  7.4098e-02,\n",
      "          9.4522e-03, -5.9471e-02, -2.1402e-01,  2.2560e-01,  2.4919e-02,\n",
      "         -9.9980e-01,  2.2925e-01,  1.4149e-01, -1.5125e-01, -8.0000e-03,\n",
      "         -2.2967e-01,  1.7203e-01, -9.1942e-01, -5.8128e-02,  4.3867e-02,\n",
      "         -5.2861e-02, -4.5936e-01, -1.2342e-02,  2.8381e-01,  5.3266e-01,\n",
      "          3.5661e-01,  6.9817e-01,  3.7456e-01,  5.0230e-01,  3.8763e-01,\n",
      "          2.4054e-01, -5.1423e-01,  7.9194e-01]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-1.9353e-01,  9.8686e-02, -1.3002e-01,  ..., -4.0502e-01,\n",
      "           4.2212e-01,  6.6780e-01],\n",
      "         [-2.3634e-01,  5.3399e-01, -2.8296e-01,  ...,  4.5405e-02,\n",
      "           3.5692e-01,  7.9987e-01],\n",
      "         [ 4.8024e-03,  3.0947e-04,  5.7587e-01,  ..., -1.3051e+00,\n",
      "           6.3736e-01,  7.8360e-01],\n",
      "         ...,\n",
      "         [-5.0777e-01,  1.2746e-01,  2.1500e-02,  ..., -4.1625e-01,\n",
      "           9.8930e-01,  4.6055e-01],\n",
      "         [ 2.9458e-01,  1.0312e-01, -4.0204e-01,  ...,  1.5016e-01,\n",
      "          -1.7526e-01, -4.2700e-01],\n",
      "         [ 5.6952e-01,  1.0726e-01, -4.3817e-02,  ...,  3.2854e-02,\n",
      "          -3.8632e-01, -1.9714e-01]]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-8.5921e-01, -2.5925e-01, -7.5782e-01,  5.6643e-01,  6.4278e-01,\n",
      "         -6.5291e-02,  7.7062e-01,  2.0449e-01, -6.9327e-01, -9.9994e-01,\n",
      "         -2.9994e-01,  8.7437e-01,  9.6538e-01,  3.7867e-01,  8.4992e-01,\n",
      "         -6.0804e-01, -1.3717e-01, -4.8014e-01,  1.9273e-01, -4.2258e-01,\n",
      "          4.7777e-01,  9.9960e-01,  1.4490e-01,  2.3226e-01,  3.8334e-01,\n",
      "          9.6394e-01, -6.8773e-01,  8.4774e-01,  9.3289e-01,  6.4819e-01,\n",
      "         -5.0749e-01,  1.0866e-01, -9.7654e-01,  5.8361e-03, -6.5533e-01,\n",
      "         -9.7962e-01,  3.2461e-01, -7.0379e-01,  1.8297e-01,  1.3460e-01,\n",
      "         -8.3209e-01,  2.3176e-01,  9.9981e-01, -1.8126e-01,  2.8927e-02,\n",
      "         -2.1967e-01, -1.0000e+00,  2.2274e-01, -8.2582e-01,  8.2735e-01,\n",
      "          7.2149e-01,  6.8037e-01,  6.9519e-03,  4.0995e-01,  3.9066e-01,\n",
      "         -5.4349e-02, -1.7128e-01, -6.3378e-02, -1.3070e-01, -5.0366e-01,\n",
      "         -6.0351e-01,  2.6684e-01, -7.4661e-01, -8.5034e-01,  7.9238e-01,\n",
      "          6.4203e-01,  1.1398e-01, -1.7565e-01, -1.6931e-02, -9.2952e-02,\n",
      "          8.0714e-01,  5.2088e-02, -7.9188e-02, -7.0457e-01,  5.1481e-01,\n",
      "          1.2220e-01, -5.9947e-01,  1.0000e+00, -2.9959e-01, -9.5999e-01,\n",
      "          5.8710e-01,  5.9864e-01,  5.0527e-01, -1.5093e-01,  3.4691e-01,\n",
      "         -1.0000e+00,  5.3619e-01,  4.8907e-02, -9.8085e-01,  2.0690e-01,\n",
      "          5.1022e-01, -2.1204e-01,  1.3585e-01,  5.4410e-01, -3.8667e-01,\n",
      "         -2.5951e-01, -1.7160e-01, -6.9680e-01, -9.1977e-02, -1.1024e-01,\n",
      "         -4.5560e-02, -1.2274e-01, -1.6636e-01, -3.0346e-01,  2.4857e-01,\n",
      "         -4.5401e-01, -4.1216e-01,  3.4926e-01, -7.2949e-02,  5.8474e-01,\n",
      "          3.8811e-01, -2.4596e-01,  3.8099e-01, -9.2967e-01,  5.7462e-01,\n",
      "         -2.4141e-01, -9.7576e-01, -5.5519e-01, -9.7977e-01,  6.1872e-01,\n",
      "         -3.3492e-02, -7.8536e-02,  9.3002e-01,  8.8040e-02,  3.0439e-01,\n",
      "          7.7820e-02, -8.2843e-01, -1.0000e+00, -5.8165e-01, -1.6284e-01,\n",
      "         -1.6836e-01, -2.0613e-01, -9.5997e-01, -9.2836e-01,  4.5892e-01,\n",
      "          9.2524e-01,  6.1226e-02,  9.9949e-01, -1.2190e-01,  8.9592e-01,\n",
      "         -2.6731e-01, -4.7754e-01,  5.4047e-01, -3.0608e-01,  4.9893e-01,\n",
      "          9.7709e-02, -4.2752e-01,  1.9922e-01, -2.3549e-01,  2.5366e-01,\n",
      "         -4.1428e-01, -1.8278e-01, -5.7707e-01, -8.8474e-01, -2.6692e-01,\n",
      "          8.9214e-01, -3.8961e-01, -8.0878e-01,  9.2714e-02, -1.2507e-01,\n",
      "         -2.0448e-01,  7.5859e-01,  4.8798e-01,  2.2430e-01, -2.4289e-01,\n",
      "          2.8211e-01,  1.5727e-01,  4.5905e-01, -7.5055e-01,  9.3151e-04,\n",
      "          3.6458e-01, -2.2492e-01, -5.8256e-01, -9.5809e-01, -2.9718e-01,\n",
      "          4.2613e-01,  9.7592e-01,  7.1229e-01,  1.9733e-01,  7.4673e-01,\n",
      "         -1.8685e-01,  5.8114e-01, -9.2285e-01,  9.6654e-01, -9.3792e-02,\n",
      "          2.2401e-01, -1.8440e-01,  4.0109e-01, -8.0426e-01, -3.1719e-02,\n",
      "          6.8467e-01, -6.5777e-01, -8.2569e-01,  2.2144e-02, -3.3477e-01,\n",
      "         -2.8616e-01, -6.5516e-01,  4.0927e-01, -2.2707e-01, -2.8262e-01,\n",
      "          8.6798e-02,  8.8136e-01,  9.3019e-01,  6.8491e-01, -3.8102e-02,\n",
      "          4.7854e-01, -8.5744e-01, -2.2619e-01,  9.8254e-02,  1.0955e-01,\n",
      "          1.2273e-01,  9.8733e-01, -2.6836e-01,  1.4449e-02, -9.0353e-01,\n",
      "         -9.6792e-01, -1.3117e-01, -8.2907e-01, -1.0113e-01, -5.3202e-01,\n",
      "          5.1489e-01, -7.1601e-02,  4.1412e-01,  3.1489e-01, -9.4949e-01,\n",
      "         -6.0095e-01,  2.8458e-01, -2.8918e-01,  2.8866e-01, -1.4728e-01,\n",
      "          7.8461e-01,  8.1815e-01, -5.4004e-01,  4.7054e-01,  8.4033e-01,\n",
      "         -6.8034e-01, -6.5986e-01,  5.8291e-01, -2.2306e-01,  8.1581e-01,\n",
      "         -5.2066e-01,  9.7280e-01,  7.5851e-01,  5.3527e-01, -8.7797e-01,\n",
      "         -4.4640e-01, -8.7316e-01, -4.4777e-01,  5.9102e-03, -4.8643e-02,\n",
      "          8.0478e-01,  5.4727e-01,  3.1997e-01,  5.1418e-01, -4.5037e-01,\n",
      "          9.9100e-01, -9.0079e-01, -9.2240e-01, -3.6970e-01, -1.4012e-01,\n",
      "         -9.7854e-01,  7.0820e-01,  1.6243e-01, -3.5737e-03, -4.1877e-01,\n",
      "         -4.1471e-01, -9.3084e-01,  7.7559e-01,  4.4331e-02,  9.5657e-01,\n",
      "         -2.2059e-01, -8.2855e-01, -6.4509e-01, -8.4839e-01, -2.6962e-01,\n",
      "          3.6872e-03, -3.2226e-01, -1.8037e-01, -9.2017e-01,  4.4864e-01,\n",
      "          3.9685e-01,  4.1256e-01, -5.8449e-01,  9.9140e-01,  1.0000e+00,\n",
      "          9.4841e-01,  8.0412e-01,  8.3627e-01, -9.9724e-01, -7.6394e-01,\n",
      "          9.9998e-01, -9.7237e-01, -1.0000e+00, -8.8654e-01, -6.5566e-01,\n",
      "          8.8896e-02, -1.0000e+00, -1.1212e-01,  1.4008e-01, -8.8231e-01,\n",
      "          4.1349e-01,  9.5424e-01,  9.6868e-01, -1.0000e+00,  8.3332e-01,\n",
      "          8.9433e-01, -5.6855e-01,  8.8968e-01, -3.0558e-01,  9.5220e-01,\n",
      "          4.5284e-01,  4.3288e-01, -1.0205e-01,  2.0851e-01, -7.8445e-01,\n",
      "         -7.2006e-01, -2.2417e-01, -5.4168e-01,  9.8535e-01,  7.4685e-02,\n",
      "         -6.3496e-01, -8.3900e-01,  3.3176e-01, -5.1244e-02, -3.0103e-01,\n",
      "         -9.2722e-01, -8.2413e-02,  3.8419e-01,  7.2849e-01,  1.4735e-02,\n",
      "          2.2071e-01, -6.4979e-01,  1.4700e-01, -3.4328e-01,  6.1212e-02,\n",
      "          5.9952e-01, -8.8443e-01, -4.2507e-01, -1.8396e-01, -3.3229e-01,\n",
      "         -3.3106e-01, -9.2420e-01,  9.3695e-01, -3.2165e-01,  7.6327e-01,\n",
      "          1.0000e+00,  6.3931e-02, -7.4833e-01,  5.1255e-01,  2.3654e-01,\n",
      "         -1.0816e-01,  1.0000e+00,  7.6502e-01, -9.6284e-01, -5.2703e-01,\n",
      "          5.8353e-01, -4.8501e-01, -5.0567e-01,  9.9816e-01, -2.0354e-01,\n",
      "         -5.3488e-01, -1.4015e-01,  9.4571e-01, -9.7808e-01,  9.6979e-01,\n",
      "         -8.5616e-01, -9.4015e-01,  9.3763e-01,  8.6838e-01, -4.8572e-01,\n",
      "         -6.0734e-01, -3.1796e-02, -4.8303e-01,  1.6150e-01, -9.3338e-01,\n",
      "          6.2592e-01,  2.3134e-01, -5.0678e-02,  8.4010e-01, -7.1290e-01,\n",
      "         -5.6992e-01,  3.4517e-01, -4.3656e-01,  1.9224e-02,  7.8628e-01,\n",
      "          3.8363e-01, -7.6302e-02,  7.6520e-02, -1.9645e-01, -4.5550e-01,\n",
      "         -9.5003e-01,  2.8116e-01,  1.0000e+00, -1.4342e-01,  4.6365e-01,\n",
      "         -3.3337e-01,  7.4249e-02, -1.9977e-01,  4.1908e-01,  4.3666e-01,\n",
      "         -2.1139e-01, -7.9187e-01,  6.6366e-01, -9.2318e-01, -9.7612e-01,\n",
      "          5.0136e-01,  1.4749e-01, -9.8535e-02,  9.9986e-01,  3.0238e-01,\n",
      "          2.3888e-01,  3.2702e-01,  9.4533e-01, -2.0832e-01,  4.5246e-01,\n",
      "          7.1408e-01,  9.6214e-01, -1.6561e-01,  5.3408e-01,  7.8809e-01,\n",
      "         -8.1196e-01, -7.5829e-02, -6.0926e-01, -1.5916e-02, -8.2443e-01,\n",
      "          2.5965e-01, -9.3798e-01,  9.3329e-01,  8.5580e-01,  2.5002e-01,\n",
      "          8.7805e-02,  3.7430e-01,  1.0000e+00, -4.5304e-01,  3.9724e-01,\n",
      "         -8.1804e-02,  5.5544e-01, -9.9786e-01, -6.2976e-01, -3.1712e-01,\n",
      "          3.9092e-03, -6.6669e-01, -2.7989e-01,  1.1557e-01, -9.5605e-01,\n",
      "          6.1686e-01,  4.1247e-01, -9.6067e-01, -9.7551e-01, -1.2493e-01,\n",
      "          6.6756e-01,  1.6504e-02, -9.1534e-01, -5.7505e-01, -4.9550e-01,\n",
      "          5.3618e-01, -1.5727e-01, -9.1070e-01, -7.6767e-02, -1.2884e-01,\n",
      "          4.4471e-01, -1.2036e-01,  5.1808e-01,  6.8498e-01,  7.2633e-01,\n",
      "         -3.8533e-01, -1.4358e-01,  5.6506e-02, -6.7368e-01,  7.3562e-01,\n",
      "         -6.9078e-01, -8.1380e-01, -1.2727e-01,  1.0000e+00, -3.9325e-01,\n",
      "          7.0155e-01,  5.5566e-01,  6.0544e-01,  4.5737e-02,  1.0369e-01,\n",
      "          7.8589e-01,  1.7212e-01, -6.0353e-01, -7.1284e-01, -3.2985e-01,\n",
      "         -2.4842e-01,  5.2060e-01,  2.2470e-01,  4.6038e-01,  6.9623e-01,\n",
      "          7.0246e-01,  1.7126e-01,  1.4751e-02, -9.0931e-02,  9.9770e-01,\n",
      "         -6.4081e-02, -1.1432e-01, -3.7569e-01,  1.2248e-01, -2.0388e-01,\n",
      "          1.4617e-01,  1.0000e+00,  2.7847e-01,  7.1748e-02, -9.7816e-01,\n",
      "         -7.3219e-01, -8.4102e-01,  9.9999e-01,  7.1388e-01, -7.9873e-01,\n",
      "          5.7028e-01,  5.7072e-01, -1.6618e-01,  7.1641e-01, -1.3554e-01,\n",
      "         -1.4765e-01,  9.8197e-02,  7.6929e-02,  9.2737e-01, -4.7269e-01,\n",
      "         -9.4119e-01, -4.2243e-01,  4.3909e-01, -9.2603e-01,  9.9859e-01,\n",
      "         -4.9823e-01, -1.4264e-01, -3.5300e-01, -2.0717e-01,  4.8985e-02,\n",
      "         -1.1939e-01, -9.7019e-01, -1.4770e-01,  7.8552e-02,  9.4157e-01,\n",
      "          1.4952e-01, -5.1386e-01, -7.9166e-01,  6.6622e-01,  5.1878e-01,\n",
      "         -7.5615e-01, -8.9660e-01,  9.2697e-01, -9.5881e-01,  6.6564e-01,\n",
      "          1.0000e+00,  2.8600e-01, -9.3142e-02,  1.6359e-01, -3.6273e-01,\n",
      "          2.8749e-01, -5.9854e-02,  4.2286e-01, -9.1579e-01, -2.3468e-01,\n",
      "         -8.5190e-02,  1.9860e-01, -3.9608e-02, -3.6254e-01,  4.6579e-01,\n",
      "          4.6542e-02, -5.1481e-01, -5.6959e-01,  1.9226e-02,  3.2609e-01,\n",
      "          7.2619e-01, -6.7052e-02, -2.5062e-02,  1.2287e-02, -3.8885e-04,\n",
      "         -8.0157e-01, -2.6001e-01, -2.9637e-01, -9.9984e-01,  5.8271e-01,\n",
      "         -1.0000e+00,  3.2063e-01,  9.8648e-02, -8.4333e-02,  7.2519e-01,\n",
      "          7.0430e-01,  4.1006e-01, -5.7301e-01, -7.1985e-01,  4.4662e-01,\n",
      "          6.5054e-01, -1.3134e-01, -3.7650e-01, -5.2312e-01,  1.8544e-01,\n",
      "         -2.0246e-02,  1.9207e-01, -4.1273e-01,  5.9175e-01, -1.6125e-01,\n",
      "          1.0000e+00,  1.0503e-02, -4.6933e-01, -9.4056e-01,  1.1986e-01,\n",
      "         -1.2947e-01,  1.0000e+00, -8.4015e-01, -8.9730e-01,  2.6046e-01,\n",
      "         -5.7979e-01, -6.5252e-01,  2.4578e-01, -4.1028e-02, -6.9572e-01,\n",
      "         -8.2925e-01,  8.3651e-01,  7.5005e-01, -5.9017e-01,  3.2118e-01,\n",
      "         -1.4854e-01, -4.7006e-01, -1.0067e-01,  7.1913e-01,  9.7345e-01,\n",
      "          2.5844e-01,  8.5044e-01, -1.3774e-01,  9.3578e-02,  9.1526e-01,\n",
      "          1.4967e-01,  1.7368e-01,  1.0796e-02,  1.0000e+00,  1.3714e-01,\n",
      "         -8.2069e-01,  2.0529e-01, -9.6381e-01, -3.6007e-02, -8.9886e-01,\n",
      "          2.4673e-01,  7.7339e-02,  8.3624e-01, -1.0841e-01,  8.9565e-01,\n",
      "         -5.8892e-01, -3.8796e-02, -4.8999e-01, -2.5773e-01,  2.1929e-01,\n",
      "         -8.5890e-01, -9.7158e-01, -9.6321e-01,  5.0116e-01, -3.6142e-01,\n",
      "          1.2478e-01,  2.2799e-01, -3.9018e-03,  3.2525e-01,  4.1733e-01,\n",
      "         -1.0000e+00,  8.9968e-01,  3.5561e-01,  7.6736e-01,  9.3720e-01,\n",
      "          6.5613e-01,  4.4967e-01,  2.1416e-01, -9.6826e-01, -9.4316e-01,\n",
      "         -2.7465e-01, -1.8075e-01,  5.0230e-01,  5.9077e-01,  7.6240e-01,\n",
      "          4.1267e-01, -4.9505e-01, -3.0172e-01, -1.0433e-01, -8.8655e-01,\n",
      "         -9.8488e-01,  2.7369e-01, -4.1948e-01, -9.1395e-01,  9.2342e-01,\n",
      "         -3.3240e-01, -9.1479e-03,  5.3070e-02, -5.7511e-01,  8.4776e-01,\n",
      "          7.0891e-01,  2.2340e-01,  4.2344e-02,  2.8277e-01,  8.1807e-01,\n",
      "          8.7859e-01,  9.6403e-01, -6.2185e-01,  6.4131e-01, -6.0960e-01,\n",
      "          3.4515e-01,  5.6057e-01, -9.0879e-01,  5.8865e-02,  2.4800e-01,\n",
      "         -1.5578e-01,  1.7758e-01, -1.7322e-01, -9.1562e-01,  2.8785e-01,\n",
      "         -1.5761e-01,  4.7891e-01, -2.6740e-01,  1.5824e-01, -2.5391e-01,\n",
      "         -1.1537e-01, -6.0598e-01, -6.1510e-01,  6.2253e-01,  2.7455e-01,\n",
      "          8.4272e-01,  7.6052e-01, -7.9055e-02, -6.0246e-01, -1.2718e-01,\n",
      "         -6.2843e-01, -8.6759e-01,  8.4108e-01,  5.3360e-02, -2.4079e-01,\n",
      "          3.2978e-01, -1.3814e-01,  7.9665e-01, -4.8283e-02, -3.4941e-01,\n",
      "         -2.3505e-01, -6.8152e-01,  8.1057e-01, -5.4192e-01, -4.3564e-01,\n",
      "         -4.0937e-01,  6.1814e-01,  2.2805e-01,  9.9948e-01, -4.9931e-01,\n",
      "         -8.3794e-01, -3.4590e-01, -3.2545e-01,  2.7738e-01, -2.7629e-01,\n",
      "         -1.0000e+00,  3.2856e-01, -5.1209e-01,  3.2523e-01, -6.2725e-01,\n",
      "          6.4230e-01, -5.6719e-01, -9.2794e-01, -3.9475e-02,  2.7597e-01,\n",
      "          5.3245e-01, -4.7643e-01, -6.2833e-01,  5.5821e-01, -3.4907e-01,\n",
      "          9.1790e-01,  7.8659e-01, -1.4413e-01,  3.4057e-01,  6.2165e-01,\n",
      "         -4.4764e-01, -5.4653e-01,  8.6669e-01]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1226, -0.1068, -0.1363,  ..., -0.2859,  0.4383,  0.1663],\n",
      "         [ 0.7388, -0.1213, -0.0055,  ...,  0.4463,  0.7769, -0.0162],\n",
      "         [ 0.7172, -0.1319,  0.3129,  ...,  0.1847,  0.2795, -0.6030],\n",
      "         ...,\n",
      "         [ 1.0239,  0.0977,  0.7029,  ...,  0.0152, -0.3469,  0.0370],\n",
      "         [ 0.5919, -0.1366, -0.4308,  ...,  0.3561, -0.0866, -0.7676],\n",
      "         [ 0.7840, -0.0285,  0.0390,  ...,  0.4585, -0.1690, -0.4019]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-9.2795e-01, -5.4544e-01, -9.3117e-01,  8.2638e-01,  8.6155e-01,\n",
      "         -1.7987e-01,  9.0632e-01,  3.5078e-01, -8.9014e-01, -9.9999e-01,\n",
      "         -7.2643e-01,  9.7296e-01,  9.8202e-01,  5.7838e-01,  9.5372e-01,\n",
      "         -7.3736e-01, -1.6576e-01, -6.6466e-01,  1.8479e-01, -5.1063e-01,\n",
      "          6.7339e-01,  1.0000e+00, -1.2172e-01,  3.8707e-01,  4.7369e-01,\n",
      "          9.9785e-01, -8.3633e-01,  9.4984e-01,  9.6035e-01,  6.6253e-01,\n",
      "         -6.5905e-01,  2.8857e-01, -9.8743e-01, -2.6459e-01, -8.9565e-01,\n",
      "         -9.9254e-01,  5.1722e-01, -7.5744e-01, -8.2507e-02, -1.5955e-02,\n",
      "         -9.1874e-01,  2.9975e-01,  9.9999e-01, -5.5964e-03,  4.2786e-01,\n",
      "         -2.7096e-01, -1.0000e+00,  3.1441e-01, -8.7613e-01,  9.6991e-01,\n",
      "          9.2438e-01,  9.6516e-01,  1.0795e-01,  5.4965e-01,  4.6192e-01,\n",
      "         -2.5407e-01, -7.8405e-02,  1.4392e-01, -3.4841e-01, -6.1442e-01,\n",
      "         -6.6517e-01,  3.0998e-01, -9.1416e-01, -9.1033e-01,  9.6654e-01,\n",
      "          8.0756e-01, -1.9605e-01, -3.8910e-01, -2.8163e-01,  2.7888e-03,\n",
      "          9.3350e-01,  2.9460e-01, -2.4377e-01, -8.8921e-01,  7.8397e-01,\n",
      "          3.2751e-01, -6.4005e-01,  1.0000e+00, -5.7371e-01, -9.7951e-01,\n",
      "          8.8000e-01,  8.5072e-01,  6.3820e-01, -5.2043e-01,  5.7441e-01,\n",
      "         -1.0000e+00,  7.1552e-01,  3.7510e-02, -9.9149e-01,  2.7291e-01,\n",
      "          7.5754e-01, -4.4032e-01,  3.1373e-01,  6.5599e-01, -5.2632e-01,\n",
      "         -6.0681e-01, -3.9300e-01, -9.2886e-01, -2.5374e-01, -4.3887e-01,\n",
      "          1.0762e-01, -2.7209e-01, -5.9093e-01, -3.9553e-01,  3.4948e-01,\n",
      "         -5.8118e-01, -5.3709e-01,  6.3559e-01,  2.0636e-01,  7.5379e-01,\n",
      "          5.3596e-01, -4.4649e-01,  4.9554e-01, -9.6724e-01,  7.2512e-01,\n",
      "         -3.2464e-01, -9.9013e-01, -6.9082e-01, -9.8912e-01,  6.0037e-01,\n",
      "         -5.2605e-01, -2.9259e-01,  9.5957e-01, -1.5131e-01,  5.8279e-01,\n",
      "         -1.0512e-01, -9.6730e-01, -1.0000e+00, -8.0147e-01, -5.9397e-01,\n",
      "         -4.7562e-01, -4.1706e-01, -9.7804e-01, -9.7552e-01,  6.9623e-01,\n",
      "          9.6432e-01,  3.2809e-01,  9.9997e-01, -3.9350e-01,  9.4808e-01,\n",
      "         -4.7966e-01, -6.3597e-01,  7.3639e-01, -5.1362e-01,  8.4484e-01,\n",
      "          3.9192e-01, -5.6447e-01,  2.3902e-01, -5.6715e-01,  6.8099e-01,\n",
      "         -8.3406e-01, -2.9592e-01, -8.2167e-01, -9.5327e-01, -3.5700e-01,\n",
      "          9.4828e-01, -6.8893e-01, -9.5993e-01, -1.1853e-01, -3.4327e-01,\n",
      "         -5.2614e-01,  8.1123e-01,  8.1888e-01,  3.9461e-01, -5.0517e-01,\n",
      "          4.4163e-01,  3.5394e-01,  6.7463e-01, -8.1860e-01, -4.0150e-01,\n",
      "          5.0375e-01, -4.0811e-01, -8.8492e-01, -9.8315e-01, -4.5510e-01,\n",
      "          5.8976e-01,  9.8571e-01,  7.9075e-01,  3.1297e-01,  8.6861e-01,\n",
      "         -3.2755e-01,  8.4452e-01, -9.6270e-01,  9.8405e-01, -2.2037e-01,\n",
      "          3.8362e-01, -4.5899e-01,  6.6913e-01, -8.6046e-01, -5.9291e-02,\n",
      "          8.0279e-01, -8.7871e-01, -8.1384e-01, -1.3461e-01, -4.0812e-01,\n",
      "         -4.1423e-01, -9.0789e-01,  4.4685e-01, -2.9682e-01, -5.0866e-01,\n",
      "         -6.6328e-02,  9.3105e-01,  9.8525e-01,  7.7139e-01,  3.5892e-01,\n",
      "          7.3300e-01, -9.1652e-01, -5.1599e-01,  1.3895e-01,  2.5791e-01,\n",
      "          2.3499e-01,  9.9480e-01, -7.7173e-01, -2.0575e-01, -9.4272e-01,\n",
      "         -9.8551e-01, -8.7182e-02, -9.2729e-01, -1.7603e-01, -6.6364e-01,\n",
      "          7.7575e-01, -6.2317e-01,  7.8287e-01,  5.6601e-01, -9.9037e-01,\n",
      "         -7.8598e-01,  4.3508e-01, -5.5166e-01,  4.9871e-01, -3.2141e-01,\n",
      "          7.9055e-01,  9.5540e-01, -5.4528e-01,  5.9539e-01,  9.0334e-01,\n",
      "         -9.3333e-01, -8.1665e-01,  7.9581e-01, -4.0531e-01,  8.5754e-01,\n",
      "         -7.1655e-01,  9.8968e-01,  9.5752e-01,  8.7675e-01, -9.4329e-01,\n",
      "         -6.9127e-01, -7.9625e-01, -7.5143e-01, -1.6966e-01,  2.5261e-01,\n",
      "          9.4872e-01,  7.0213e-01,  5.7406e-01,  2.9656e-01, -6.8189e-01,\n",
      "          9.9805e-01, -8.4300e-01, -9.5301e-01, -6.7497e-01, -4.0135e-01,\n",
      "         -9.8930e-01,  8.9919e-01,  4.3517e-01,  4.8100e-01, -4.9659e-01,\n",
      "         -7.4974e-01, -9.6638e-01,  8.5611e-01,  9.7796e-02,  9.8851e-01,\n",
      "         -3.7938e-01, -9.2313e-01, -7.7030e-01, -9.3604e-01, -6.9697e-02,\n",
      "         -2.6198e-01, -6.6656e-01, -9.5780e-02, -9.5935e-01,  5.3470e-01,\n",
      "          5.5717e-01,  6.6238e-01, -9.0777e-01,  9.9930e-01,  1.0000e+00,\n",
      "          9.7091e-01,  8.8997e-01,  9.4236e-01, -9.9997e-01, -7.1943e-01,\n",
      "          1.0000e+00, -9.9764e-01, -1.0000e+00, -9.2832e-01, -7.1323e-01,\n",
      "          4.1148e-01, -1.0000e+00, -2.1312e-01, -7.1511e-02, -9.1844e-01,\n",
      "          7.6819e-01,  9.7781e-01,  9.9704e-01, -1.0000e+00,  8.2542e-01,\n",
      "          9.4326e-01, -6.9907e-01,  9.8487e-01, -5.1239e-01,  9.7538e-01,\n",
      "          6.0516e-01,  5.9183e-01, -2.5428e-01,  5.4400e-01, -9.4668e-01,\n",
      "         -8.8180e-01, -7.1106e-01, -8.1597e-01,  9.9925e-01,  1.8207e-01,\n",
      "         -8.2274e-01, -8.7035e-01,  7.4704e-01, -1.0113e-01, -4.8565e-02,\n",
      "         -9.7094e-01, -2.9064e-01,  7.8224e-01,  8.8169e-01,  1.7611e-01,\n",
      "          3.6750e-01, -5.8539e-01,  3.4940e-01,  1.0821e-01,  2.9171e-01,\n",
      "          7.4839e-01, -9.6438e-01, -5.4046e-01, -6.6862e-01,  1.9337e-01,\n",
      "         -6.4523e-01, -9.6407e-01,  9.5756e-01, -5.7063e-01,  9.5374e-01,\n",
      "          1.0000e+00,  3.9026e-01, -8.6659e-01,  8.1676e-01,  4.3726e-01,\n",
      "         -3.9992e-01,  1.0000e+00,  8.3305e-01, -9.7693e-01, -6.1947e-01,\n",
      "          7.6504e-01, -6.0897e-01, -7.3329e-01,  9.9970e-01, -2.7107e-01,\n",
      "         -8.1608e-01, -7.1108e-01,  9.7396e-01, -9.8783e-01,  9.9862e-01,\n",
      "         -9.2696e-01, -9.7778e-01,  9.7611e-01,  9.4692e-01, -6.9927e-01,\n",
      "         -7.3879e-01,  1.7747e-01, -6.9283e-01,  3.6484e-01, -9.6402e-01,\n",
      "          8.0631e-01,  5.7241e-01, -1.1819e-01,  8.8566e-01, -8.2722e-01,\n",
      "         -6.4676e-01,  3.6098e-01, -8.0051e-01, -4.2878e-01,  9.7651e-01,\n",
      "          6.0597e-01, -1.9900e-01, -1.3448e-02, -3.0453e-01, -7.2105e-01,\n",
      "         -9.8000e-01,  5.8680e-01,  1.0000e+00, -3.8067e-01,  8.6118e-01,\n",
      "         -4.8720e-01, -5.2434e-02, -1.0422e-01,  6.1521e-01,  6.5736e-01,\n",
      "         -3.9692e-01, -8.7868e-01,  8.6601e-01, -9.6648e-01, -9.8688e-01,\n",
      "          7.3026e-01,  2.2259e-01, -3.6553e-01,  1.0000e+00,  6.6338e-01,\n",
      "          2.7802e-01,  5.6216e-01,  9.9718e-01, -2.9529e-02,  6.1963e-01,\n",
      "          9.2875e-01,  9.7891e-01, -2.9724e-01,  6.1872e-01,  8.4892e-01,\n",
      "         -9.4776e-01, -2.7813e-01, -7.0817e-01,  1.3783e-01, -9.1659e-01,\n",
      "         -2.3876e-02, -9.4588e-01,  9.6397e-01,  9.8087e-01,  5.0812e-01,\n",
      "          2.5592e-01,  6.8270e-01,  1.0000e+00, -8.5754e-01,  5.1718e-01,\n",
      "         -6.3403e-02,  7.6347e-01, -9.9993e-01, -8.6581e-01, -3.6037e-01,\n",
      "         -6.5971e-02, -9.2127e-01, -4.8129e-01,  4.1412e-01, -9.6176e-01,\n",
      "          8.9137e-01,  7.7151e-01, -9.9036e-01, -9.9101e-01, -2.6943e-01,\n",
      "          8.8396e-01,  1.6971e-01, -9.9596e-01, -8.5727e-01, -5.6057e-01,\n",
      "          7.9711e-01, -2.5414e-01, -9.4260e-01, -4.5366e-01, -3.6382e-01,\n",
      "          6.5781e-01, -3.1399e-01,  6.1305e-01,  9.1109e-01,  7.5194e-01,\n",
      "         -8.3288e-01, -5.6880e-01, -8.5811e-02, -8.1573e-01,  8.8448e-01,\n",
      "         -8.0322e-01, -9.6981e-01, -2.1976e-01,  1.0000e+00, -4.4017e-01,\n",
      "          9.0633e-01,  7.2160e-01,  7.7438e-01, -1.8385e-01,  1.7249e-01,\n",
      "          9.4541e-01,  3.4179e-01, -7.0726e-01, -9.4069e-01, -2.6170e-01,\n",
      "         -4.8218e-01,  6.3998e-01,  6.6286e-01,  7.3146e-01,  8.2482e-01,\n",
      "          8.9511e-01,  1.4929e-01, -1.5199e-01, -1.5863e-04,  9.9974e-01,\n",
      "         -1.1590e-01, -6.3121e-02, -4.1485e-01, -9.6153e-02, -3.5128e-01,\n",
      "          1.2781e-02,  1.0000e+00,  4.3150e-01,  6.7648e-01, -9.8988e-01,\n",
      "         -9.4708e-01, -9.3123e-01,  1.0000e+00,  8.1837e-01, -7.9052e-01,\n",
      "          7.8389e-01,  6.9904e-01, -6.6075e-02,  8.0203e-01, -3.3261e-01,\n",
      "         -2.6573e-01,  1.5793e-01,  1.5869e-01,  9.4838e-01, -6.8786e-01,\n",
      "         -9.6989e-01, -6.2988e-01,  6.0628e-01, -9.7426e-01,  9.9999e-01,\n",
      "         -6.6644e-01, -3.2309e-01, -4.9429e-01, -4.3965e-01, -2.6219e-01,\n",
      "          3.6154e-02, -9.8410e-01, -2.9875e-01,  2.5908e-01,  9.5167e-01,\n",
      "          2.3494e-01, -6.4513e-01, -8.9257e-01,  9.3516e-01,  8.6240e-01,\n",
      "         -9.6042e-01, -9.3987e-01,  9.5916e-01, -9.8499e-01,  7.4943e-01,\n",
      "          1.0000e+00,  3.3566e-01,  4.5098e-01,  2.8353e-01, -4.2293e-01,\n",
      "          4.6369e-01, -4.8583e-01,  7.9519e-01, -9.7022e-01, -3.6120e-01,\n",
      "         -3.1335e-01,  2.7523e-01, -1.4361e-01, -3.7049e-01,  6.6536e-01,\n",
      "          3.1019e-01, -6.0462e-01, -7.3140e-01, -9.0077e-02,  4.5353e-01,\n",
      "          9.2387e-01, -2.7838e-01, -2.1682e-01,  2.2835e-01, -1.9851e-01,\n",
      "         -9.2918e-01, -3.9574e-01, -5.2552e-01, -1.0000e+00,  7.6513e-01,\n",
      "         -1.0000e+00,  7.5489e-01,  4.0974e-01, -3.6100e-01,  8.5131e-01,\n",
      "          7.0796e-01,  7.6938e-01, -7.6572e-01, -9.1482e-01,  3.2945e-01,\n",
      "          7.6467e-01, -3.9725e-01, -7.7779e-01, -7.0484e-01,  3.7520e-01,\n",
      "         -6.9224e-02,  2.5618e-01, -5.5598e-01,  7.1108e-01, -3.2015e-01,\n",
      "          1.0000e+00,  1.9150e-01, -6.7714e-01, -9.8398e-01,  1.8128e-01,\n",
      "         -2.3963e-01,  1.0000e+00, -9.0630e-01, -9.4815e-01,  3.8215e-01,\n",
      "         -8.2850e-01, -8.4803e-01,  3.3587e-01,  2.3265e-03, -8.2385e-01,\n",
      "         -9.8121e-01,  9.5007e-01,  7.7227e-01, -6.8356e-01,  5.8283e-01,\n",
      "         -3.4503e-01, -6.0634e-01,  1.9588e-02,  9.2449e-01,  9.8784e-01,\n",
      "          7.9352e-01,  9.0305e-01, -1.0579e-02, -3.6188e-01,  9.6972e-01,\n",
      "          1.5382e-01,  1.7950e-01,  2.5041e-02,  1.0000e+00,  3.9915e-01,\n",
      "         -9.1955e-01,  7.1121e-02, -9.8156e-01, -3.1201e-01, -9.4827e-01,\n",
      "          3.7169e-01,  3.1336e-01,  9.1219e-01, -3.9499e-01,  9.6648e-01,\n",
      "         -9.1578e-01,  4.7015e-02, -7.4193e-01, -6.0014e-01,  4.2548e-01,\n",
      "         -9.2434e-01, -9.7822e-01, -9.8472e-01,  7.1176e-01, -4.0835e-01,\n",
      "         -6.6677e-02,  2.1163e-01,  7.0535e-02,  5.2604e-01,  4.9569e-01,\n",
      "         -1.0000e+00,  9.3129e-01,  5.1551e-01,  9.2785e-01,  9.6900e-01,\n",
      "          8.1834e-01,  6.3301e-01,  3.4156e-01, -9.8159e-01, -9.9118e-01,\n",
      "         -3.5395e-01, -2.1581e-01,  7.4590e-01,  6.9262e-01,  8.9941e-01,\n",
      "          4.9385e-01, -5.1409e-01, -5.3987e-01, -6.7600e-01, -7.6238e-01,\n",
      "         -9.9242e-01,  5.1609e-01, -7.2090e-01, -9.6139e-01,  9.3683e-01,\n",
      "         -2.6948e-01, -7.0668e-02, -1.2939e-01, -9.0802e-01,  9.5541e-01,\n",
      "          8.4234e-01,  2.8401e-01,  1.1784e-01,  3.1773e-01,  8.9780e-01,\n",
      "          9.3337e-01,  9.7570e-01, -8.7016e-01,  7.4997e-01, -8.5501e-01,\n",
      "          6.5936e-01,  8.1814e-01, -9.4184e-01,  1.6916e-01,  6.1362e-01,\n",
      "         -3.8395e-01,  2.3965e-01, -2.3463e-01, -9.8271e-01,  6.6467e-01,\n",
      "         -2.5890e-01,  6.7843e-01, -4.9921e-01,  8.6073e-02, -4.2877e-01,\n",
      "         -2.0970e-01, -6.9876e-01, -8.2736e-01,  7.2429e-01,  3.3395e-01,\n",
      "          8.9223e-01,  9.0504e-01, -8.4266e-03, -8.0276e-01, -2.1804e-01,\n",
      "         -8.2653e-01, -9.0311e-01,  9.6031e-01, -5.7898e-02, -2.9917e-01,\n",
      "          6.9966e-01, -1.6489e-02,  8.9583e-01,  3.5278e-01, -4.1529e-01,\n",
      "         -3.5498e-01, -7.1783e-01,  8.9709e-01, -7.2049e-01, -7.2288e-01,\n",
      "         -5.9240e-01,  7.8598e-01,  3.6054e-01,  1.0000e+00, -8.3085e-01,\n",
      "         -9.6488e-01, -6.2600e-01, -5.1104e-01,  4.2594e-01, -6.3171e-01,\n",
      "         -1.0000e+00,  3.2024e-01, -7.9912e-01,  8.2005e-01, -8.3517e-01,\n",
      "          9.2605e-01, -8.2104e-01, -9.8720e-01, -3.6345e-01,  7.2503e-01,\n",
      "          8.5952e-01, -5.5451e-01, -8.1595e-01,  6.4778e-01, -7.8383e-01,\n",
      "          9.9552e-01,  8.7858e-01, -7.1328e-01,  9.5441e-02,  7.2654e-01,\n",
      "         -8.3969e-01, -7.6153e-01,  9.3141e-01]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0916,  0.1471, -0.2386,  ..., -0.1563,  0.4078,  0.3894],\n",
      "         [ 0.6770,  0.6492, -0.1441,  ..., -0.4110,  0.8061, -0.2847],\n",
      "         [-0.1408, -0.2735,  0.5158,  ...,  0.0379, -0.1181,  0.7982],\n",
      "         ...,\n",
      "         [ 1.2759,  0.1964, -0.4679,  ..., -0.0694,  0.3140, -0.5006],\n",
      "         [ 0.7555,  0.1469, -0.2542,  ...,  0.1856, -0.2548, -0.5401],\n",
      "         [ 0.6682,  0.1986,  0.2501,  ...,  0.4069, -0.3334, -0.4257]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-8.0686e-01, -2.2299e-01, -3.2241e-01,  4.8952e-01,  3.4382e-01,\n",
      "         -1.2032e-01,  6.9520e-01,  1.3184e-01, -2.4512e-01, -9.9958e-01,\n",
      "         -1.7036e-02,  6.7521e-01,  9.6855e-01,  7.0003e-03,  8.5061e-01,\n",
      "         -4.5805e-01,  7.0108e-02, -4.9323e-01,  2.1206e-01, -2.7282e-01,\n",
      "          5.6101e-01,  9.9606e-01,  3.1496e-01,  2.9546e-01,  2.9631e-01,\n",
      "          8.1065e-01, -4.4970e-01,  8.7278e-01,  9.1802e-01,  7.1075e-01,\n",
      "         -3.0878e-01,  1.1584e-01, -9.8358e-01,  1.7863e-02, -1.7117e-01,\n",
      "         -9.7456e-01,  1.9371e-01, -6.1200e-01,  1.5055e-01,  2.2654e-01,\n",
      "         -8.5151e-01,  1.3093e-01,  9.9875e-01, -3.2728e-01,  1.2335e-01,\n",
      "         -2.0917e-01, -9.9992e-01,  1.0926e-01, -8.3719e-01,  4.3413e-01,\n",
      "          3.7045e-01,  3.9176e-01,  1.1511e-02,  3.8876e-01,  3.6133e-01,\n",
      "          4.1947e-02, -1.9996e-01,  1.4000e-03, -1.2616e-01, -4.7686e-01,\n",
      "         -5.5612e-01,  3.1081e-01, -5.2840e-01, -8.0724e-01,  4.3071e-01,\n",
      "          6.6911e-02,  6.9958e-02, -6.5067e-02,  1.2200e-02, -8.4734e-02,\n",
      "          7.3333e-01, -6.8603e-02,  3.3302e-02, -7.0652e-01,  4.8485e-02,\n",
      "          4.6974e-02, -5.2027e-01,  1.0000e+00, -2.5564e-01, -9.7165e-01,\n",
      "          1.5045e-01,  2.0225e-01,  3.7543e-01,  3.0344e-01, -2.7894e-01,\n",
      "         -1.0000e+00,  3.9628e-01, -8.0603e-02, -9.8626e-01,  7.8809e-02,\n",
      "          3.6737e-01, -1.9031e-01, -9.7522e-02,  4.0959e-01,  4.1535e-03,\n",
      "         -1.0164e-01, -1.0686e-01, -3.5893e-01, -6.7862e-02, -1.1426e-01,\n",
      "         -7.2888e-02,  7.1067e-02, -2.2746e-02, -2.0436e-01,  1.6404e-01,\n",
      "         -3.9792e-01, -4.2817e-01,  4.1706e-01, -1.7952e-01,  5.8322e-01,\n",
      "          3.7154e-01, -1.9673e-01,  3.0219e-01, -9.1851e-01,  4.8852e-01,\n",
      "         -2.1935e-01, -9.7742e-01, -4.9725e-01, -9.8490e-01,  5.2565e-01,\n",
      "         -4.8948e-02, -1.2594e-01,  9.1481e-01,  2.1645e-01,  2.0316e-01,\n",
      "          9.4025e-02, -4.4286e-01, -1.0000e+00, -4.9167e-01, -1.8498e-01,\n",
      "          1.6568e-01, -2.1676e-02, -9.6866e-01, -9.4205e-01,  4.4755e-01,\n",
      "          9.3355e-01,  1.1013e-01,  9.9722e-01,  2.4395e-02,  8.8352e-01,\n",
      "          1.3391e-01, -1.7094e-01,  1.9053e-01, -2.4250e-01,  4.1109e-01,\n",
      "         -1.8491e-01, -2.9900e-01,  2.0781e-01, -1.8654e-01,  7.6722e-02,\n",
      "         -2.4985e-01, -6.3768e-02, -8.7946e-02, -8.8577e-01, -3.1934e-01,\n",
      "          9.0420e-01, -1.0081e-01, -3.2454e-01,  4.8516e-01, -8.4695e-02,\n",
      "         -2.3039e-01,  7.2527e-01,  3.4383e-01,  2.1810e-01, -1.6539e-01,\n",
      "          3.6157e-01, -3.8750e-01,  3.7481e-01, -7.2129e-01,  3.5275e-01,\n",
      "          2.6539e-01, -1.5066e-01, -1.4549e-01, -9.6202e-01, -2.2819e-01,\n",
      "          2.4493e-01,  9.7737e-01,  6.6570e-01,  8.5234e-02,  4.0584e-01,\n",
      "         -1.9319e-01,  3.0080e-01, -9.1189e-01,  9.6925e-01,  4.3126e-02,\n",
      "          1.6572e-01,  1.5299e-01,  1.7093e-01, -7.5770e-01, -3.9009e-01,\n",
      "          6.1387e-01, -4.9067e-01, -7.5286e-01,  8.9702e-05, -3.7074e-01,\n",
      "         -3.8147e-01, -2.5835e-01,  2.9609e-01, -2.0146e-01, -2.8713e-01,\n",
      "          3.5494e-02,  8.8752e-01,  8.4935e-01,  6.4068e-01, -3.6406e-01,\n",
      "          5.5068e-01, -8.1188e-01, -3.7362e-01, -2.8311e-03,  6.6569e-02,\n",
      "          2.1272e-03,  9.8815e-01, -1.3937e-04,  3.2747e-02, -8.7733e-01,\n",
      "         -9.7131e-01, -1.4306e-01, -8.4507e-01, -8.5499e-02, -4.7284e-01,\n",
      "          3.8813e-01,  1.9385e-01, -1.5420e-03,  2.5713e-01, -9.1007e-01,\n",
      "         -5.9906e-01,  3.1877e-01, -1.7440e-01,  3.5344e-01, -2.4483e-01,\n",
      "          8.6671e-01,  4.8638e-01, -5.1108e-01,  4.2756e-01,  8.9019e-01,\n",
      "         -3.8918e-01, -6.6770e-01,  5.2215e-01, -1.9979e-01,  7.6202e-01,\n",
      "         -4.1740e-01,  9.3271e-01,  4.9086e-01,  5.1573e-01, -8.5127e-01,\n",
      "         -2.3228e-03, -8.1527e-01,  2.3096e-02,  8.8388e-02, -5.3617e-01,\n",
      "          3.5246e-01,  4.7703e-01,  2.7456e-01,  7.6563e-01, -3.2994e-01,\n",
      "          9.7321e-01, -9.4379e-01, -9.3321e-01, -1.7857e-01,  2.1602e-02,\n",
      "         -9.8374e-01,  5.2285e-01,  1.0435e-01, -1.3533e-01, -3.0419e-01,\n",
      "         -3.1433e-01, -9.3927e-01,  6.9664e-01,  3.0802e-02,  9.3781e-01,\n",
      "         -1.9482e-01, -7.8810e-01, -4.1474e-01, -8.7151e-01, -2.7210e-01,\n",
      "         -8.0095e-02,  2.5176e-01, -1.8003e-01, -9.2417e-01,  4.5692e-01,\n",
      "          4.7498e-01,  4.4293e-01, -1.0102e-01,  9.8447e-01,  9.9989e-01,\n",
      "          9.5249e-01,  7.9192e-01,  5.9227e-01, -9.8413e-01, -6.4783e-01,\n",
      "          9.9985e-01, -8.7207e-01, -9.9999e-01, -8.9089e-01, -2.8301e-01,\n",
      "          1.2107e-01, -1.0000e+00, -9.3700e-02,  2.0726e-01, -8.5831e-01,\n",
      "          1.8100e-02,  9.6094e-01,  9.4789e-01, -1.0000e+00,  7.1105e-01,\n",
      "          9.1123e-01, -4.9669e-01,  7.2305e-01, -1.6953e-01,  9.5151e-01,\n",
      "          3.6130e-01,  4.3508e-01, -6.8855e-04,  1.8918e-01, -4.8506e-01,\n",
      "         -6.6997e-01,  1.5187e-01, -2.0105e-01,  9.4032e-01,  6.4458e-02,\n",
      "         -6.3068e-01, -8.0393e-01,  6.8438e-02, -1.9234e-01, -4.6021e-01,\n",
      "         -9.2282e-01, -1.2655e-01, -2.0578e-01,  4.6382e-01,  1.2704e-01,\n",
      "          7.4986e-02, -5.1848e-01, -9.8831e-03, -4.8526e-01, -5.9607e-02,\n",
      "          5.6890e-01, -8.5993e-01, -2.9521e-01, -7.4110e-02, -3.0890e-01,\n",
      "          1.1591e-01, -9.3399e-01,  9.3768e-01, -1.3088e-01,  4.0376e-01,\n",
      "          1.0000e+00, -1.5107e-02, -7.1628e-01,  2.3951e-01,  7.7013e-02,\n",
      "         -2.2379e-01,  1.0000e+00,  6.1579e-01, -9.6853e-01, -5.0026e-01,\n",
      "          4.3299e-01, -4.0356e-01, -4.1208e-01,  9.9454e-01, -1.2091e-01,\n",
      "         -1.4528e-01,  4.8511e-02,  9.6689e-01, -9.8467e-01,  8.3579e-01,\n",
      "         -8.2538e-01, -9.4252e-01,  9.4174e-01,  9.0431e-01, -4.2421e-01,\n",
      "         -4.7026e-01,  2.2799e-03,  3.8771e-02,  1.3732e-01, -9.1441e-01,\n",
      "          4.1251e-01,  1.7027e-01, -5.9711e-02,  8.5774e-01, -5.2398e-01,\n",
      "         -5.0221e-01,  2.2273e-01, -2.9517e-01,  1.6697e-01,  4.3923e-01,\n",
      "          3.4896e-01, -5.5544e-02, -4.9067e-02, -1.3725e-01, -5.9643e-01,\n",
      "         -9.5096e-01,  1.6752e-01,  1.0000e+00, -4.1518e-02,  2.5738e-01,\n",
      "         -1.0134e-01,  6.0283e-02, -2.7958e-01,  3.8037e-01,  3.1563e-01,\n",
      "         -1.5624e-01, -6.1970e-01,  3.1328e-01, -8.7941e-01, -9.7850e-01,\n",
      "          4.4226e-01,  9.3511e-02, -1.2836e-01,  9.9859e-01,  1.8232e-02,\n",
      "          2.1655e-01,  2.9967e-03,  7.7520e-01, -1.5646e-01,  6.8152e-02,\n",
      "          1.0684e-01,  9.7120e-01, -1.3070e-01,  4.9999e-01,  7.2495e-01,\n",
      "         -3.7095e-01, -9.3084e-02, -5.6358e-01, -5.4136e-02, -9.0591e-01,\n",
      "          3.0184e-01, -9.4763e-01,  9.3613e-01,  5.1029e-01,  2.2657e-01,\n",
      "         -3.1769e-02,  1.5065e-01,  1.0000e+00, -3.4465e-01,  3.4197e-01,\n",
      "          1.0993e-01,  3.9918e-01, -9.8762e-01, -5.4590e-01, -3.3166e-01,\n",
      "          1.9863e-02, -1.1016e-01, -2.1480e-01,  1.3375e-01, -9.5121e-01,\n",
      "          9.2999e-02,  2.0205e-01, -9.2490e-01, -9.7957e-01,  4.9113e-02,\n",
      "          4.2954e-01, -8.3791e-03, -8.1138e-01, -5.3300e-01, -5.0323e-01,\n",
      "          2.8359e-01, -2.4846e-02, -9.1071e-01,  4.0784e-01, -1.5888e-01,\n",
      "          3.6774e-01, -1.0612e-01,  4.8710e-01,  7.4736e-02,  8.6045e-01,\n",
      "          6.6246e-02,  4.8408e-02,  5.5609e-02, -6.2664e-01,  7.0346e-01,\n",
      "         -6.4990e-01, -4.6110e-01, -2.5820e-02,  1.0000e+00, -3.8861e-01,\n",
      "          4.7782e-01,  5.7174e-01,  4.5443e-01,  2.1037e-02,  1.0476e-01,\n",
      "          4.3951e-01,  1.7653e-01,  9.5418e-02, -2.8005e-01,  7.2910e-02,\n",
      "         -1.6408e-01,  5.2590e-01,  1.2256e-01, -1.9894e-01,  6.5706e-01,\n",
      "          5.0232e-01,  1.0202e-01,  9.4792e-02, -6.1020e-02,  9.9283e-01,\n",
      "         -4.1248e-02,  3.3551e-02, -3.0120e-01,  7.8970e-02, -2.6579e-01,\n",
      "          2.0337e-01,  1.0000e+00,  6.4166e-02, -1.4659e-01, -9.7980e-01,\n",
      "         -3.0348e-01, -7.4981e-01,  9.9968e-01,  7.4714e-01, -6.0165e-01,\n",
      "          4.4016e-01,  3.4232e-01, -1.2155e-01,  5.1343e-01, -3.2914e-02,\n",
      "         -1.1737e-01,  1.4597e-01, -1.7194e-02,  9.1768e-01, -4.1211e-01,\n",
      "         -9.4909e-01, -2.0610e-01,  3.1223e-01, -9.3100e-01,  9.8629e-01,\n",
      "         -4.2117e-01, -8.5191e-02, -2.9631e-01,  3.0435e-02, -1.5285e-01,\n",
      "         -6.7541e-02, -9.6929e-01, -9.0588e-02,  4.7212e-02,  9.4035e-01,\n",
      "          1.2173e-01, -4.8531e-01, -8.4477e-01,  1.9359e-01,  1.4838e-01,\n",
      "         -3.5532e-01, -8.4379e-01,  9.3836e-01, -9.4182e-01,  4.8614e-01,\n",
      "          9.9998e-01,  2.5972e-01, -2.2162e-01,  7.3730e-02, -3.1670e-01,\n",
      "          2.0919e-01, -1.8726e-01,  4.4862e-01, -9.2211e-01, -2.1932e-01,\n",
      "         -1.1458e-01,  5.0189e-02, -7.1695e-02,  1.2491e-02,  4.3015e-01,\n",
      "          8.0767e-02, -4.2851e-01, -4.5231e-01, -4.2673e-02,  2.4192e-01,\n",
      "          5.0222e-01, -1.0540e-01, -2.6487e-02,  8.6148e-02,  8.1803e-02,\n",
      "         -7.8484e-01, -2.4421e-01, -2.2101e-01, -9.9799e-01,  4.3678e-01,\n",
      "         -1.0000e+00, -4.9680e-02, -4.7322e-01, -1.4798e-01,  7.3383e-01,\n",
      "          6.4690e-01,  7.4190e-02, -5.5259e-01, -3.4895e-01,  6.6752e-01,\n",
      "          6.0822e-01, -5.7611e-02, -1.0756e-02, -5.5520e-01,  4.7648e-02,\n",
      "          4.0849e-02,  1.7056e-01, -1.3920e-01,  6.4882e-01, -2.0873e-01,\n",
      "          1.0000e+00,  3.2760e-02, -3.2290e-01, -9.0637e-01,  5.3779e-02,\n",
      "         -1.8950e-01,  9.9997e-01, -7.8044e-01, -9.4395e-01,  2.0184e-01,\n",
      "         -3.9368e-01, -6.1099e-01,  2.2460e-01, -5.9490e-02, -5.1331e-01,\n",
      "         -3.8211e-01,  8.6641e-01,  5.3158e-01, -4.6109e-01,  3.4083e-01,\n",
      "         -1.8141e-01, -3.6930e-01, -1.1726e-01,  3.8178e-01,  9.7938e-01,\n",
      "          8.6651e-02,  8.4419e-01,  1.8142e-01,  6.7194e-02,  9.4803e-01,\n",
      "          2.0685e-01, -8.9184e-02, -1.8085e-02,  1.0000e+00,  2.0441e-01,\n",
      "         -8.7508e-01,  2.6002e-01, -9.7399e-01,  1.5406e-01, -9.1468e-01,\n",
      "          1.7366e-01,  3.9733e-02,  8.4116e-01, -1.6723e-01,  8.7914e-01,\n",
      "         -8.6786e-02, -2.3597e-02, -7.0525e-02,  1.3028e-01,  2.9929e-01,\n",
      "         -8.7986e-01, -9.7172e-01, -9.7321e-01,  2.4731e-01, -3.4106e-01,\n",
      "          3.2160e-02,  2.8095e-01,  8.7979e-02,  3.3537e-01,  2.6111e-01,\n",
      "         -1.0000e+00,  9.0112e-01,  2.4606e-01,  2.2813e-01,  9.4592e-01,\n",
      "          3.9214e-01,  2.5666e-01,  1.4539e-01, -9.7772e-01, -9.0418e-01,\n",
      "         -1.9177e-01, -1.9933e-01,  5.1555e-01,  5.3044e-01,  7.8680e-01,\n",
      "          2.9901e-01, -3.3177e-01, -3.0554e-01,  1.3996e-01, -8.6962e-01,\n",
      "         -9.8758e-01,  2.2157e-01, -6.8776e-02, -8.6520e-01,  9.4174e-01,\n",
      "         -5.3337e-01, -1.6239e-02,  3.4652e-01, -3.7854e-01,  7.4652e-01,\n",
      "          4.9156e-01,  5.9954e-02, -2.4314e-02,  3.4650e-01,  8.0163e-01,\n",
      "          8.3739e-01,  9.6227e-01, -2.2726e-01,  4.5088e-01, -2.0726e-01,\n",
      "          2.6087e-01,  6.4391e-01, -8.9209e-01,  5.3065e-02, -5.8796e-02,\n",
      "          6.2017e-02,  1.5919e-01, -1.1727e-01, -8.7744e-01,  1.7795e-01,\n",
      "         -1.7138e-01,  3.7482e-01, -2.2412e-01,  2.3654e-01, -2.6802e-01,\n",
      "         -9.2976e-02, -4.2445e-01, -2.6789e-01,  5.4537e-01,  1.2605e-01,\n",
      "          8.8098e-01,  5.5562e-01, -2.3485e-03, -4.6912e-01,  2.6387e-03,\n",
      "         -5.7470e-02, -8.2332e-01,  7.8401e-01,  1.6842e-01,  3.6794e-01,\n",
      "          1.7365e-01, -1.1491e-01,  6.0495e-01, -2.1981e-01, -2.5810e-01,\n",
      "         -2.3895e-01, -6.1963e-01,  6.9854e-01, -5.1007e-01, -3.5797e-01,\n",
      "         -2.6709e-01,  4.8873e-01,  1.9705e-01,  9.9515e-01, -2.1266e-02,\n",
      "         -5.2976e-01, -4.3841e-01, -9.7563e-02,  3.1836e-01, -2.7569e-01,\n",
      "         -1.0000e+00,  3.4360e-01, -2.5629e-01, -6.0843e-02, -2.8846e-01,\n",
      "          3.8419e-01, -4.2911e-01, -9.1202e-01, -4.0926e-02,  3.1795e-01,\n",
      "          2.2781e-01, -3.9413e-01, -5.3014e-01,  4.4311e-01, -3.5236e-02,\n",
      "          7.0615e-01,  8.1643e-01,  2.5728e-01,  6.0562e-01,  5.6391e-01,\n",
      "         -3.5051e-01, -5.8491e-01,  8.8958e-01]], device='cuda:0',\n",
      "       grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.1718,  0.0371,  0.2040,  ..., -0.2708,  0.1625,  0.0199],\n",
      "         [-0.3548, -0.8362,  0.0472,  ..., -0.4600,  0.7287, -0.2013],\n",
      "         [ 0.6051, -0.4749,  0.1342,  ...,  0.2463, -0.3385, -0.7629],\n",
      "         ...,\n",
      "         [ 0.1780, -0.3283,  0.9140,  ..., -0.3041,  0.6276, -0.4430],\n",
      "         [-0.0145, -0.5396,  0.0137,  ...,  0.5967,  0.2730, -0.4674],\n",
      "         [ 0.7575, -0.0207,  0.0027,  ...,  0.1405, -0.7242, -0.2699]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-0.8465, -0.2556, -0.1754,  0.4987,  0.3600, -0.0556,  0.8446,  0.1693,\n",
      "         -0.3003, -0.9997, -0.1758,  0.6829,  0.9608, -0.0291,  0.9209, -0.4783,\n",
      "         -0.0844, -0.4871,  0.2622, -0.5015,  0.6006,  0.9965,  0.5023,  0.2007,\n",
      "          0.3955,  0.8667, -0.6396,  0.9183,  0.9302,  0.6310, -0.6042,  0.1136,\n",
      "         -0.9763, -0.1158, -0.1889, -0.9667,  0.2157, -0.6628,  0.1993,  0.0134,\n",
      "         -0.8736,  0.1718,  0.9982, -0.4305, -0.0319, -0.2963, -1.0000,  0.1972,\n",
      "         -0.7720,  0.3450,  0.2053,  0.2285,  0.1142,  0.4303,  0.3160,  0.0572,\n",
      "         -0.1228,  0.0251, -0.1041, -0.4966, -0.5629,  0.0783, -0.5332, -0.8555,\n",
      "          0.5888,  0.1057,  0.0390, -0.2562, -0.0458, -0.0401,  0.8561,  0.1557,\n",
      "          0.1440, -0.8075,  0.1145,  0.2385, -0.3523,  1.0000, -0.0583, -0.9574,\n",
      "          0.3905,  0.2567,  0.3146,  0.3309, -0.0860, -1.0000,  0.2762, -0.0090,\n",
      "         -0.9816,  0.1565,  0.4232, -0.2008, -0.1181,  0.3663, -0.1424, -0.2458,\n",
      "         -0.1340, -0.4537, -0.0915, -0.0605, -0.0454, -0.1471, -0.1266, -0.2507,\n",
      "          0.1305, -0.3449, -0.3336,  0.3166, -0.2266,  0.5931,  0.2793, -0.2249,\n",
      "          0.2597, -0.9320,  0.5405, -0.1934, -0.9770, -0.4303, -0.9848,  0.5055,\n",
      "         -0.0195, -0.1017,  0.9371,  0.3844,  0.2511,  0.1209, -0.2244, -1.0000,\n",
      "         -0.3068, -0.1043, -0.0783, -0.1881, -0.9522, -0.9343,  0.5079,  0.9457,\n",
      "          0.1942,  0.9973, -0.1714,  0.9074, -0.0316, -0.1722,  0.1354, -0.3539,\n",
      "          0.4604,  0.1690, -0.4248,  0.1374,  0.0242, -0.0303, -0.3962, -0.0534,\n",
      "         -0.1795, -0.9254, -0.3172,  0.9234, -0.1403, -0.3625,  0.4637, -0.1534,\n",
      "         -0.2116,  0.7484,  0.4645,  0.2362,  0.0231,  0.2697, -0.1449,  0.4371,\n",
      "         -0.7425,  0.1985,  0.3408, -0.2340, -0.0070, -0.9663, -0.2922,  0.3876,\n",
      "          0.9778,  0.7619,  0.1850,  0.4055, -0.0328,  0.4767, -0.9237,  0.9579,\n",
      "         -0.2061,  0.2602,  0.1251,  0.3175, -0.7580, -0.2756,  0.7724, -0.4525,\n",
      "         -0.7861,  0.1145, -0.3597, -0.3508, -0.3396,  0.3263, -0.2616, -0.3041,\n",
      "          0.0694,  0.8969,  0.9484,  0.7676, -0.3154,  0.4936, -0.8663, -0.4147,\n",
      "          0.0335,  0.1240,  0.1758,  0.9885, -0.2392, -0.1622, -0.8874, -0.9757,\n",
      "         -0.1352, -0.8547, -0.0443, -0.6082,  0.2991,  0.0650,  0.2441,  0.2073,\n",
      "         -0.9780, -0.6810,  0.2507, -0.1306,  0.3335, -0.1259,  0.4148,  0.5028,\n",
      "         -0.3960,  0.5807,  0.8526, -0.4131, -0.7229,  0.7163, -0.2616,  0.8002,\n",
      "         -0.4860,  0.9525,  0.4230,  0.6309, -0.8878, -0.0439, -0.8549, -0.0543,\n",
      "         -0.0351, -0.3860,  0.4529,  0.3804,  0.3385,  0.7418, -0.3546,  0.9930,\n",
      "         -0.5085, -0.9069, -0.0216, -0.1572, -0.9679,  0.4005,  0.2289, -0.1903,\n",
      "         -0.3087, -0.5063, -0.9197,  0.7904,  0.0059,  0.9739,  0.0785, -0.8172,\n",
      "         -0.3383, -0.8886, -0.2991, -0.1216,  0.1076, -0.1004, -0.9437,  0.3956,\n",
      "          0.3743,  0.4413, -0.1102,  0.9950,  0.9999,  0.9481,  0.8519,  0.8885,\n",
      "         -0.9833, -0.5702,  0.9999, -0.8721, -1.0000, -0.8945, -0.4084,  0.3377,\n",
      "         -1.0000, -0.0946,  0.0491, -0.8716,  0.0894,  0.9582,  0.9802, -1.0000,\n",
      "          0.7365,  0.9240, -0.3803,  0.8078, -0.0601,  0.9492,  0.4612,  0.2752,\n",
      "         -0.2155,  0.2588, -0.4035, -0.7784,  0.0382, -0.2135,  0.9508,  0.0931,\n",
      "         -0.6059, -0.8784,  0.0703, -0.0764, -0.3359, -0.9548, -0.0196,  0.1478,\n",
      "          0.5581,  0.0381,  0.2489, -0.5633,  0.1347, -0.4215,  0.1720,  0.5144,\n",
      "         -0.8971, -0.5451, -0.1069, -0.3492, -0.0430, -0.9428,  0.9491, -0.3897,\n",
      "          0.2131,  1.0000, -0.1194, -0.7848,  0.4910,  0.1945, -0.1582,  1.0000,\n",
      "          0.6058, -0.9560, -0.3582,  0.3670, -0.4223, -0.3440,  0.9937, -0.2174,\n",
      "         -0.1476, -0.0064,  0.9481, -0.9725,  0.8753, -0.8805, -0.9520,  0.9479,\n",
      "          0.9097, -0.3428, -0.4352,  0.0950, -0.1305,  0.2638, -0.9407,  0.5539,\n",
      "          0.2432,  0.0378,  0.8467, -0.7363, -0.3360,  0.2775, -0.2953,  0.1444,\n",
      "          0.4243,  0.3786, -0.0962,  0.0364, -0.1404, -0.0054, -0.9704,  0.1637,\n",
      "          1.0000, -0.1082,  0.1472, -0.1518,  0.0047, -0.2467,  0.3398,  0.4502,\n",
      "         -0.2001, -0.7734,  0.4033, -0.9359, -0.9706,  0.7094,  0.1767, -0.1711,\n",
      "          0.9994,  0.2535,  0.0426,  0.1404,  0.8777, -0.1098,  0.4841,  0.4265,\n",
      "          0.9545, -0.1005,  0.3193,  0.8154, -0.3768, -0.1194, -0.5195,  0.0495,\n",
      "         -0.8751,  0.1640, -0.9335,  0.9510,  0.2816,  0.2067,  0.1602,  0.1311,\n",
      "          1.0000, -0.2659,  0.4858, -0.2553,  0.6836, -0.9890, -0.7613, -0.2870,\n",
      "          0.0652, -0.1993, -0.2249,  0.1863, -0.9534,  0.1621,  0.1237, -0.9706,\n",
      "         -0.9795,  0.2239,  0.7231,  0.0807, -0.8228, -0.5209, -0.4474,  0.2791,\n",
      "         -0.1199, -0.9226,  0.3252, -0.1467,  0.4223, -0.1415,  0.3669,  0.1714,\n",
      "          0.8252, -0.0464, -0.0991, -0.0376, -0.6838,  0.6558, -0.6947, -0.5330,\n",
      "         -0.0933,  1.0000, -0.4504,  0.3508,  0.6346,  0.5850,  0.0023,  0.0439,\n",
      "          0.4573,  0.0636, -0.1355, -0.2816, -0.5884, -0.2385,  0.3382, -0.0429,\n",
      "         -0.0162,  0.7099,  0.5958,  0.0682,  0.0156, -0.0868,  0.9976,  0.0125,\n",
      "         -0.0413, -0.3859,  0.1160, -0.2737, -0.1272,  1.0000,  0.2359,  0.1349,\n",
      "         -0.9747, -0.3745, -0.8533,  0.9999,  0.7765, -0.6884,  0.4122,  0.3838,\n",
      "         -0.0531,  0.6489, -0.1061, -0.2134,  0.1745,  0.1153,  0.9298, -0.4514,\n",
      "         -0.9400, -0.4014,  0.3407, -0.9459,  0.9920, -0.4437, -0.0869, -0.2502,\n",
      "          0.1338,  0.2658, -0.1142, -0.9727, -0.1657,  0.0342,  0.9422,  0.0857,\n",
      "         -0.3206, -0.9071,  0.0844,  0.1024, -0.3685, -0.8894,  0.9466, -0.9770,\n",
      "          0.5728,  1.0000,  0.1788, -0.5597,  0.0449, -0.2421,  0.2723,  0.0653,\n",
      "          0.4691, -0.9408, -0.3317, -0.1310,  0.1329, -0.0615,  0.2186,  0.5943,\n",
      "          0.1159, -0.2166, -0.4589,  0.0795,  0.3707,  0.7457, -0.1816, -0.0966,\n",
      "         -0.0440, -0.0374, -0.8827, -0.1874, -0.1823, -0.9985,  0.6506, -1.0000,\n",
      "         -0.0456, -0.3913, -0.1052,  0.7823,  0.5468,  0.3629, -0.6177, -0.4392,\n",
      "          0.7163,  0.6074, -0.0802,  0.0070, -0.6009,  0.1306, -0.0094,  0.2814,\n",
      "          0.0368,  0.6860, -0.1847,  1.0000,  0.1198, -0.3197, -0.9610,  0.1836,\n",
      "         -0.0642,  1.0000, -0.8584, -0.9174,  0.2280, -0.4854, -0.7923,  0.2129,\n",
      "         -0.1861, -0.5781, -0.6054,  0.9255,  0.7834, -0.4203,  0.3405, -0.2657,\n",
      "         -0.4312, -0.1229,  0.2017,  0.9770,  0.2302,  0.8289,  0.1766, -0.0716,\n",
      "          0.9417,  0.0105,  0.3645,  0.0486,  1.0000,  0.1468, -0.8849,  0.2452,\n",
      "         -0.9688, -0.0711, -0.9387,  0.2131,  0.1222,  0.8957, -0.2720,  0.8880,\n",
      "         -0.1720,  0.0584, -0.2223,  0.3237,  0.2679, -0.8961, -0.9643, -0.9703,\n",
      "          0.5040, -0.2692,  0.0040,  0.1320, -0.0700,  0.3214,  0.4431, -1.0000,\n",
      "          0.9068,  0.2454,  0.3583,  0.9390,  0.5181,  0.3517,  0.1518, -0.9665,\n",
      "         -0.9703, -0.2536, -0.1883,  0.5646,  0.5437,  0.8620,  0.2451, -0.4455,\n",
      "         -0.3822,  0.0091, -0.6917, -0.9852,  0.3382, -0.0972, -0.9283,  0.9302,\n",
      "         -0.2703, -0.0342,  0.3596, -0.4358,  0.9253,  0.7067,  0.1822,  0.1116,\n",
      "          0.3599,  0.7823,  0.8854,  0.9608, -0.0916,  0.7175, -0.2277,  0.3182,\n",
      "          0.4622, -0.8959,  0.0625,  0.0922,  0.1327,  0.0213, -0.0860, -0.9587,\n",
      "          0.0408, -0.0488,  0.4138, -0.3439,  0.1376, -0.3218, -0.0425, -0.4669,\n",
      "         -0.5201,  0.4460,  0.0104,  0.8720,  0.6178, -0.0201, -0.4316, -0.1361,\n",
      "         -0.0722, -0.8742,  0.8814,  0.0965,  0.2034,  0.1075, -0.1244,  0.7316,\n",
      "         -0.2205, -0.3134, -0.2649, -0.5711,  0.7880, -0.2116, -0.4370, -0.4202,\n",
      "          0.6134,  0.2441,  0.9965, -0.2025, -0.4575, -0.2616, -0.3594,  0.3063,\n",
      "         -0.1826, -1.0000,  0.2489, -0.1979,  0.0901, -0.2694,  0.1847, -0.1845,\n",
      "         -0.9601, -0.1050,  0.1797,  0.2896, -0.4594, -0.3630,  0.3475,  0.1388,\n",
      "          0.8324,  0.8040, -0.0836,  0.4690,  0.4384, -0.1637, -0.5453,  0.8798]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None), BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0499,  0.2185, -0.0576,  ..., -0.3023, -0.1887,  0.6551],\n",
      "         [ 0.7256,  0.0362, -0.1488,  ...,  0.1777,  0.2603,  0.5894],\n",
      "         [-0.0970,  0.0674,  0.7675,  ..., -0.6381, -0.2912, -0.2798],\n",
      "         ...,\n",
      "         [ 0.6005, -0.0958, -0.2105,  ..., -0.0729,  0.5784,  0.3362],\n",
      "         [-0.1583, -0.4340, -0.6357,  ...,  0.6012, -0.2025, -0.2426],\n",
      "         [ 0.8945,  0.1474, -0.0287,  ...,  0.2251, -0.6388, -0.1321]]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), pooler_output=tensor([[-0.9156, -0.4725, -0.9188,  0.8766,  0.7463, -0.2201,  0.9004,  0.3932,\n",
      "         -0.8466, -1.0000, -0.5763,  0.8880,  0.9768,  0.5833,  0.9313, -0.6916,\n",
      "         -0.3353, -0.6417,  0.3623, -0.4746,  0.7198,  1.0000, -0.0290,  0.3659,\n",
      "          0.5863,  0.9892, -0.7100,  0.9465,  0.9571,  0.7506, -0.7367,  0.2910,\n",
      "         -0.9881, -0.3270, -0.9211, -0.9902,  0.4675, -0.7875, -0.0985, -0.0505,\n",
      "         -0.9322,  0.3997,  1.0000, -0.0594,  0.4436, -0.4509, -1.0000,  0.3774,\n",
      "         -0.8974,  0.9235,  0.8346,  0.8239,  0.2817,  0.5421,  0.5357, -0.1023,\n",
      "         -0.0634,  0.1563, -0.2711, -0.6055, -0.6910,  0.4263, -0.8957, -0.9172,\n",
      "          0.8525,  0.7917, -0.2848, -0.3487, -0.2109, -0.0038,  0.9313,  0.2674,\n",
      "         -0.0753, -0.9115,  0.6738,  0.4256, -0.7580,  1.0000, -0.5326, -0.9773,\n",
      "          0.9079,  0.7623,  0.7037, -0.3280,  0.5268, -1.0000,  0.5072, -0.1995,\n",
      "         -0.9888,  0.4041,  0.6246, -0.3816,  0.4741,  0.7747, -0.6281, -0.5323,\n",
      "         -0.3328, -0.7901, -0.4339, -0.2525,  0.1572, -0.3071, -0.4175, -0.5074,\n",
      "          0.4638, -0.5636, -0.5459,  0.6360,  0.2477,  0.7360,  0.5979, -0.4795,\n",
      "          0.5823, -0.9602,  0.6985, -0.4070, -0.9876, -0.7430, -0.9910,  0.7150,\n",
      "         -0.5006, -0.1549,  0.9639, -0.3262,  0.5886, -0.1251, -0.9030, -1.0000,\n",
      "         -0.6329, -0.4142, -0.3897, -0.3026, -0.9754, -0.9591,  0.6771,  0.9602,\n",
      "          0.3491,  0.9999, -0.3654,  0.9427, -0.4982, -0.7804,  0.5466, -0.5000,\n",
      "          0.8216,  0.4124, -0.6384,  0.2303, -0.1625,  0.4021, -0.6271, -0.3794,\n",
      "         -0.8127, -0.9543, -0.5159,  0.9583, -0.5839, -0.9353, -0.0328, -0.2990,\n",
      "         -0.5767,  0.9062,  0.6884,  0.3368, -0.3147,  0.5133,  0.2186,  0.6831,\n",
      "         -0.8514, -0.1864,  0.4700, -0.4243, -0.8605, -0.9732, -0.5161,  0.7238,\n",
      "          0.9902,  0.8071,  0.3715,  0.7782, -0.3691,  0.7538, -0.9613,  0.9797,\n",
      "         -0.3372,  0.4204, -0.2160,  0.5207, -0.8402,  0.1390,  0.8671, -0.7636,\n",
      "         -0.8180, -0.0981, -0.5589, -0.5718, -0.7492,  0.5188, -0.4576, -0.5223,\n",
      "         -0.2933,  0.9292,  0.9860,  0.8483,  0.3105,  0.8210, -0.9325, -0.5658,\n",
      "          0.2038,  0.3713,  0.2906,  0.9926, -0.7298, -0.2084, -0.9474, -0.9867,\n",
      "          0.1140, -0.9263, -0.2286, -0.7610,  0.7875, -0.0565,  0.6436,  0.5129,\n",
      "         -0.9901, -0.8033,  0.4200, -0.5348,  0.4464, -0.2119,  0.6671,  0.9237,\n",
      "         -0.6573,  0.6530,  0.9487, -0.9130, -0.8169,  0.8578, -0.4291,  0.8674,\n",
      "         -0.7452,  0.9890,  0.9275,  0.8018, -0.9212, -0.7412, -0.8841, -0.6676,\n",
      "         -0.1857, -0.0430,  0.8937,  0.7481,  0.5729,  0.3913, -0.6721,  0.9973,\n",
      "         -0.6561, -0.9622, -0.3635, -0.4443, -0.9876,  0.8781,  0.3727,  0.4519,\n",
      "         -0.6133, -0.7263, -0.9478,  0.9216,  0.2026,  0.9887, -0.1093, -0.9476,\n",
      "         -0.5752, -0.9317, -0.0751, -0.3029, -0.4802, -0.0831, -0.9574,  0.5631,\n",
      "          0.5847,  0.5585, -0.8541,  0.9990,  1.0000,  0.9727,  0.9023,  0.9203,\n",
      "         -0.9998, -0.3823,  1.0000, -0.9882, -1.0000, -0.9359, -0.6951,  0.4327,\n",
      "         -1.0000, -0.2757, -0.0103, -0.9264,  0.6178,  0.9765,  0.9936, -1.0000,\n",
      "          0.8325,  0.9473, -0.7583,  0.9388, -0.3902,  0.9656,  0.6607,  0.5616,\n",
      "         -0.3130,  0.4794, -0.9266, -0.9111, -0.6309, -0.6989,  0.9977,  0.2094,\n",
      "         -0.7650, -0.9241,  0.2664, -0.1926,  0.1159, -0.9697, -0.3976,  0.4586,\n",
      "          0.7425,  0.2826,  0.3023, -0.7155,  0.4261,  0.1084,  0.3148,  0.7754,\n",
      "         -0.9356, -0.5997, -0.4304, -0.1757, -0.7023, -0.9725,  0.9723, -0.3804,\n",
      "          0.8711,  1.0000,  0.0811, -0.8996,  0.6640,  0.4505, -0.3954,  1.0000,\n",
      "          0.7681, -0.9785, -0.7372,  0.7134, -0.6839, -0.7488,  0.9996, -0.3506,\n",
      "         -0.7081, -0.3654,  0.9765, -0.9899,  0.9958, -0.9116, -0.9688,  0.9719,\n",
      "          0.9527, -0.5599, -0.7826,  0.2337, -0.7014,  0.4854, -0.9407,  0.6712,\n",
      "          0.5965, -0.2354,  0.8883, -0.8519, -0.7456,  0.3513, -0.4412, -0.2177,\n",
      "          0.9212,  0.6415, -0.3664, -0.0258, -0.4038, -0.4876, -0.9809,  0.6121,\n",
      "          1.0000, -0.3138,  0.7432, -0.3361, -0.1159,  0.0252,  0.6700,  0.6596,\n",
      "         -0.4186, -0.8667,  0.7845, -0.9669, -0.9868,  0.8344,  0.3340, -0.4040,\n",
      "          1.0000,  0.4948,  0.4242,  0.3169,  0.9834, -0.0355,  0.5679,  0.8711,\n",
      "          0.9823, -0.3393,  0.7330,  0.8153, -0.8810, -0.4080, -0.6690,  0.1585,\n",
      "         -0.9342,  0.0529, -0.9525,  0.9723,  0.9521,  0.5514,  0.3158,  0.7021,\n",
      "          1.0000, -0.6158,  0.6311, -0.3193,  0.8791, -0.9999, -0.8278, -0.4109,\n",
      "         -0.1732, -0.7858, -0.4543,  0.4340, -0.9679,  0.8312,  0.7561, -0.9921,\n",
      "         -0.9882, -0.2058,  0.8803,  0.1688, -0.9826, -0.7136, -0.6030,  0.6595,\n",
      "         -0.3550, -0.9470, -0.2865, -0.4659,  0.6085, -0.3373,  0.6812,  0.8364,\n",
      "          0.7687, -0.7156, -0.4100, -0.0732, -0.8512,  0.8274, -0.8518, -0.8926,\n",
      "         -0.3243,  1.0000, -0.4437,  0.8877,  0.7444,  0.8038, -0.3087,  0.3346,\n",
      "          0.9537,  0.3117, -0.6443, -0.8385, -0.5457, -0.5591,  0.7044,  0.4895,\n",
      "          0.6493,  0.8557,  0.7921,  0.2003, -0.1385,  0.1359,  0.9996, -0.3375,\n",
      "         -0.1418, -0.5483, -0.1675, -0.4885, -0.4948,  1.0000,  0.3778,  0.5396,\n",
      "         -0.9895, -0.8573, -0.9277,  1.0000,  0.8396, -0.7438,  0.5577,  0.5680,\n",
      "         -0.2469,  0.7156, -0.3511, -0.3953,  0.2079,  0.2978,  0.9364, -0.6164,\n",
      "         -0.9698, -0.7406,  0.5755, -0.9617,  0.9999, -0.6534, -0.3418, -0.5240,\n",
      "          0.0797,  0.4729,  0.0114, -0.9829, -0.3427,  0.3197,  0.9616,  0.3080,\n",
      "         -0.7107, -0.9286,  0.8000,  0.7475, -0.8668, -0.9501,  0.9629, -0.9854,\n",
      "          0.6215,  1.0000,  0.3707,  0.1120,  0.2923, -0.4689,  0.4742, -0.3742,\n",
      "          0.6792, -0.9648, -0.4355, -0.2537,  0.4222, -0.2384,  0.0318,  0.7231,\n",
      "          0.4040, -0.7306, -0.6884, -0.1744,  0.5033,  0.8397, -0.4486, -0.2724,\n",
      "          0.1882, -0.2157, -0.9420, -0.4040, -0.5199, -1.0000,  0.7250, -1.0000,\n",
      "          0.4930,  0.2462, -0.3281,  0.8670,  0.3962,  0.6980, -0.7565, -0.8810,\n",
      "          0.4760,  0.8537, -0.4175, -0.5567, -0.6960,  0.4085, -0.2356,  0.3909,\n",
      "         -0.5960,  0.8331, -0.2723,  1.0000,  0.2594, -0.6905, -0.9817,  0.2769,\n",
      "         -0.3090,  1.0000, -0.8629, -0.9542,  0.4498, -0.7809, -0.8451,  0.3907,\n",
      "          0.1361, -0.8133, -0.9549,  0.9656,  0.8862, -0.7225,  0.5811, -0.4869,\n",
      "         -0.7296,  0.2565,  0.9334,  0.9862,  0.3921,  0.8881,  0.2704, -0.3477,\n",
      "          0.9736,  0.2494,  0.3988,  0.1993,  1.0000,  0.3923, -0.9326,  0.1733,\n",
      "         -0.9790, -0.2875, -0.9521,  0.3366,  0.2487,  0.8999, -0.4449,  0.9503,\n",
      "         -0.8544,  0.0896, -0.5560, -0.4274,  0.4822, -0.9285, -0.9747, -0.9832,\n",
      "          0.6814, -0.5091, -0.1486,  0.2885,  0.2083,  0.5630,  0.5749, -1.0000,\n",
      "          0.9403,  0.5731,  0.8957,  0.9597,  0.7153,  0.5023,  0.3260, -0.9821,\n",
      "         -0.9856, -0.4545, -0.3252,  0.8116,  0.7259,  0.8628,  0.5297, -0.5832,\n",
      "         -0.3696, -0.6032, -0.4746, -0.9932,  0.5615, -0.6340, -0.9540,  0.9587,\n",
      "         -0.0488, -0.2427, -0.1211, -0.8112,  0.9571,  0.8056,  0.3770,  0.2464,\n",
      "          0.5101,  0.8778,  0.9701,  0.9826, -0.8306,  0.8361, -0.7662,  0.5394,\n",
      "          0.7081, -0.9596,  0.2486,  0.4458, -0.5320,  0.3131, -0.4069, -0.9772,\n",
      "          0.7379, -0.3432,  0.5862, -0.5789,  0.1294, -0.6057, -0.3873, -0.7521,\n",
      "         -0.7645,  0.7837,  0.4369,  0.8839,  0.8473, -0.2165, -0.7926, -0.2292,\n",
      "         -0.7465, -0.9123,  0.9360, -0.2282, -0.1609,  0.6966,  0.1392,  0.7805,\n",
      "          0.3503, -0.4867, -0.3733, -0.7471,  0.8662, -0.3418, -0.7428, -0.6494,\n",
      "          0.7334,  0.4382,  1.0000, -0.7432, -0.9183, -0.4340, -0.4293,  0.4882,\n",
      "         -0.5847, -1.0000,  0.4557, -0.6378,  0.6712, -0.7416,  0.7793, -0.7352,\n",
      "         -0.9860, -0.3733,  0.2470,  0.7352, -0.6380, -0.7131,  0.7238, -0.4080,\n",
      "          0.9623,  0.8821,  0.1367,  0.1440,  0.7631, -0.7055, -0.7265,  0.9005]],\n",
      "       device='cuda:0', grad_fn=<CompiledFunctionBackward>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Set the logging configurations\n",
    "torch._logging.set_logs(recompiles=True)\n",
    "\n",
    "def get_predictions(text_list):\n",
    "    \"\"\"\n",
    "    Given a list of strings, tokenize and pass them to the model for predictions.\n",
    "    :param text_list: List of strings\n",
    "    :return: List of model outputs\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for text in text_list:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "        output = model(**encoded_input)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "# Your training set of 10 strings\n",
    "training_set = [\n",
    "    \"Hello world!\",\n",
    "    \"How are you?\",\n",
    "    \"What's the weather like?\",\n",
    "    \"I love reading books.\",\n",
    "    \"The movie was fantastic!\",\n",
    "    \"My cat is adorable.\",\n",
    "    \"Let's go for a hike.\",\n",
    "    \"Coffee is my morning fuel.\",\n",
    "    \"The concert was a blast!\",\n",
    "    \"Keep calm and code on.\"\n",
    "]\n",
    "\n",
    "# Fetch predictions for the training set\n",
    "predictions = get_predictions(training_set)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 16:38:31,394] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 12, actual 5\")\n",
      "[2023-09-07 16:38:44,209] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 5, actual 6\")\n",
      "[2023-09-07 16:38:59,636] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 6, actual 9\")\n",
      "[2023-09-07 16:39:13,068] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 9, actual 7\")\n",
      "[2023-09-07 16:39:27,220] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 7, actual 10\")\n",
      "[2023-09-07 16:39:40,681] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 10, actual 8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Torchdynamo Profiler Report\n",
      "===========================\n",
      "\n",
      "Graph Breaks\n",
      "------------\n",
      "Graph breaks happen when torchdynamo encounters code it can't safely trace.\n",
      "If you want to find out why breaks are happening, check below for each break reason\n",
      "You may gain additional insight by passing `fullgraph=True` to torch.compile,\n",
      "to stop at the first break.\n",
      "\n",
      "No graph breaks detected.\n",
      "\n",
      "Recompilation\n",
      "-------------\n",
      "These subgraphs were recompiled more than once due to guard failures\n",
      "Guard failures indicate some condition assumed to be static by the tracer changed,\n",
      "making it unsafe to reuse the compiled program.\n",
      "\n",
      "Function                            Recompiles  Recompile Reasons\n",
      "--------------------------------  ------------  -------------------------------------------------------------------------\n",
      "'forward' (modeling_bert.py:913)             6  tensor 'L['input_ids']' stride mismatch at index 0. expected 12, actual 5\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 5, actual 6\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 6, actual 9\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 9, actual 7\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 7, actual 10\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 10, actual 8\n",
      "\n",
      "Set torch._dynamo.config.cache_size_limit to 6 to avoid being cache limited.\n",
      "\n",
      "TorchDynamo compilation metrics:\n",
      "Function                              Runtimes (s)\n",
      "------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "_compile.<locals>.compile_inner       13.6077, 12.8045, 15.4170, 13.4223, 14.1285, 13.4511, 13.4440\n",
      "OutputGraph.call_user_compiler        11.3394, 10.5672, 11.7722, 11.2045, 11.8927, 11.2126, 11.1949\n",
      "create_aot_dispatcher_function        0.0161, 0.0155, 0.0161, 0.0155, 0.0154, 0.0155, 0.0155, 0.0155, 0.0166, 0.0155, 0.0154, 0.0155, 0.0159, 0.0157, 0.0166, 0.0156, 0.0156, 0.0154, 0.0154, 0.0154, 0.0163, 0.0156, 0.0157, 0.0155, 11.2750, 0.0159, 0.0154, 0.0153, 0.0154, 0.0165, 0.0155, 0.0153, 0.0154, 0.0154, 0.0159, 0.0197, 0.0183, 0.0159, 0.0155, 0.0155, 0.0157, 0.0163, 0.0157, 0.0157, 0.0156, 0.0154, 0.0156, 0.0166, 0.0156, 10.5060, 0.0159, 0.0156, 0.0156, 0.0164, 0.0153, 0.0155, 0.0156, 0.0156, 0.0156, 0.0166, 0.0156, 0.0156, 0.0159, 0.0157, 0.0157, 0.0164, 0.0154, 0.0156, 0.0156, 0.0187, 0.0157, 0.0167, 0.0156, 0.0156, 11.7101, 0.0165, 0.0154, 0.0154, 0.0154, 0.0156, 0.0155, 0.0166, 0.0156, 0.0156, 0.0156, 0.0155, 0.0155, 0.0167, 0.0157, 0.0156, 0.0155, 0.0154, 0.0156, 0.0165, 0.0155, 0.0156, 0.0155, 0.0155, 0.0156, 11.1430, 0.0158, 0.0161, 0.0154, 0.0152, 0.0153, 0.0154, 0.0153, 0.0163, 0.0153, 0.0153, 0.0153, 0.0153, 0.0156, 0.0163, 0.0184, 0.0157, 0.0153, 0.0153, 0.0152, 0.0161, 0.0153, 0.0153, 0.0154, 0.0152, 11.8311, 0.0159, 0.0155, 0.0157, 0.0156, 0.0165, 0.0156, 0.0156, 0.0156, 0.0156, 0.0156, 0.0164, 0.0154, 0.0158, 0.0155, 0.0155, 0.0156, 0.0164, 0.0156, 0.0156, 0.0156, 0.0154, 0.0155, 0.0173, 0.0175, 11.1524, 0.0157, 0.0153, 0.0153, 0.0187, 0.0155, 0.0164, 0.0154, 0.0155, 0.0153, 0.0153, 0.0153, 0.0163, 0.0157, 0.0153, 0.0154, 0.0153, 0.0154, 0.0161, 0.0154, 0.0153, 0.0153, 0.0155, 0.0153, 0.0162, 11.1331\n",
      "compile_fx.<locals>.fw_compiler_base  4.7118, 3.9176, 5.0461, 4.5049, 5.2993, 4.5750, 4.6356\n",
      "GraphLowering.run                     0.7486, 0.8233, 0.8458, 0.7610, 0.8733, 1.8309, 0.7250\n",
      "GraphLowering.compile_to_module       2.6885, 1.8191, 2.8995, 2.4603, 3.1463, 1.4589, 2.6072\n",
      "Scheduler.__init__                    0.9064, 1.0614, 2.0829, 1.8867, 2.2796, 0.8856, 2.0167\n",
      "Scheduler.codegen                     1.7130, 0.6835, 0.7330, 0.5054, 0.7914, 0.5040, 0.5215\n",
      "WrapperCodeGen.generate               0.0576, 0.0629, 0.0718, 0.0569, 0.0640, 0.0577, 0.0576\n"
     ]
    }
   ],
   "source": [
    "from torch._dynamo.utils import CompileProfiler\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Set the logging configurations\n",
    "torch._logging.set_logs(recompiles=True, graph_breaks=True)\n",
    "\n",
    "def get_predictions(text_list):\n",
    "    \"\"\"\n",
    "    Given a list of strings, tokenize and pass them to the model for predictions.\n",
    "    :param text_list: List of strings\n",
    "    :return: List of model outputs\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for text in text_list:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "        output = model(**encoded_input)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "# Your training set of 10 strings\n",
    "training_set = [\n",
    "    \"Hello world!\",\n",
    "    \"How are you?\",\n",
    "    \"What's the weather like?\",\n",
    "    \"I love reading books.\",\n",
    "    \"The movie was fantastic!\",\n",
    "    \"My cat is adorable.\",\n",
    "    \"Let's go for a hike.\",\n",
    "    \"Coffee is my morning fuel.\",\n",
    "    \"The concert was a blast!\",\n",
    "    \"Keep calm and code on.\"\n",
    "]\n",
    "\n",
    "# Fetch predictions for the training set\n",
    "with CompileProfiler() as prof:\n",
    "    predictions = get_predictions(training_set)\n",
    "    print(prof.report())\n",
    "\n",
    "print(torch._dynamo.utils.compile_times())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perf optimisation - Dynamic shapes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 01:34:26,263] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 12, actual 5\")\n",
      "[2023-09-07 01:34:38,597] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 5, actual 6\")\n",
      "[2023-09-07 01:34:53,022] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 6, actual 9\")\n",
      "[2023-09-07 01:35:08,995] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 9, actual 7\")\n",
      "[2023-09-07 01:35:22,980] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 7, actual 10\")\n",
      "[2023-09-07 01:35:39,181] torch._dynamo.convert_frame.__recompiles: [DEBUG] ('Recompiling function forward in /usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py:913', \"triggered by the following guard failure: tensor 'L['input_ids']' stride mismatch at index 0. expected 10, actual 8\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Torchdynamo Profiler Report\n",
      "===========================\n",
      "\n",
      "Graph Breaks\n",
      "------------\n",
      "Graph breaks happen when torchdynamo encounters code it can't safely trace.\n",
      "If you want to find out why breaks are happening, check below for each break reason\n",
      "You may gain additional insight by passing `fullgraph=True` to torch.compile,\n",
      "to stop at the first break.\n",
      "\n",
      "No graph breaks detected.\n",
      "\n",
      "Recompilation\n",
      "-------------\n",
      "These subgraphs were recompiled more than once due to guard failures\n",
      "Guard failures indicate some condition assumed to be static by the tracer changed,\n",
      "making it unsafe to reuse the compiled program.\n",
      "\n",
      "Function                            Recompiles  Recompile Reasons\n",
      "--------------------------------  ------------  -------------------------------------------------------------------------\n",
      "'forward' (modeling_bert.py:913)             6  tensor 'L['input_ids']' stride mismatch at index 0. expected 12, actual 5\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 5, actual 6\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 6, actual 9\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 9, actual 7\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 7, actual 10\n",
      "                                                tensor 'L['input_ids']' stride mismatch at index 0. expected 10, actual 8\n",
      "\n",
      "Set torch._dynamo.config.cache_size_limit to 6 to avoid being cache limited.\n",
      "\n",
      "TorchDynamo compilation metrics:\n",
      "Function                              Runtimes (s)\n",
      "------------------------------------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "_compile.<locals>.compile_inner       14.3616, 12.3248, 14.4135, 15.9634, 13.9622, 16.1912, 11.8795\n",
      "OutputGraph.call_user_compiler        12.1064, 10.1405, 12.2600, 13.7626, 11.7611, 13.9276, 9.6857\n",
      "create_aot_dispatcher_function        0.0156, 0.0151, 0.0158, 0.0182, 0.0152, 0.0152, 0.0183, 0.0181, 0.0163, 0.0153, 0.0185, 0.0178, 0.0156, 0.0159, 0.0192, 0.0152, 0.0155, 0.0152, 0.0152, 0.0152, 0.0164, 0.0153, 0.0182, 0.0182, 12.0374, 0.0155, 0.0151, 0.0152, 0.0158, 0.0152, 0.0151, 0.0151, 0.0152, 0.0152, 0.0161, 0.0153, 0.0153, 0.0157, 0.0154, 0.0152, 0.0161, 0.0154, 0.0152, 0.0154, 0.0153, 0.0153, 0.0161, 0.0152, 0.0152, 10.0811, 0.0158, 0.0152, 0.0150, 0.0158, 0.0155, 0.0152, 0.0182, 0.0151, 0.0152, 0.0160, 0.0151, 0.0152, 0.0155, 0.0151, 0.0152, 0.0158, 0.0152, 0.0151, 0.0152, 0.0151, 0.0152, 0.0160, 0.0151, 0.0151, 12.1990, 0.0156, 0.0152, 0.0167, 0.0183, 0.0153, 0.0161, 0.0152, 0.0152, 0.0152, 0.0151, 0.0152, 0.0161, 0.0156, 0.0153, 0.0152, 0.0152, 0.0151, 0.0160, 0.0152, 0.0152, 0.0151, 0.0152, 0.0158, 0.0164, 13.7023, 0.0181, 0.0153, 0.0158, 0.0152, 0.0183, 0.0166, 0.0152, 0.0155, 0.0193, 0.0182, 0.0152, 0.0152, 0.0175, 0.0153, 0.0161, 0.0152, 0.0168, 0.0169, 0.0157, 0.0151, 0.0160, 0.0184, 0.0163, 0.0155, 11.7018, 0.0159, 0.0151, 0.0154, 0.0152, 0.0166, 0.0154, 0.0164, 0.0153, 0.0152, 0.0151, 0.0153, 0.0152, 0.0164, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0162, 0.0153, 0.0153, 0.0152, 0.0152, 0.0151, 13.8663, 0.0158, 0.0153, 0.0157, 0.0151, 0.0152, 0.0152, 0.0152, 0.0153, 0.0161, 0.0152, 0.0152, 0.0152, 0.0157, 0.0152, 0.0160, 0.0152, 0.0152, 0.0151, 0.0151, 0.0151, 0.0160, 0.0152, 0.0152, 0.0151, 9.6253\n",
      "compile_fx.<locals>.fw_compiler_base  3.5414, 3.8490, 3.9955, 5.2536, 4.3486, 3.3838, 3.3846\n",
      "GraphLowering.run                     0.7710, 0.8069, 0.8238, 2.5773, 0.8875, 0.7260, 0.7113\n",
      "GraphLowering.compile_to_module       1.4651, 1.7926, 1.9175, 1.4339, 2.1183, 1.4144, 1.4163\n",
      "Scheduler.__init__                    0.8690, 1.0466, 1.1238, 0.8709, 1.2247, 0.8521, 0.8527\n",
      "Scheduler.codegen                     0.5264, 0.6699, 0.7172, 0.4934, 0.8114, 0.4937, 0.4939\n",
      "WrapperCodeGen.generate               0.0578, 0.0643, 0.0646, 0.0581, 0.0703, 0.0568, 0.0580\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device=\"cuda:0\")\n",
    "model = torch.compile(model, backend=\"inductor\", dynamic=False) # This is the only line of code that we changed\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "output = model(**encoded_input)\n",
    "\n",
    "# Set the logging configurations\n",
    "torch._logging.set_logs(recompiles=True, graph_breaks=True)\n",
    "\n",
    "def get_predictions(text_list):\n",
    "    \"\"\"\n",
    "    Given a list of strings, tokenize and pass them to the model for predictions.\n",
    "    :param text_list: List of strings\n",
    "    :return: List of model outputs\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for text in text_list:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "        output = model(**encoded_input)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "# Your training set of 10 strings\n",
    "training_set = [\n",
    "    \"Hello world!\",\n",
    "    \"How are you?\",\n",
    "    \"What's the weather like?\",\n",
    "    \"I love reading books.\",\n",
    "    \"The movie was fantastic!\",\n",
    "    \"My cat is adorable.\",\n",
    "    \"Let's go for a hike.\",\n",
    "    \"Coffee is my morning fuel.\",\n",
    "    \"The concert was a blast!\",\n",
    "    \"Keep calm and code on.\"\n",
    "]\n",
    "\n",
    "# Fetch predictions for the training set\n",
    "with CompileProfiler() as prof:\n",
    "    predictions = get_predictions(training_set)\n",
    "    print(prof.report())\n",
    "\n",
    "print(torch._dynamo.utils.compile_times())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Torchdynamo Profiler Report\n",
      "===========================\n",
      "\n",
      "Graph Breaks\n",
      "------------\n",
      "Graph breaks happen when torchdynamo encounters code it can't safely trace.\n",
      "If you want to find out why breaks are happening, check below for each break reason\n",
      "You may gain additional insight by passing `fullgraph=True` to torch.compile,\n",
      "to stop at the first break.\n",
      "\n",
      "No graph breaks detected.\n",
      "\n",
      "Recompilation\n",
      "-------------\n",
      "These subgraphs were recompiled more than once due to guard failures\n",
      "Guard failures indicate some condition assumed to be static by the tracer changed,\n",
      "making it unsafe to reuse the compiled program.\n",
      "\n",
      "No recompilation detected.\n",
      "\n",
      "TorchDynamo compilation metrics:\n",
      "Function                              Runtimes (s)\n",
      "------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "_compile.<locals>.compile_inner       28.9943\n",
      "OutputGraph.call_user_compiler        25.9173\n",
      "create_aot_dispatcher_function        0.0353, 0.0336, 0.0346, 0.0337, 0.0337, 0.0328, 0.0338, 0.0380, 0.0346, 0.0336, 0.0344, 0.0334, 0.0345, 0.0338, 0.0338, 0.0327, 0.0336, 0.0339, 0.0344, 0.0334, 0.0342, 0.0334, 0.0344, 0.0341, 25.8393\n",
      "compile_fx.<locals>.fw_compiler_base  5.4223\n",
      "GraphLowering.run                     0.7857, 1.0572\n",
      "GraphLowering.compile_to_module       1.6698, 1.9044\n",
      "Scheduler.__init__                    0.9646, 0.9504\n",
      "Scheduler.codegen                     0.6052, 0.8000\n",
      "WrapperCodeGen.generate               0.0883, 0.1229\n",
      "compile_fx.<locals>.bw_compiler       6.3244\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device=\"cuda:0\")\n",
    "model = torch.compile(model, backend=\"inductor\", dynamic=True) # This is the only line of code that we changed\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "output = model(**encoded_input)\n",
    "\n",
    "# Set the logging configurations\n",
    "torch._logging.set_logs(recompiles=True, graph_breaks=True)\n",
    "\n",
    "def get_predictions(text_list):\n",
    "    \"\"\"\n",
    "    Given a list of strings, tokenize and pass them to the model for predictions.\n",
    "    :param text_list: List of strings\n",
    "    :return: List of model outputs\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "    for text in text_list:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "        output = model(**encoded_input)\n",
    "        outputs.append(output)\n",
    "    return outputs\n",
    "\n",
    "# Your training set of 10 strings\n",
    "training_set = [\n",
    "    \"Hello world!\",\n",
    "    \"How are you?\",\n",
    "    \"What's the weather like?\",\n",
    "    \"I love reading books.\",\n",
    "    \"The movie was fantastic!\",\n",
    "    \"My cat is adorable.\",\n",
    "    \"Let's go for a hike.\",\n",
    "    \"Coffee is my morning fuel.\",\n",
    "    \"The concert was a blast!\",\n",
    "    \"Keep calm and code on.\"\n",
    "]\n",
    "\n",
    "# Fetch predictions for the training set\n",
    "with CompileProfiler() as prof:\n",
    "    predictions = get_predictions(training_set)\n",
    "    print(prof.report())\n",
    "\n",
    "print(torch._dynamo.utils.compile_times())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimising graph breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 01:39:32,189] [64/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] Graph break: call_function BuiltinVariable(print) [ConstantVariable(str)] {} from user code at:\n",
      "[2023-09-07 01:39:32,189] [64/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]   File \"/tmp/ipykernel_19834/3151414406.py\", line 5, in toy_example\n",
      "[2023-09-07 01:39:32,189] [64/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG]     print(\"woo\")\n",
      "[2023-09-07 01:39:32,189] [64/0] torch._dynamo.symbolic_convert.__graph_breaks: [DEBUG] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woo\n",
      "[GraphCompileReason(reason='call_function BuiltinVariable(print) [ConstantVariable(str)] {}', user_stack=[<FrameSummary file /tmp/ipykernel_19834/3151414406.py, line 5 in toy_example>], graph_break=True), GraphCompileReason(reason='generic_jump TensorVariable()', user_stack=[<FrameSummary file /tmp/ipykernel_19834/3151414406.py, line 6 in <resume in toy_example>>], graph_break=True)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch._dynamo as dynamo\n",
    "def toy_example(a, b):\n",
    "    x = a / (torch.abs(a) + 1)\n",
    "    print(\"woo\")\n",
    "    if b.sum() < 0:\n",
    "        b = b * -1\n",
    "    return x * b\n",
    "\n",
    "explain = dynamo.explain(toy_example)(torch.randn(10), torch.randn(10))\n",
    "\n",
    "print(explain.break_reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CudaGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real eager (warmup) Model took 0.1197 seconds\n",
      "Real eager Model took 0.1192 seconds\n",
      "Eager compile (warmup) Model took 0.3551 seconds\n",
      "Eager compile Model took 0.3525 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/_inductor/compile_fx.py:135: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inductor (warmup) Model took 111.2118 seconds\n",
      "Inductor Model took 0.0899 seconds\n",
      "Dynamic Shapes (warmup) Model took 0.0908 seconds\n",
      "Dynamic Shapes Model took 0.0898 seconds\n",
      "Dynamic Shapes with CUDA Graph (warmup) Model took 0.8104 seconds\n",
      "Dynamic Shapes with CUDA Graph Model took 8.6877 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AUTOTUNE addmm(12x1024, 12x1024, 1024x1024)\n",
      "  bias_addmm 0.0328 ms 100.0%\n",
      "  addmm 0.0330 ms 99.5%\n",
      "  triton_mm_3 0.1293 ms 25.4%\n",
      "  triton_mm_6 0.1520 ms 21.6%\n",
      "  triton_mm_4 0.3574 ms 9.2%\n",
      "  triton_mm_0 0.3732 ms 8.8%\n",
      "  triton_mm_5 0.3848 ms 8.5%\n",
      "  triton_mm_1 0.3960 ms 8.3%\n",
      "  triton_mm_2 0.7030 ms 4.7%\n",
      "SingleProcess AUTOTUNE takes 4.4057 seconds\n",
      "AUTOTUNE bmm(16x12x64, 16x64x12)\n",
      "  bmm 0.0146 ms 100.0%\n",
      "  triton_bmm_22 0.0160 ms 91.0%\n",
      "  triton_bmm_21 0.0170 ms 85.8%\n",
      "  triton_bmm_23 0.0189 ms 77.1%\n",
      "SingleProcess AUTOTUNE takes 2.0906 seconds\n",
      "AUTOTUNE bmm(16x12x12, 16x12x64)\n",
      "  bmm 0.0144 ms 100.0%\n",
      "  triton_bmm_25 0.0147 ms 97.8%\n",
      "  triton_bmm_24 0.0149 ms 96.8%\n",
      "SingleProcess AUTOTUNE takes 1.0130 seconds\n",
      "AUTOTUNE addmm(12x4096, 12x1024, 1024x4096)\n",
      "  bias_addmm 0.0523 ms 100.0%\n",
      "  addmm 0.0523 ms 100.0%\n",
      "  triton_mm_36 0.2053 ms 25.5%\n",
      "  triton_mm_39 0.2078 ms 25.2%\n",
      "  triton_mm_37 0.3613 ms 14.5%\n",
      "  triton_mm_33 0.3736 ms 14.0%\n",
      "  triton_mm_38 0.3885 ms 13.5%\n",
      "  triton_mm_34 0.3910 ms 13.4%\n",
      "  triton_mm_35 0.7107 ms 7.4%\n",
      "SingleProcess AUTOTUNE takes 4.0500 seconds\n",
      "AUTOTUNE addmm(12x1024, 12x4096, 4096x1024)\n",
      "  bias_addmm 0.0494 ms 100.0%\n",
      "  addmm 0.0494 ms 100.0%\n",
      "  triton_mm_43 0.4832 ms 10.2%\n",
      "  triton_mm_46 0.5698 ms 8.7%\n",
      "  triton_mm_44 1.3867 ms 3.6%\n",
      "  triton_mm_40 1.4294 ms 3.5%\n",
      "  triton_mm_45 1.4966 ms 3.3%\n",
      "  triton_mm_41 1.5466 ms 3.2%\n",
      "  triton_mm_42 2.7845 ms 1.8%\n",
      "SingleProcess AUTOTUNE takes 4.1153 seconds\n",
      "AUTOTUNE mm(1x1024, 1024x1024)\n",
      "  mm 0.0227 ms 100.0%\n",
      "  triton_mm_1131 0.1250 ms 18.2%\n",
      "  triton_mm_1134 0.1427 ms 15.9%\n",
      "  triton_mm_1132 0.3557 ms 6.4%\n",
      "  triton_mm_1128 0.3714 ms 6.1%\n",
      "  triton_mm_1133 0.3798 ms 6.0%\n",
      "  triton_mm_1129 0.3886 ms 5.8%\n",
      "  triton_mm_1130 0.7018 ms 3.2%\n",
      "SingleProcess AUTOTUNE takes 4.2433 seconds\n",
      "AUTOTUNE mm(1x1024, 1024x1024)\n",
      "  mm 0.0272 ms 100.0%\n",
      "  triton_mm_1138 0.0906 ms 30.0%\n",
      "  triton_mm_1139 0.0958 ms 28.4%\n",
      "  triton_mm_1141 0.0960 ms 28.3%\n",
      "  triton_mm_1135 0.0986 ms 27.6%\n",
      "  triton_mm_1140 0.1245 ms 21.9%\n",
      "  triton_mm_1137 0.1520 ms 17.9%\n",
      "  triton_mm_1136 0.1534 ms 17.7%\n",
      "SingleProcess AUTOTUNE takes 4.0285 seconds\n",
      "AUTOTUNE mm(1024x1, 1x1024)\n",
      "  triton_mm_1142 0.0171 ms 100.0%\n",
      "  triton_mm_1151 0.0171 ms 100.0%\n",
      "  mm 0.0174 ms 98.2%\n",
      "  triton_mm_1150 0.0176 ms 97.3%\n",
      "  triton_mm_1143 0.0179 ms 95.5%\n",
      "  triton_mm_1144 0.0181 ms 94.7%\n",
      "  triton_mm_1147 0.0186 ms 92.2%\n",
      "  triton_mm_1149 0.0189 ms 90.7%\n",
      "  triton_mm_1145 0.0194 ms 88.4%\n",
      "  triton_mm_1146 0.0195 ms 87.7%\n",
      "SingleProcess AUTOTUNE takes 4.4329 seconds\n",
      "AUTOTUNE mm(12x1024, 1024x4096)\n",
      "  mm 0.0309 ms 100.0%\n",
      "  triton_mm_1155 0.0991 ms 31.2%\n",
      "  triton_mm_1156 0.1032 ms 29.9%\n",
      "  triton_mm_1158 0.1126 ms 27.4%\n",
      "  triton_mm_1152 0.1157 ms 26.7%\n",
      "  triton_mm_1157 0.1282 ms 24.1%\n",
      "  triton_mm_1153 0.1584 ms 19.5%\n",
      "  triton_mm_1154 0.1627 ms 19.0%\n",
      "SingleProcess AUTOTUNE takes 4.4280 seconds\n",
      "AUTOTUNE mm(1024x12, 12x4096)\n",
      "  triton_mm_1160 0.0325 ms 100.0%\n",
      "  triton_mm_1167 0.0349 ms 93.1%\n",
      "  triton_mm_1159 0.0354 ms 91.9%\n",
      "  mm 0.0366 ms 88.6%\n",
      "  triton_mm_1161 0.0379 ms 85.7%\n",
      "  triton_mm_1168 0.0402 ms 80.9%\n",
      "  triton_mm_1162 0.0418 ms 77.8%\n",
      "  triton_mm_1164 0.0432 ms 75.2%\n",
      "  triton_mm_1166 0.0432 ms 75.2%\n",
      "  triton_mm_1163 0.0438 ms 74.1%\n",
      "SingleProcess AUTOTUNE takes 4.7314 seconds\n",
      "AUTOTUNE mm(12x4096, 4096x1024)\n",
      "  mm 0.0326 ms 100.0%\n",
      "  triton_mm_1172 0.3262 ms 10.0%\n",
      "  triton_mm_1173 0.3614 ms 9.0%\n",
      "  triton_mm_1175 0.3730 ms 8.8%\n",
      "  triton_mm_1169 0.4112 ms 7.9%\n",
      "  triton_mm_1174 0.4559 ms 7.2%\n",
      "  triton_mm_1170 0.5858 ms 5.6%\n",
      "  triton_mm_1171 0.6048 ms 5.4%\n",
      "SingleProcess AUTOTUNE takes 4.1405 seconds\n",
      "AUTOTUNE mm(4096x12, 12x1024)\n",
      "  mm 0.0309 ms 100.0%\n",
      "  triton_mm_1177 0.0318 ms 97.0%\n",
      "  triton_mm_1184 0.0336 ms 91.9%\n",
      "  triton_mm_1178 0.0338 ms 91.5%\n",
      "  triton_mm_1176 0.0339 ms 91.0%\n",
      "  triton_mm_1181 0.0386 ms 80.1%\n",
      "  triton_mm_1183 0.0395 ms 78.1%\n",
      "  triton_mm_1179 0.0397 ms 77.8%\n",
      "  triton_mm_1180 0.0397 ms 77.8%\n",
      "  triton_mm_1185 0.0400 ms 77.2%\n",
      "SingleProcess AUTOTUNE takes 4.6675 seconds\n",
      "AUTOTUNE mm(12x1024, 1024x1024)\n",
      "  mm 0.0275 ms 100.0%\n",
      "  triton_mm_1189 0.0899 ms 30.6%\n",
      "  triton_mm_1190 0.0992 ms 27.7%\n",
      "  triton_mm_1192 0.1010 ms 27.3%\n",
      "  triton_mm_1186 0.1112 ms 24.7%\n",
      "  triton_mm_1191 0.1210 ms 22.8%\n",
      "  triton_mm_1187 0.1552 ms 17.7%\n",
      "  triton_mm_1188 0.1600 ms 17.2%\n",
      "SingleProcess AUTOTUNE takes 3.9806 seconds\n",
      "AUTOTUNE mm(1024x12, 12x1024)\n",
      "  mm 0.0181 ms 100.0%\n",
      "  triton_mm_1201 0.0192 ms 94.2%\n",
      "  triton_mm_1193 0.0195 ms 92.6%\n",
      "  triton_mm_1194 0.0205 ms 88.3%\n",
      "  triton_mm_1195 0.0208 ms 86.9%\n",
      "  triton_mm_1198 0.0213 ms 85.0%\n",
      "  triton_mm_1202 0.0213 ms 85.0%\n",
      "  triton_mm_1200 0.0216 ms 83.7%\n",
      "  triton_mm_1196 0.0229 ms 79.0%\n",
      "  triton_mm_1197 0.0234 ms 77.4%\n",
      "SingleProcess AUTOTUNE takes 4.6560 seconds\n",
      "AUTOTUNE bmm(16x12x12, 16x12x64)\n",
      "  bmm 0.0142 ms 100.0%\n",
      "  triton_bmm_1204 0.0146 ms 97.8%\n",
      "  triton_bmm_1203 0.0149 ms 95.7%\n",
      "SingleProcess AUTOTUNE takes 1.0241 seconds\n",
      "AUTOTUNE bmm(16x64x12, 16x12x12)\n",
      "  bmm 0.0144 ms 100.0%\n",
      "  triton_bmm_1209 0.0149 ms 96.8%\n",
      "  triton_bmm_1208 0.0150 ms 95.7%\n",
      "SingleProcess AUTOTUNE takes 0.9919 seconds\n",
      "AUTOTUNE mm(12x1024, 1024x1024)\n",
      "  mm 0.0283 ms 100.0%\n",
      "  triton_mm_1232 0.0914 ms 31.0%\n",
      "  triton_mm_1233 0.0918 ms 30.8%\n",
      "  triton_mm_1235 0.1116 ms 25.4%\n",
      "  triton_mm_1229 0.1158 ms 24.4%\n",
      "  triton_mm_1234 0.1346 ms 21.0%\n",
      "  triton_mm_1230 0.1550 ms 18.3%\n",
      "  triton_mm_1231 0.1605 ms 17.6%\n",
      "SingleProcess AUTOTUNE takes 4.1562 seconds\n",
      "AUTOTUNE mm(1024x12, 12x1024)\n",
      "  triton_mm_1236 0.0189 ms 100.0%\n",
      "  mm 0.0190 ms 99.2%\n",
      "  triton_mm_1244 0.0190 ms 99.2%\n",
      "  triton_mm_1245 0.0195 ms 96.7%\n",
      "  triton_mm_1237 0.0202 ms 93.7%\n",
      "  triton_mm_1238 0.0202 ms 93.7%\n",
      "  triton_mm_1243 0.0211 ms 89.4%\n",
      "  triton_mm_1241 0.0213 ms 88.7%\n",
      "  triton_mm_1240 0.0226 ms 83.7%\n",
      "  triton_mm_1239 0.0235 ms 80.3%\n",
      "SingleProcess AUTOTUNE takes 4.7182 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autotune (warmup) Model took 0.8872 seconds\n",
      "Autotune Model took 9.0501 seconds\n",
      "Autotune no cudagraph (warmup) Model took 0.1079 seconds\n",
      "Autotune no cudagraph Model took 0.1071 seconds\n",
      "TorchDynamo compilation metrics:\n",
      "Function                              Runtimes (s)\n",
      "------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "_compile.<locals>.compile_inner       66.3536\n",
      "OutputGraph.call_user_compiler        58.7143\n",
      "create_aot_dispatcher_function        0.0356, 0.0344, 0.0355, 0.0341, 0.0362, 0.0352, 0.0354, 0.0350, 0.0361, 0.0352, 0.0370, 0.0343, 0.0355, 0.0356, 0.0360, 0.0351, 0.0360, 0.0351, 0.0362, 0.0352, 0.0366, 0.0345, 0.0356, 0.0344, 0.0356, 0.0343, 0.0353, 0.0343, 0.0355, 0.0347, 0.0359, 0.0351, 0.0351, 0.0340, 0.0351, 0.0351, 0.0365, 0.0353, 0.0356, 0.0346, 0.0422, 0.0359, 0.0371, 0.0347, 0.0354, 0.0342, 0.0384, 0.0354, 58.5584\n",
      "compile_fx.<locals>.fw_compiler_base  12.7962\n",
      "GraphLowering.run                     3.6075, 5.9248\n",
      "GraphLowering.compile_to_module       3.1191, 3.5929\n",
      "Scheduler.__init__                    1.8075, 1.6815\n",
      "Scheduler.codegen                     1.1445, 1.5774\n",
      "WrapperCodeGen.generate               0.1449, 0.2798\n",
      "compile_fx.<locals>.bw_compiler       17.2505\n"
     ]
    }
   ],
   "source": [
    "import transformers \n",
    "from transformers import BertTokenizer, BertModel, T5Tokenizer, T5ForConditionalGeneration\n",
    "import time\n",
    "import torch\n",
    "\n",
    "torch._logging.set_logs()\n",
    "torch._dynamo.reset()\n",
    "\n",
    "training_set = [\n",
    "    \"Each culture offers a unique flavor to the world.\",\n",
    "    \"Time, an ever-flowing river, waits for none.\",\n",
    "    \"Childhood memories are treasures of the heart.\",\n",
    "    \"Love is the force that binds the universe.\",\n",
    "    \"Dreams are where imagination knows no bounds.\",\n",
    "    \"Laughter is the shortest distance between two people.\",\n",
    "    \"Food is more than sustenance; it's an experience.\",\n",
    "    \"Moonlit nights have a tale of their own.\",\n",
    "]\n",
    "\n",
    "def get_predictions(model_instance, text_list):\n",
    "    \"\"\"\n",
    "    Given a list of strings and a model instance, tokenize and pass them to the model for predictions.\n",
    "    :param model_instance: Instance of the model to run predictions\n",
    "    :param text_list: List of strings\n",
    "    :return: List of model outputs\n",
    "    \"\"\"\n",
    "    for text in text_list:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "        output = model_instance(**encoded_input)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-large-uncased\").to(device=\"cuda:0\")\n",
    "\n",
    "real_eager = model\n",
    "aot_eager = torch.compile(model, backend=\"aot_eager\", dynamic=True)\n",
    "model_ind = torch.compile(model, backend=\"inductor\", dynamic=False)\n",
    "model_dynamic_shapes = torch.compile(model, backend=\"inductor\", dynamic=True)\n",
    "model_dynamic_shapes_cuda_graph = torch.compile(model, backend=\"inductor\", dynamic=True, mode=\"reduce-overhead\")\n",
    "model_autotune = torch.compile(model, backend=\"inductor\", dynamic=True, mode=\"max-autotune\")\n",
    "model_autotune_nograph = torch.compile(model, backend=\"inductor\", dynamic=True, mode=\"max-autotune-no-cudagraphs\")\n",
    "\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device=\"cuda:0\")\n",
    "\n",
    "#start_time = time.time()\n",
    "#output = model(**encoded_input)\n",
    "#elapsed_time = time.time() - start_time\n",
    "#print(f\"Eager Model took {elapsed_time:.4f} seconds\")\n",
    "\n",
    "models = [\n",
    "    (\"Real eager\", real_eager),\n",
    "    (\"Eager compile\", aot_eager),\n",
    "    (\"Inductor\", model_ind),\n",
    "    (\"Dynamic Shapes\", model_dynamic_shapes),\n",
    "    (\"Dynamic Shapes with CUDA Graph\", model_dynamic_shapes_cuda_graph),\n",
    "    (\"Autotune\", model_autotune),\n",
    "    (\"Autotune no cudagraph\", model_autotune_nograph)\n",
    "]\n",
    "\n",
    "for name, model_instance in models:\n",
    "\n",
    "    # Reset for actual timing\n",
    "    torch._dynamo.reset()\n",
    "\n",
    "    # Warmup\n",
    "    model_instance(**tokenizer(training_set[0], return_tensors='pt').to(device=\"cuda:0\"))\n",
    "\n",
    "    start_time = time.time()\n",
    "    get_predictions(model_instance, training_set)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    print(f\"{name} (warmup) Model took {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    get_predictions(model_instance, training_set)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    print(f\"{name} Model took {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    \n",
    "print(torch._dynamo.utils.compile_times())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
